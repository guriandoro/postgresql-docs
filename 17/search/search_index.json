{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Percona Distribution for PostgreSQL 17 Documentation","text":"<p>Percona Distribution for PostgreSQL is a suite of open source software, tools and services required to deploy and maintain a reliable production cluster for PostgreSQL. </p> <p>Percona Distribution for PostgreSQL includes Percona Server for PostgreSQL packaged with extensions from open source community that are certified and tested to work together for high availability, backups, security, and monitoring that help ensure the cluster\u2019s peak performance. </p> <p>Part of the solution, Percona Operator for PostgreSQL, makes it easy to orchestrate the cluster reliably and repeatably in Kubernetes.</p> <p>What\u2019s included in Percona Distribution for PostgreSQL? </p>"},{"location":"index.html#whats-in-it-for-you","title":"What\u2019s in it for you?","text":"<ul> <li>No vendor lock in - all components of Percona Distribution for PostgreSQL are fully open source</li> <li>No guesswork on finding the right version of a component \u2013 they all undergo thorough testing to ensure compatibility</li> <li>Freely available reference architectures for solutions like high-availability, backups and disaster recovery </li> <li>Spatial data handling support via PostGIS</li> <li>Monitoring of the database health, performance and infrastructure usage via open source Percona Management and Monitoring  with PostgreSQL-specific dashboards</li> <li>Run PostgreSQL on Kubernetes using open source Percona Operator for PostgreSQL . It not only automates deployment and management of PostgreSQL clusters on Kubernetes, but also includes enterprise-ready features for high-availability, backup and restore, replication, logging, and more </li> <li>Automate PostgreSQL provisioning and management in Kubernetes, in the cloud or on-premises with Percona Everest  - the cloud-native database platform</li> </ul>"},{"location":"index.html#installation-guides","title":"Installation guides","text":"<p>Get started quickly with the step-by-step installation instructions.</p> <p>Quickstart guides </p>"},{"location":"index.html#solutions","title":"Solutions","text":"<p>Check our solutions to build the database infrastructure that meets the requirements of your organization - be it high-availability, disaster recovery or spatial data handling.</p> <p>Solutions </p>"},{"location":"index.html#troubleshooting-and-faq","title":"Troubleshooting and FAQ","text":"<p>Our comprehensive resources will help you overcome challenges, from everyday issues to specific doubts.</p> <p>Troubleshooting </p>"},{"location":"index.html#whats-new","title":"What\u2019s new?","text":"<p>Learn about the releases and changes in the Distribution.</p> <p>Release notes </p>"},{"location":"index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"apt.html","title":"Install Percona Distribution for PostgreSQL on Debian and Ubuntu","text":"<p>This document describes how to install Percona Server for PostgreSQL from Percona repositories on DEB-based distributions such as Debian and Ubuntu. Read more about Percona repositories.</p>"},{"location":"apt.html#preconditions","title":"Preconditions","text":"<ol> <li>Debian and other systems that use the <code>apt</code> package manager include the upstream PostgreSQL server package <code>postgresql-17</code> by default. The components of Percona Distribution for PostgreSQL 17 can only be installed together with Percona Server for PostgreSQL (<code>percona-postgresql-17</code>). If you wish to use Percona Distribution for PostgreSQL, uninstall the <code>postgresql-17</code>  package provided by your distribution and then install the chosen components from Percona Distribution for PostgreSQL.</li> <li> <p>Install <code>curl</code> for Telemetry. We use it to better understand the use of our products and improve them. To install <code>curl</code>, run the following command:</p> <pre><code>$ sudo apt install curl\n</code></pre> </li> </ol>"},{"location":"apt.html#procedure","title":"Procedure","text":"<p>Run all the commands in the following sections as root or using the <code>sudo</code> command:</p>"},{"location":"apt.html#configure-percona-repository","title":"Configure Percona repository","text":"<ol> <li> <p>Install the <code>percona-release</code> repository management tool to subscribe to Percona repositories:</p> <ul> <li> <p>Fetch <code>percona-release</code> packages from Percona web:</p> <pre><code>$ wget https://repo.percona.com/apt/percona-release_latest.$(lsb_release -sc)_all.deb\n</code></pre> </li> <li> <p>Install the downloaded package with <code>dpkg</code>:</p> <pre><code>$ sudo dpkg -i percona-release_latest.$(lsb_release -sc)_all.deb\n</code></pre> </li> <li> <p>Refresh the local cache:</p> <pre><code>$ sudo apt update\n</code></pre> </li> </ul> </li> <li> <p>Enable the repository</p> </li> </ol> <p>Percona provides two repositories for Percona Distribution for PostgreSQL. We recommend enabling the Major release repository to timely receive the latest updates. </p> <pre><code>$ sudo percona-release setup ppg-17\n</code></pre>"},{"location":"apt.html#install-packages","title":"Install packages","text":"Install using meta-packageInstall packages individually <p>The meta package enables you to install several components of the distribution in one go.</p> <pre><code>$ sudo apt install percona-ppg-server-17\n</code></pre> <p>Run the following commands:</p> <ol> <li> <p>Install the PostgreSQL server package:</p> <pre><code>$ sudo apt install percona-postgresql-17\n</code></pre> </li> <li> <p>Install the components:</p> <p>Install <code>pg_repack</code>:</p> <pre><code>$ sudo apt install percona-postgresql-17-repack\n</code></pre> <p>Install <code>pgAudit</code>:</p> <pre><code>$ sudo apt install percona-postgresql-17-pgaudit\n</code></pre> <p>Install <code>pgBackRest</code>:</p> <pre><code>$ sudo apt install percona-pgbackrest\n</code></pre> <p>Install <code>Patroni</code>:</p> <pre><code>$ sudo apt install percona-patroni\n</code></pre> <p>Install <code>pg_stat_monitor</code> </p> <p>Install <code>pgBouncer</code>:</p> <pre><code>$ sudo apt install percona-pgbouncer\n</code></pre> <p>Install <code>pgAudit-set_user</code>:</p> <pre><code>$ sudo apt install percona-pgaudit17-set-user\n</code></pre> <p>Install <code>pgBadger</code>:</p> <pre><code>$ sudo apt install percona-pgbadger\n</code></pre> <p>Install <code>wal2json</code>:</p> <pre><code>$ sudo apt install percona-postgresql-17-wal2json\n</code></pre> <p>Install PostgreSQL contrib extensions:</p> <pre><code>$ sudo apt install percona-postgresql-contrib\n</code></pre> <p>Install HAProxy</p> <pre><code>$ sudo apt install percona-haproxy\n</code></pre> <p>Install pgpool2</p> <pre><code>$ sudo apt install percona-pgpool2\n</code></pre> <p>Install <code>pg_gather</code></p> <pre><code>$ sudo apt install percona-pg-gather\n</code></pre> <p>Some extensions require additional setup in order to use them with Percona Distribution for PostgreSQL. For more information, refer to Enabling extensions.</p> </li> </ol>"},{"location":"apt.html#start-the-service","title":"Start the service","text":"<p>The installation process automatically initializes and starts the default database. You can check the database status using the following command:</p> <pre><code>$ sudo systemctl status postgresql.service\n</code></pre> <p>Check the Percona Distribution for PostgreSQL version:</p> <pre><code>$ psql --version\n</code></pre> Sample output <pre><code>psql (PostgreSQL) 17.0.1 (Percona Server for PostgreSQL) 17.0.1\n</code></pre> <p>Congratulations! Your Percona Distribution for PostgreSQL is up and running.</p>"},{"location":"apt.html#next-steps","title":"Next steps","text":"<p>Enable extensions </p> <p>Connect to PostgreSQL </p> <p></p>"},{"location":"apt.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"connect.html","title":"Connect to the PostgreSQL server","text":"<p>With PostgreSQL server up and running, let\u2019s connect to it.</p> <p>By default, the <code>postgres</code> user and the <code>postgres</code> database are created in PostgreSQL upon its installation and initialization. This allows you to connect to the database as the <code>postgres</code> user.</p> <ol> <li> <p>Switch to the <code>postgres</code> user.</p> <pre><code>$ sudo su postgres\n</code></pre> </li> <li> <p>Open the PostgreSQL interactive terminal <code>psql</code>:</p> <pre><code>$ psql\n</code></pre> <p> Hint: You can connect to <code>psql</code> as the <code>postgres</code> user in one go: </p> <pre><code>$ sudo su - postgres -c psql\n</code></pre> </li> </ol>"},{"location":"connect.html#basic-psql-commands","title":"Basic <code>psql</code> commands","text":"<p>While connected to PostgreSQL, let\u2019s practice some basic <code>psql</code> commands to interact with the database:</p> <ol> <li> <p>List databases:</p> <pre><code>$ \\l\n</code></pre> </li> <li> <p>Display tables in the current database:</p> <pre><code>$ \\dt\n</code></pre> </li> <li> <p>Display columns in a table</p> <pre><code>$ \\d &lt;table_name&gt;\n</code></pre> </li> <li> <p>Switch databases</p> <pre><code>$ \\c &lt;database_name&gt;\n</code></pre> </li> <li> <p>Display users and roles</p> <pre><code>$ \\du\n</code></pre> </li> <li> <p>Exit the <code>psql</code> terminal:</p> <pre><code>$ \\q\n</code></pre> </li> </ol> <p>To learn more about using <code>psql</code>, see <code>psql</code>  documentation.</p> <p>Congratulations! You have connected to PostgreSQL and learned some essential <code>psql</code> commands. </p>"},{"location":"connect.html#next-steps","title":"Next steps","text":"<p>Manipulate data in PostgreSQL </p> <p></p>"},{"location":"connect.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"contrib.html","title":"PostgreSQL contrib modules and utilities","text":"<p>Find the list of controb modules and extensions included in Percona Distribution for PostgtreSQL.</p> Name Database superuser Description adminpack Required Support toolpack for pgAdmin to provide additional functionality like remote management of server log files. amcheck Required Provides functions to verify the logical consistency of the structure of indexes, such as B-trees. It\u2019s useful for detecting system catalog corruption and index corruption. auth_delay Required Causes the server to pause briefly before reporting authentication failure, to make brute-force attacks on database passwords more difficult. auto_explain Required Automatically logs execution plans of slow SQL statements. It helps in performance analysis by tracking down un-optimized queries in large applications that exceed a specified time threshold. basebackup_to_shell Adds a custom basebackup target called <code>shell</code>. This enables an administartor to make a base backup of a running PostgreSQL server to a shell archive. basic-archive Required An archive module that copies completed WAL segment files to the specified directory. Can be used as a starting point for developing own archive module. bloom Required Provides an index access method based on Bloom filters.  A Bloom filter is a space-efficient data structure that is used to test whether an element is a member of a set. btree_gin Required Provides GIN index operator classes with B-tree-like behavior. This allows you to use GIN indexes, which are typically used for full-text search, in situations where you might otherwise use a B-tree index, such as with integer or text data. btree_gist Required Provides GiST (Generalized Search Tree) index operator classes that implement B-tree-like behavior. This allows you to use GiST indexes, which are typically used for multidimensional and non-scalar data, in situations where you might otherwise use a B-tree index, such as with integer or text data. citext Provides a case-insensitive character string type, citext. Essentially, it internally calls <code>lower</code> when comparing values. Otherwise, it behaves almost exactly like <code>text</code>. cube Implements a data type cube for representing multidimensional cubes dblink Required Provides functions to connect to other PostgreSQL databases from within a database session. This allows for queries to be run across multiple databases as if they were on the same server. dict_int An example of an add-on dictionary template for full-text search. It\u2019s used to demonstrate how to create custom dictionaries in PostgreSQL. dict_xsyn Required Example synonym full-text search dictionary. This dictionary type replaces words with groups of their synonyms, and so makes it possible to search for a word using any of its synonyms. earthdistance Required This module  provides two different approaches to calculating great circle distances on the surface of the Earth. The fisrt one depends on the <code>cube</code> module. The second one is based on the built-in <code>point</code> data type, using longitude and latitude for the coordinates. hstore Implements the <code>hstore</code> data type for storing sets of key/value pairs within a single PostgreSQL value. intagg Integer aggregator and enumerator. intarray Provides a number of useful functions and operators for manipulating null-free arrays of integers. isn Provides data types for the following international product numbering standards: EAN13, UPC, ISBN (books), ISMN (music), and ISSN (serials). lo Provides support for managing Large Objects (also called LOs or BLOBs). This includes a data type lo and a trigger lo_manage. ltree Implements a data type <code>ltree</code> for representing labels of data stored in a hierarchical tree-like structure. Extensive facilities for searching through label trees are provided. oldsnapshot Required Allows inspection of the server state that is used to implement old_snapshot_threshold. pageinspect Required Provides functions that allow you to inspect the contents of database pages at a low level, which is useful for debugging purposes. passwordcheck Checks users\u2019 passwords whenever they are set with CREATE ROLE or ALTER ROLE. If a password is considered too weak, it will be rejected and the command will terminate with an error. pg_buffercache Required Provides the set of functions for examining what\u2019s happening in the shared buffer cache in real time. pgcrypto Required Provides cryptographic functions for PostgreSQL. pg_freespacemap Required Provides a means of examining the free space map (FSM), which PostgreSQL uses to track the locations of available space in tables and indexes. This can be useful for understanding space utilization and planning for maintenance operations. pg_prewarm Provides a convenient way to load relation data into either the operating system buffer cache or the PostgreSQL buffer cache. This can be useful for reducing the time needed for a newly started database to reach its full performance potential by preloading frequently accessed data. pgrowlocks Required Provides a function to show row locking information for a specified table. pg_stat_statements Required A module for tracking planning and execution statistics of all SQL statements executed by a server. Consider using an advanced version of <code>pg_stat_statements</code> - <code>pg_stat_monitor</code> pgstattuple Required Povides various functions to obtain tuple-level statistics. It offers detailed information about tables and indexes, such as the amount of free space and the number of live and dead tuples. pg_surgery Required Provides various functions to perform surgery on a damaged relation. These functions are unsafe by design and using them may corrupt (or further corrupt) your database. Use them with caution and only as a last resort pg_trgm Provides functions and operators for determining the similarity of alphanumeric text based on trigram matching. A trigram is a contiguous sequence of three characters. The extension can be used for text search and pattern matching operations. pg_visibility Required Provides a way to examine the visibility map (VM) and the page-level visibility information of a table. It also provides functions to check the integrity of a visibility map and to force it to be rebuilt. pg_walinspect Required Provides SQL functions that allow you to inspect the contents of write-ahead log of a running PostgreSQL database cluster at a low level, which is useful for debugging, analytical, reporting or educational purposes. postgres_fdw Required Provides a Foreign Data Wrapper (FDW) for accessing data in remote PostgreSQL servers. It allows a PostgreSQL database to interact with remote tables as if they were local. seg Implements a data type <code>seg</code> for representing line segments, or floating point intervals. <code>seg</code> can represent uncertainty in the interval endpoints, making it especially useful for representing laboratory measurements. segpgsql SELinux-, label-based mandatory access control (MAC) security module. It can only be used on Linux 2.6.28 or higher with SELinux enabled. spi Required Provides several workable examples of using the Server Programming Interface (SPI) and triggers. sslinfo Reqjuired Provides information about the SSL certificate that the current client provided when connecting to PostgreSQL. tablefunc Includes various functions that return tables (that is, multiple rows). These functions are useful both in their own right and as examples of how to write C functions that return multiple rows. tcn Provides a trigger function that notifies listeners of changes to any table on which it is attached. test_decoding Required An SQL-based test/example module for WAL logical decoding tsm_system_rows Provides the table sampling method SYSTEM_ROWS, which can be used in the TABLESAMPLE clause of a SELECT command. tsm_system_time Provides the table sampling method  SYSTEM_TIME, which can be used in the TABLESAMPLE clause of a SELECT command. unaccent A text search dictionary that removes accents (diacritic signs) from lexemes. It\u2019s a filtering dictionary, which means its output is always passed to the next dictionary (if any). This allows accent-insensitive processing for full text search. uuid-ossp Required Provides functions to generate universally unique identifiers (UUIDs) using one of several standard algorithms xml2 Required Provides XPath querying and XSLT functionality. It allows for complex querying and transformation of XML data stored in PostgreSQL. <p></p>"},{"location":"contrib.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"crud.html","title":"Manipulate data in PostgreSQL","text":"<p>On the previous step, you have connected to PostgreSQL as the superuser <code>postgres</code>. Now, let\u2019s insert some sample data and operate with it in PostgreSQL.</p>"},{"location":"crud.html#create-a-database","title":"Create a database","text":"<p>Let\u2019s create the database <code>test</code>. Use the CREATE DATABASE command:</p> <pre><code>CREATE DATABASE test;\n</code></pre>"},{"location":"crud.html#create-a-table","title":"Create a table","text":"<p>Let\u2019s create a sample table <code>Customers</code> in the <code>test</code> database using the following command:</p> <pre><code>CREATE TABLE customers (\n    id SERIAL PRIMARY KEY,  -- 'id' is an auto-incrementing integer\n    first_name VARCHAR(50), -- 'first_name' is a string with a maximum length of 50 characters\n    last_name VARCHAR(50),  -- 'last_name' is a string with a maximum length of 50 characters\n    email VARCHAR(100)      -- 'email' is a string with a maximum length of 100 characters\n);\n</code></pre> <p> Hint:Having issues with table creation? Check our Troubleshooting guide</p>"},{"location":"crud.html#insert-the-data","title":"Insert the data","text":"<p>Populate the table with the sample data as follows:</p> <pre><code>INSERT INTO customers (first_name, last_name, email)\nVALUES \n    ('John', 'Doe', 'john.doe@example.com'),  -- Insert a new row\n    ('Jane', 'Doe', 'jane.doe@example.com');\n    ('Alice', 'Smith', 'alice.smith@example.com');\n</code></pre>"},{"location":"crud.html#query-data","title":"Query data","text":"<p>Let\u2019s verify the data insertion by querying it:</p> <pre><code>SELECT * FROM customers;\n</code></pre> Expected output <pre><code>id | first_name | last_name |          email\n----+------------+-----------+-------------------------\n  1 | John       | Doe       | john.doe@example.com\n  2 | Jane       | Doe       | jane.doe@example.com\n  3 | Alice      | Smith     | alice.smith@example.com\n(3 rows)\n</code></pre>"},{"location":"crud.html#update-data","title":"Update data","text":"<p>Let\u2019s update John Doe\u2019s record with a new email address.</p> <ol> <li> <p>Use the UPDATE command for that:</p> <pre><code>UPDATE customers \nSET email = 'john.doe@myemail.com'\nWHERE first_name = 'John' AND last_name = 'Doe';\n</code></pre> </li> <li> <p>Query the table to verify the updated data:</p> <pre><code>SELECT * FROM customers WHERE first_name = 'John' AND last_name = 'Doe';\n</code></pre> Expected output <pre><code> id | first_name | last_name |          email\n----+------------+-----------+-------------------------\n  2 | Jane       | Doe       | jane.doe@example.com\n  3 | Alice      | Smith     | alice.smith@example.com\n  1 | John       | Doe       | john.doe@myemail.com\n(3 rows)\n</code></pre> </li> </ol>"},{"location":"crud.html#delete-data","title":"Delete data","text":"<p>Use the DELETE command to delete rows. For example, delete the record of Alice Smith:</p> <pre><code>DELETE FROM Customers WHERE first_name = 'Alice' AND last_name = 'Smith';\n</code></pre> <p>If you wish to delete the whole table, use the <code>DROP TABLE</code> command instead as follows:</p> <pre><code>DROP TABLE customers;\n</code></pre> <p>To delete the whole database, use the DROP DATABASE command:</p> <pre><code>DROP DATABASE test;\n</code></pre> <p>Congratulations! You have used basic create, read, update and delete (CRUD) operations to manipulate data in Percona Distribution for PostgreSQL. To deepen your knowledge, see the data manipulation  section in PostgreSQL documentation.</p>"},{"location":"crud.html#next-steps","title":"Next steps","text":"<p>What\u2019s next?</p> <p></p>"},{"location":"crud.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"docker.html","title":"Run Percona Distribution for PostgreSQL in a Docker container","text":"<p>Docker images of Percona Distribution for PostgreSQL are hosted publicly on Docker Hub .</p> <p>For more information about using Docker, see the Docker Docs .</p> <p>Make sure that you are using the latest version of Docker . The ones provided via <code>apt</code> and <code>yum</code> may be outdated and cause errors.</p> <p>By default, Docker pulls the image from Docker Hub if it is not available locally.</p> Docker image contents <p>The Docker image of Percona Distribution for PostgreSQL includes the following components:    </p> Component name Description <code>percona-postgresql17</code> A metapackage that installs the latest version of PostgreSQL <code>percona-postgresql17-server</code> The PostgreSQL server package. <code>percona-postgresql-common</code> PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. <code>percona-postgresql-client-common</code> The manager for multiple PostgreSQL client versions. <code>percona-postgresql17-contrib</code> A collection of additional PostgreSQLcontrib extensions <code>percona-postgresql17-libs</code> Libraries for use with PostgreSQL. <code>percona-pg-stat-monitor17</code> A Query Performance Monitoring tool for PostgreSQL. <code>percona-pgaudit17</code> Provides detailed session or object audit logging via the standard PostgreSQL logging facility. <code>percona-pgaudit17_set_user</code> An additional layer of logging and control when unprivileged users must escalate themselves to superuser or object owner roles in order to perform needed maintenance tasks. <code>percona-pg_repack17</code> rebuilds PostgreSQL database objects. <code>percona-wal2json17</code> a PostgreSQL logical decoding JSON output plugin."},{"location":"docker.html#start-the-container","title":"Start the container","text":"<ol> <li> <p>Start a Percona Distribution for PostgreSQL container as follows:</p> <pre><code>$ docker run --name container-name -e POSTGRES_PASSWORD=secret -d percona/percona-distribution-postgresql:&lt;tag&gt;-multi\n</code></pre> <p>Where:    </p> <ul> <li><code>container-name</code> is the name you assign to your container</li> <li><code>POSTGRES_PASSWORD</code> is the superuser password </li> <li><code>tag-multi</code> is the tag specifying the version you need. For example, <code>17.0-multi</code>. The <code>multi</code> part of the tag serves to identify the architecture (x86_64 or ARM64) and pull the respective image. See the full list of tags .     </li> </ul> <p>Tip</p> <p>You can secure the password by exporting it to the environment file and using that to start the container.    </p> <ol> <li> <p>Export the password to the environment file:    </p> <pre><code>$ echo \"POSTGRES_PASSWORD=secret\" &gt; .my-pg.env\n</code></pre> </li> <li> <p>Start the container:       </p> <pre><code>$ docker run --name container-name --env-file ./.my-pg.env -d percona/percona-distribution-postgresql:&lt;tag&gt;-multi\n</code></pre> </li> </ol> </li> <li> <p>Connect to the container\u2019s interactive terminal: </p> <pre><code>$ docker exec -it container-name bash\n</code></pre> <p>The <code>container-name</code> is the name of the container that you started in the previous step.</p> </li> </ol>"},{"location":"docker.html#connect-to-percona-distribution-for-postgresql-from-an-application-in-another-docker-container","title":"Connect to Percona Distribution for PostgreSQL from an application in another Docker container","text":"<p>This image exposes the standard PostgreSQL port (<code>5432</code>), so container linking makes the instance available to other containers. Start other containers like this in order to link it to the Percona Distribution for PostgreSQL container:</p> <pre><code>$ docker run --name app-container-name --network container:container-name -d app-that-uses-postgresql \n</code></pre> <p>where:</p> <ul> <li><code>app-container-name</code> is the name of the container where your application is running, </li> <li><code>container name</code> is the name of your Percona Distribution for PostgreSQL container, and </li> <li><code>app-that-uses-postgresql</code> is the name of your PostgreSQL client.</li> </ul>"},{"location":"docker.html#connect-to-percona-distribution-for-postgresql-from-the-psql-command-line-client","title":"Connect to Percona Distribution for PostgreSQL from the <code>psql</code> command line client","text":"<p>The following command starts another container instance and runs the <code>psql</code> command line client against your original container, allowing you to execute SQL statements against your database:</p> <pre><code>$ docker run -it --network container:db-container-name --name container-name percona/percona-distribution-postgresql:&lt;tag&gt;-multi psql -h address -U postgres\n</code></pre> <p>Where:</p> <ul> <li><code>db-container-name</code> is the name of your database container</li> <li><code>container-name</code> is the name of your container that you will use to connect to the database container using the <code>psql</code> command line client <code>tag-multi</code> is the tag specifying the version you need. For example, <code>17.0-multi</code>. The <code>multi</code> part of the tag serves to identify the architecture (x86_64 or ARM64) and pull the respective image. </li> <li><code>address</code> is the network address where your database container is running. Use 127.0.0.1, if the database container is running on the local machine/host.   </li> </ul>"},{"location":"docker.html#enable-pg_stat_monitor","title":"Enable <code>pg_stat_monitor</code>","text":"<p>To enable the <code>pg_stat_monitor</code> extension after launching the container, do the following:</p> <ul> <li>connect to the server, </li> <li>select the desired database and enable the <code>pg_stat_monitor</code> view for that database:</li> </ul> <pre><code>create extension pg_stat_monitor;\n</code></pre> <ul> <li>to ensure that everything is set up correctly, run:</li> </ul> <pre><code>\\d pg_stat_monitor;\n</code></pre> Output <pre><code>                         View \"public.pg_stat_monitor\"\n      Column        |           Type           | Collation | Nullable | Default\n---------------------+--------------------------+-----------+----------+---------\nbucket              | integer                  |           |          |\nbucket_start_time   | timestamp with time zone |           |          |\nuserid              | oid                      |           |          |\ndbid                | oid                      |           |          |\nqueryid             | text                     |           |          |\nquery               | text                     |           |          |\nplan_calls          | bigint                   |           |          |\nplan_total_time     | numeric                  |           |          |\nplan_min_timei      | numeric                  |           |          |\nplan_max_time       | numeric                  |           |          |\nplan_mean_time      | numeric                  |           |          |\nplan_stddev_time    | numeric                  |           |          |\nplan_rows           | bigint                   |           |          |\ncalls               | bigint                   |           |          |\ntotal_time          | numeric                  |           |          |\nmin_time            | numeric                  |           |          |\nmax_time            | numeric                  |           |          |\nmean_time           | numeric                  |           |          |\nstddev_time         | numeric                  |           |          |\nrows                | bigint                   |           |          |\nshared_blks_hit     | bigint                   |           |          |\nshared_blks_read    | bigint                   |           |          |\nshared_blks_dirtied | bigint                   |           |          |\nshared_blks_written | bigint                   |           |          |\nlocal_blks_hit      | bigint                   |           |          |\nlocal_blks_read     | bigint                   |           |          |\nlocal_blks_dirtied  | bigint                   |           |          |\nlocal_blks_written  | bigint                   |           |          |\ntemp_blks_read      | bigint                   |           |          |\ntemp_blks_written   | bigint                   |           |          |\nblk_read_time       | double precision         |           |          |\nblk_write_time      | double precision         |           |          |\nhost                | bigint                   |           |          |\nclient_ip           | inet                     |           |          |\nresp_calls          | text[]                   |           |          |\ncpu_user_time       | double precision         |           |          |\ncpu_sys_time        | double precision         |           |          |\ntables_names        | text[]                   |           |          |\nwait_event          | text                     |           |          |\nwait_event_type     | text                     |           |          |\n</code></pre> <p>Note that the <code>pg_stat_monitor</code> view is available only for the databases where you enabled it. If you create a new database, make sure to create the view for it to see its statistics data.</p> <p></p>"},{"location":"docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"enable-extensions.html","title":"Enable Percona Distribution for PostgreSQL components","text":"<p>Some components require additional configuration before using them with Percona Distribution for PostgreSQL. This sections provides configuration instructions per component.</p>"},{"location":"enable-extensions.html#patroni","title":"Patroni","text":"<p>Patroni is the third-party high availability solution for PostgreSQL. The High Availability in PostgreSQL with Patroni chapter provides details about the solution overview and architecture deployment. </p> <p>While setting up a high availability PostgreSQL cluster with Patroni, you will need the following components:</p> <ul> <li> <p>Patroni installed on every <code>postresql</code> node. </p> </li> <li> <p>Distributed Configuration Store (DCS). Patroni supports such DCSs as etcd, zookeeper, Kubernetes though etcd is the most popular one. It is available within Percona Distribution for PostgreSQL for all supported operating systems. </p> </li> <li> <p>HAProxy .</p> </li> </ul> <p>If you install the software fom packages, all required dependencies and service unit files are included. If you install the software from the tarballs, you must first enable <code>etcd</code>. See the steps in the etcd section if this document.</p> <p>See the configuration guidelines for Debian and Ubuntu and RHEL and CentOS. </p>"},{"location":"enable-extensions.html#etcd","title":"etcd","text":"<p>If you installed etcd from binary tarballs, you need to create the <code>etcd.service</code> file. This file allows <code>systemd</code> to start, stop, restart, and manage the <code>etcd</code> service. This includes handling dependencies, monitoring the service, and ensuring it runs as expected. </p> /etc/systemd/system/etcd.service<pre><code>[Unit]\nAfter=network.target\nDescription=etcd - highly-available key value store\n\n[Service]\nLimitNOFILE=65536\nRestart=on-failure\nType=notify\nExecStart=/usr/bin/etcd --config-file /etc/etcd/etcd.conf.yaml\nUser=etcd\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"enable-extensions.html#pgbadger","title":"pgBadger","text":"<p>Enable the following options in <code>postgresql.conf</code> configuration file before starting the service:</p> <pre><code>log_min_duration_statement = 0\nlog_line_prefix = '%t [%p]: '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_lock_waits = on\nlog_temp_files = 0\nlog_autovacuum_min_duration = 0\nlog_error_verbosity = default\n</code></pre> <p>For details about each option, see pdBadger documentation .</p>"},{"location":"enable-extensions.html#pgaudit","title":"pgaudit","text":"<p>Add the <code>pgaudit</code> to <code>shared_preload_libraries</code> in <code>postgresql.conf</code>. The recommended way is to use the ALTER SYSTEM command. Connect to psql and use the following command:</p> <pre><code>ALTER SYSTEM SET shared_preload_libraries = 'pgaudit';\n</code></pre> <p>Start / restart the server to apply the configuration.</p> <p>To configure <code>pgaudit</code>, you must have the privileges of a superuser. You can specify the settings in one of these ways:</p> <ul> <li>globally (in postgresql.conf or using ALTER SYSTEM \u2026 SET), </li> <li>at the database level (using ALTER DATABASE \u2026 SET), </li> <li>at the role level (using ALTER ROLE \u2026 SET). Note that settings are not inherited through normal role inheritance and SET ROLE will not alter a user\u2019s pgAudit settings. This is a limitation of the roles system and not inherent to pgAudit. </li> </ul> <p>Refer to the pgaudit documentation for details about available settings.</p> <p>To enable <code>pgaudit</code>, connect to psql and run the CREATE EXTENSION command:</p> <pre><code>CREATE EXTENSION pgaudit;\n</code></pre>"},{"location":"enable-extensions.html#pgaudit-set-user","title":"pgaudit set-user","text":"<p>Add the <code>set-user</code> to <code>shared_preload_libraries</code> in <code>postgresql.conf</code>. The recommended way is to use the ALTER SYSTEM  command. Connect to psql and use the following command:</p> <pre><code>ALTER SYSTEM SET shared_preload_libraries = 'set-user';\n</code></pre> <p>Start / restart the server to apply the configuration.</p> <p>Install the extension into your database:</p> <pre><code>psql &lt;database&gt;\nCREATE EXTENSION set_user;\n</code></pre> <p>You can fine-tune user behavior with the custom parameters  supplied with the extension.</p>"},{"location":"enable-extensions.html#pgbouncer","title":"pgbouncer","text":"<p><code>pgbouncer</code> requires the <code>pgbouncer.ini</code> configuration file to start. The default path is <code>/etc/pgbouncer/pgbouncer.ini</code>. When installing <code>pgbouncer</code> from a tarball, the path is <code>percona-pgbouncer/etc/pgbouncer.ini</code>.</p> <p>Find detailed information about configuration file options in the <code>pgbouncer documentation</code>.</p>"},{"location":"enable-extensions.html#pgpool2","title":"pgpool2","text":"<p><code>pgpool-II</code> requires the configuration file to start. When you install pgpool from a package, the configuration file is automatically created for you at the path <code>/etc/pgpool2/pgpool.conf</code> on Debian and Ubuntu and <code>/etc/pgpool-II/pgpool.conf</code> on RHEL and derivatives.</p> <p>When you installed pgpool from tarballs, you can use the sample configuration file <code>&lt;tarballsdir&gt;/percona-pgpool-II/etc/pgpool2/pgpool.conf.sample</code>:</p> <pre><code>$ cp &lt;tarballsdir&gt;/percona-pgpool-II/etc/pgpool2/pgpool.conf.sample &lt;config-gile-path&gt;/pgpool.conf\n</code></pre> <p>Specify the path to it when starting pgpool:</p> <pre><code>$ pgpool -f &lt;config-gile-path&gt;/pgpool.conf\n</code></pre>"},{"location":"enable-extensions.html#pg_stat_monitor","title":"pg_stat_monitor","text":"<p>Please refer to <code>pg_stat_monitor</code> for setup steps.</p>"},{"location":"enable-extensions.html#wal2json","title":"wal2json","text":"<p>After the installation, enable the following option in <code>postgresql.conf</code> configuration file before starting the service:</p> <pre><code>wal_level = logical\n</code></pre> <p>Start / restart the server to apply the changes.</p>"},{"location":"enable-extensions.html#next-steps","title":"Next steps","text":"<p>Connect to PostgreSQL </p> <p></p>"},{"location":"enable-extensions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"extensions.html","title":"Extensions","text":"<p>Percona Distribution for PostgreSQL is not only Percona Server for PostgreSQL. It also includes extensions - the add-ons that enhance the functionality of PostgreSQL database. By installing these extensions, you can modify and extend your database server with new features, functions, and data types.</p> <p>Percona Distribution for PostgreSQL includes the extensions that have been tested to work together. These extensions encompass the following:</p> <ul> <li>PostgreSQL contrib modules and utilities</li> <li>Extensions authored by Percona</li> <li>Third-party components</li> </ul> <p>Percona also supports extra modules, not included in Percona Distribution for PostgreSQL but tested to work with it.</p> <p>Additionally, see the list of PostgreSQL software covered by Percona Support.</p>"},{"location":"extensions.html#install-an-extension","title":"Install an extension","text":"<p>To use an extension, install it. Run the <code>CREATE EXTENSION</code> command on the PostgreSQL node where you want the extension to be available. </p> <p>The user should be a superuser or have the <code>CREATE</code> privilege on the current database to be able to run the <code>CREATE EXTENSION</code> command. Some extensions may require additional privileges depending on their functionality. To learn more, check the documentation for the desired extension.</p> <p></p>"},{"location":"extensions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"how-to.html","title":"How to","text":""},{"location":"how-to.html#how-to-configure-etcd-nodes-simultaneously","title":"How to configure etcd nodes simultaneously","text":"<p>Note</p> <p>We assume you have a deeper knowledge of how etcd works. Otherwise, refer to the configuration where you add etcd nodes one by one. </p> <p>Instead of adding <code>etcd</code> nodes one by one, you can configure and start all nodes in parallel. </p> <ol> <li> <p>Create the etcd configuration file on every node. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node names and IP addresses with the actual names and IP addresses of your nodes.</p> node1node2node3 /etc/etcd/etcd.conf.yaml<pre><code>name: 'node1'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: new\ninitial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,node3=http://10.104.0.3:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.1:2380 \nlisten-peer-urls: http://10.104.0.1:2380\nadvertise-client-urls: http://10.104.0.1:2379\nlisten-client-urls: http://10.104.0.1:2379\n</code></pre> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node2'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: new\ninitial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,     node3=http://10.104.0.3:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.2:2380 \nlisten-peer-urls: http://10.104.0.2:2380\nadvertise-client-urls: http://10.104.0.2:2379\nlisten-client-urls: http://10.104.0.2:2379\n</code></pre> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node1'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: new\ninitial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,     node3=http://10.104.0.3:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.3:2380 \nlisten-peer-urls: http://10.104.0.3:2380\nadvertise-client-urls: http://10.104.0.3:2379\nlisten-client-urls: http://10.104.0.3:2379\n</code></pre> </li> <li> <p>Enable and start the <code>etcd</code> service on all nodes:</p> <pre><code>$ sudo systemctl enable --now etcd\n</code></pre> <p>During the node start, etcd searches for other cluster nodes defined in the configuration. If the other nodes are not yet running, the start may fail by a quorum timeout. This is expected behavior. Try starting all nodes again at the same time for the etcd cluster to be created.</p> </li> <li> <p>Check the etcd cluster members.  Connect to one of the nodes and run the following command:</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>The output resembles the following:</p> <pre><code>2d346bd3ae7f07c4: name=node2 peerURLs=http://10.104.0.2:2380 clientURLs=http://10.104.0.2:2379 isLeader=false\n8bacb519ebdee8db: name=node3 peerURLs=http://10.104.0.3:2380 clientURLs=http://10.104.0.3:2379 isLeader=false\nc5f52ea2ade25e1b: name=node1 peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379 isLeader=true\n</code></pre> </li> </ol> <p></p>"},{"location":"how-to.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"installing.html","title":"Quickstart guide","text":"<p>Percona Distribution for PostgreSQL is the Percona server for PostgreSQL with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. Read more.</p> <p>This document aims to guide database application developers and DevOps engineers in getting started with Percona Distribution for PostgreSQL. Upon completion of this guide, you\u2019ll have Percona Distribution for PostgreSQL installed and operational, and you\u2019ll be able to:</p> <ul> <li>Connect to PostgreSQL using the <code>psql</code> interactive terminal </li> <li>Interact with PostgreSQL with basic psql commands</li> <li>Manipulate data in PostgreSQL </li> <li>Understand the next steps you can take as a database application developer or administrator to expand your knowledge of Percona Distribution for PostgreSQL</li> </ul>"},{"location":"installing.html#install-percona-distribution-for-postgresql","title":"Install Percona Distribution for PostgreSQL","text":"<p>You can select from multiple easy-to-follow installation options, but we recommend using a Package Manager for a convenient and quick way to try the software first.</p>  Package manager Docker Kubernetes Manual download <p>Percona provides installation packages in <code>DEB</code> and <code>RPM</code> format for 64-bit Linux distributions. Find the full list of supported platforms and versions on the Percona Software and Platform Lifecycle page .</p> <p>If you are on Debian or Ubuntu, use <code>apt</code> for installation.</p> <p>If you are on Red Hat Enterprise Linux or compatible derivatives, use <code>yum</code>.</p> <p>Install via apt  Install via yum </p> <p>Get our image from Docker Hub and spin up a cluster on a Docker container for quick evaluation.</p> <p>Check below to get access to a detailed step-by-step guide.</p> <p>Run in Docker </p> <p>Percona Operator for Kubernetes is a controller introduced to simplify complex deployments that require meticulous and secure database expertise.</p> <p>Check below to get access to a detailed step-by-step guide.</p> <p>Get started with Percona Operator </p> <p>If you need to install Percona Distribution for PostgreSQL offline or as a non-superuser, check out the link below for a step-by-step guide and get access to the downloads directory.</p> <p>Note that for this scenario you must make sure that all dependencies are satisfied.</p> <p>Install from tarballs </p> <p></p>"},{"location":"installing.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"ldap.html","title":"LDAP Authentication","text":"<p>When a client application or a user that runs the client application connects to the database, it must identify themselves. The process of validating the client\u2019s identity and determining whether this client is permitted to access the database it has requested is called authentication. </p> <p>Percona Distribution for PortgreSQL supports several authentication methods , including the LDAP authentication . The use of LDAP is to provide a central place for authentication - meaning the LDAP server stores usernames and passwords and their resource permissions. </p> <p>The LDAP authentication in Percona Distribution for PortgreSQL is implemented the same way as in upstream PostgreSQL.</p> <p></p>"},{"location":"ldap.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"licensing.html","title":"Copyright and licensing information","text":"<p>Percona Distribution for PostgreSQL is licensed under the PostgreSQL license  and licenses of all components included in the Distribution.</p>"},{"location":"licensing.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Distribution for PostgreSQL documentation is (C)2009-2023 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License .</p> <p></p>"},{"location":"licensing.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"major-upgrade.html","title":"Upgrading Percona Distribution for PostgreSQL from 16 to 17","text":"<p>This document describes the in-place upgrade of Percona Distribution for PostgreSQL using the <code>pg_upgrade</code> tool.</p> <p>Important</p> <p>When running a major upgrade on RHEL 8 and compatible derivatives, consider the following:</p> <p>Percona Distribution for PostgreSQL 16.3, 15.7, 14.12, 13.15 and 12.18 include <code>llvm</code> packages 16.0.6, while its previous versions 16.2, 15.6, 14.11, 13.14, and 12.17 include <code>llvm</code> 12.0.1. Since <code>llvm</code> libraries differ and are not compatible, the direct major version upgrade from 15.6 to 16.3 may cause issues. </p> <p>To ensure a smooth upgrade path, follow these steps:</p> <ul> <li>Upgrade to the latest minor version within your current major version (e.g., from 15.6 to 15.7).</li> <li>Then, perform the major upgrade to your desired version (e.g., from 15.7 to 16.3).</li> </ul> <p>The in-place upgrade means installing a new version without removing the old version and keeping the data files on the server.</p> <p>See also</p> <p><code>pg_upgrade</code> Documentation </p> <p>Similar to installing, we recommend you to upgrade Percona Distribution for PostgreSQL from Percona repositories.</p> <p>Important</p> <p>A major upgrade is a risky process because of many changes between versions and issues that might occur during or after the upgrade. Therefore, make sure to back up your data first. The backup tools are out of scope of this document. Use the backup tool of your choice.</p> <p>The general in-place upgrade flow for Percona Distribution for PostgreSQL is the following:</p> <ol> <li> <p>Install new version of Percona Distribution for PostgreSQL packages.</p> </li> <li> <p>Stop the PostgreSQL service.</p> </li> <li> <p>Check the upgrade without modifying the data.</p> </li> <li> <p>Upgrade Percona Distribution for PostgreSQL.</p> </li> <li> <p>Start PostgreSQL service.</p> </li> <li> <p>Execute the  analyze_new_cluster.sh script to generate statistics so the system is usable.</p> </li> <li> <p>Delete old packages and configuration files.</p> </li> </ol> <p>The exact steps may differ depending on the package manager of your operating system.</p>"},{"location":"major-upgrade.html#on-debian-and-ubuntu-using-apt","title":"On Debian and Ubuntu using <code>apt</code>","text":"<p>Run all commands as root or via sudo:</p> <ol> <li> <p>Install Percona Distribution for PostgreSQL 17 packages.</p> <ul> <li> <p>Install percona-release . If you have installed it before, update it to the latest version</p> </li> <li> <p>Enable Percona repository:</p> </li> </ul> <pre><code>$ sudo percona-release setup ppg-17\n</code></pre> <ul> <li>Install Percona Distribution for PostgreSQL 17 package:</li> </ul> <pre><code>$ sudo apt install percona-postgresql-17\n</code></pre> </li> <li> <p>Stop the <code>postgresql</code> service.</p> <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> <p>This stops both Percona Distribution for PostgreSQL 16 and 17.</p> </li> <li> <p>Run the database upgrade.</p> <ul> <li>Log in as the <code>postgres</code> user.</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Change the current directory to the <code>tmp</code> directory where logs and some scripts will be recorded:</li> </ul> <pre><code>$ cd tmp/\n</code></pre> <ul> <li>Check the ability to upgrade Percona Distribution for PostgreSQL from 16 to 17:</li> </ul> <pre><code>$ /usr/lib/postgresql/17/bin/pg_upgrade \\\n--old-datadir=/var/lib/postgresql/16/main \\\n--new-datadir=/var/lib/postgresql/17/main  \\\n--old-bindir=/usr/lib/postgresql/16/bin  \\\n--new-bindir=/usr/lib/postgresql/17/bin  \\\n--old-options '-c config_file=/etc/postgresql/16/main/postgresql.conf' \\\n--new-options '-c config_file=/etc/postgresql/17/main/postgresql.conf' \\\n--check\n</code></pre> <p>The <code>--check</code> flag here instructs <code>pg_upgrade</code> to only check the upgrade without changing any data.</p> <p>Sample output</p> <pre><code>Performing Consistency Checks\n-----------------------------\nChecking cluster versions                                   ok\nChecking database user is the install user                  ok\nChecking database connection settings                       ok\nChecking for prepared transactions                          ok\nChecking for reg* data types in user tables                 ok\nChecking for contrib/isn with bigint-passing mismatch       ok\nChecking for tables WITH OIDS                               ok\nChecking for invalid \"sql_identifier\" user columns          ok\nChecking for presence of required libraries                 ok\nChecking database user is the install user                  ok\nChecking for prepared transactions                          ok\n\n*Clusters are compatible*\n</code></pre> <ul> <li>Upgrade the Percona Distribution for PostgreSQL</li> </ul> <pre><code>$ /usr/lib/postgresql/17/bin/pg_upgrade \\\n--old-datadir=/var/lib/postgresql/16/main \\\n--new-datadir=/var/lib/postgresql/17/main  \\\n--old-bindir=/usr/lib/postgresql/16/bin  \\\n--new-bindir=/usr/lib/postgresql/17/bin  \\\n--old-options '-c config_file=/etc/postgresql/16/main/postgresql.conf' \\\n--new-options '-c config_file=/etc/postgresql/17/main/postgresql.conf' \\\n--link\n</code></pre> <p>The  <code>--link</code> flag creates hard links to the files on the old version cluster so you don\u2019t need to copy data.</p> <p>If you don\u2019t wish to use the <code>--link</code> option, make sure that you have enough disk space to store 2 copies of files for both old version and new version clusters.</p> <ul> <li>Go back to the regular user:</li> </ul> <pre><code>$ exit\n</code></pre> <ul> <li>The Percona Distribution for PostgreSQL 16 uses the <code>5432</code> port while the Percona Distribution for PostgreSQL 17 is set up to use the <code>5433</code> port by default. To start the Percona Distribution for PostgreSQL 17, swap ports in the configuration files of both versions.</li> </ul> <pre><code>$ sudo vim /etc/postgresql/17/main/postgresql.conf\n$ port = 5433 # Change to 5432 here\n$ sudo vim /etc/postgresql/16/main/postgresql.conf\n$ port = 5432 # Change to 5433 here\n</code></pre> </li> <li> <p>Start the <code>postgreqsl</code> service.</p> <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> </li> <li> <p>Check the <code>postgresql</code> version.</p> <ul> <li>Log in as a postgres user</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Check the database version</li> </ul> <pre><code>$ psql -c \"SELECT version();\"\n</code></pre> </li> <li> <p>After the upgrade, the Optimizer statistics are not transferred to the new cluster. Run the <code>vaccumdb</code> command to analyze the new cluster:</p> <pre><code>$ /usr/lib/postgresql/17/bin/vacuumdb --all --analyze-in-stages\n</code></pre> </li> <li> <p>Delete the old cluster\u2019s data files:</p> <pre><code>$ ./delete_old_cluster.sh\n$ sudo rm -rf /etc/postgresql/15/main\n$ #Logout\n$ exit\n</code></pre> </li> </ol>"},{"location":"major-upgrade.html#on-red-hat-enterprise-linux-and-centos-using-yum","title":"On Red Hat Enterprise Linux and CentOS using <code>yum</code>","text":"<p>Run all commands as root or via sudo:</p> <ol> <li> <p>Install Percona Distribution for PostgreSQL 17 packages</p> <ul> <li> <p>Install percona-release </p> </li> <li> <p>Enable Percona repository:</p> </li> </ul> <pre><code>$ sudo percona-release setup ppg-17\n</code></pre> <ul> <li>Install Percona Distribution for PostgreSQL 17:</li> </ul> <pre><code>$ sudo yum install percona-postgresql17-server\n</code></pre> </li> <li> <p>Set up Percona Distribution for PostgreSQL 17 cluster</p> </li> <li> <p>Log is as the postgres user</p> <pre><code>$ sudo su postgres\n</code></pre> </li> <li> <p>Set up locale settings</p> <pre><code>export LC_ALL=\"en_US.UTF-8\"\nexport LC_CTYPE=\"en_US.UTF-8\"\n</code></pre> </li> <li> <p>Initialize cluster with the new data directory</p> <pre><code>$ /usr/pgsql-17/bin/initdb -D /var/lib/pgsql/17/data\n</code></pre> </li> <li> <p>Stop the <code>postgresql</code> 16 service</p> <pre><code>$ systemctl stop postgresql-16\n</code></pre> </li> <li> <p>Run the database upgrade.</p> <ul> <li>Log in as the <code>postgres</code> user</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Check the ability to upgrade Percona Distribution for PostgreSQL from 16 to 17:</li> </ul> <pre><code>$ /usr/pgsql-17/bin/pg_upgrade \\\n--old-bindir /usr/pgsql-16/bin \\\n--new-bindir /usr/pgsql-17/bin  \\\n--old-datadir /var/lib/pgsql/16/data \\\n--new-datadir /var/lib/pgsql/17/data \\\n--check\n</code></pre> <p>The <code>--check</code> flag here instructs <code>pg_upgrade</code> to only check the upgrade without changing any data.</p> <p>Sample output</p> <pre><code>Performing Consistency Checks\n-----------------------------\nChecking cluster versions                                   ok\nChecking database user is the install user                  ok\nChecking database connection settings                       ok\nChecking for prepared transactions                          ok\nChecking for reg* data types in user tables                 ok\nChecking for contrib/isn with bigint-passing mismatch       ok\nChecking for tables WITH OIDS                               ok\nChecking for invalid \"sql_identifier\" user columns          ok\nChecking for presence of required libraries                 ok\nChecking database user is the install user                  ok\nChecking for prepared transactions                          ok\n\n*Clusters are compatible*\n</code></pre> <ul> <li>Upgrade the Percona Distribution for PostgreSQL</li> </ul> <pre><code>$ /usr/pgsql-17/bin/pg_upgrade \\\n--old-bindir /usr/pgsql-16/bin \\\n--new-bindir /usr/pgsql-17/bin  \\\n--old-datadir /var/lib/pgsql/16/data \\\n--new-datadir /var/lib/pgsql/17/data \\\n--link \n</code></pre> <p>The  <code>--link</code> flag creates hard links to the files on the old version cluster so you don\u2019t need to copy data.    If you don\u2019t wish to use the <code>--link</code> option, make sure that you have enough disk space to store 2 copies of files for both old version and new version clusters.</p> </li> <li> <p>Start the <code>postgresql</code> 17 service.</p> <pre><code>$ systemctl start postgresql-17\n</code></pre> </li> <li> <p>Check postgresql status</p> <pre><code>$ systemctl status postgresql-17\n</code></pre> </li> <li> <p>After the upgrade, the Optimizer statistics are not transferred to the new cluster. Run the <code>vaccumdb</code> command to analyze the new cluster:</p> <ul> <li>Log in as the postgres user</li> </ul> <pre><code>$ sudo su postgres\n</code></pre> <ul> <li>Run the script to analyze the new cluster:</li> </ul> <pre><code>$ /usr/pgsql-17/bin/vacuumdb --all --analyze-in-stages\n</code></pre> </li> <li> <p>Delete Percona Distribution for PostgreSQL 16 configuration files</p> <pre><code>$ ./delete_old_cluster.sh\n</code></pre> </li> <li> <p>Delete Percona Distribution old data files</p> <pre><code>$ rm -rf /var/lib/pgsql/16/data\n</code></pre> </li> </ol> <p></p>"},{"location":"major-upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"migration.html","title":"Migrate from PostgreSQL to Percona Distribution for PostgreSQL","text":"<p>Percona Distribution for PostgreSQL includes the PostgreSQL database and additional extensions that have been selected to cover the needs of the enterprise and are guaranteed to work together. Percona Distribution for PostgreSQL is available as a software collection that is easy to deploy.</p> <p>We encourage users to migrate from their PostgreSQL deployments based on community binaries to Percona Distribution for PostgreSQL. This document provides the migration instructions. </p> <p>Depending on your business requirements, you may migrate to Percona Distribution for PostgreSQL either on the same server or onto a different server. </p>"},{"location":"migration.html#migrate-on-the-same-server","title":"Migrate on the same server","text":"On Debian and Ubuntu Linux On RHEL and derivatives <p>To ensure that your data is safe during the migration, we recommend to make a backup of your data and all configuration files (such as <code>pg_hba.conf</code>, <code>postgresql.conf</code>, <code>postgresql.auto.conf</code>) using the tool of your choice. The backup process is out of scope of this document. You can use <code>pg_dumpall</code> or other tools of your choice. For more information, see the blog post PostgreSQL Upgrade Using pg_dumpall by Avinash Vallarapu, Fernando Laudares Camargos, Jobin Augustine and Nickolay Ihalainen.</p> <p>Run all commands as root or via sudo:</p> <ol> <li> <p>Stop the <code>postgresql</code> server   </p> <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> </li> <li> <p>Remove community packages</p> <pre><code>$ sudo apt-get --purge remove postgresql\n</code></pre> </li> <li> <p>Install percona-release </p> </li> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages</p> </li> <li>(Optional) Restore the data from the backup.</li> <li> <p>Start the <code>postgresql</code> service. The installation process starts and initializes the default cluster automatically. You can check its status with: </p> <pre><code>$ sudo systemctl status postgresql\n</code></pre> <p>If <code>postresql</code> service is not started, start it manually:</p> <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> </li> </ol> <p>To ensure that your data is safe during the migration, we recommend to make a backup of your data and all configuration files (such as <code>pg_hba.conf</code>, <code>postgresql.conf</code>, <code>postgresql.auto.conf</code>) using the tool of your choice. The backup process is out of scope of this document. You can use <code>pg_dumpall</code> or other tools of your choice. </p> <p>Run all commands as root or via sudo:</p> <ol> <li> <p>Stop the <code>postgresql</code> server   </p> <pre><code>$ sudo systemctl stop postgresql-17\n</code></pre> </li> <li> <p>Remove community packages</p> <pre><code>$ sudo yum remove postgresql\n</code></pre> </li> <li> <p>Install percona-release </p> </li> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages</p> </li> <li>(Optional) Restore the data from the backup.</li> <li> <p>Start the <code>postgresql</code> service</p> <pre><code>$ sudo systemctl start postgresql-17\n</code></pre> </li> </ol>"},{"location":"migration.html#migrate-on-a-different-server","title":"Migrate on a different server","text":"<p>In this scenario, we will refer to the server with PostgreSQL Community as the \u201csource\u201d and to the server with Percona Distribution for PostgreSQL as the \u201ctarget\u201d.</p> <p>To migrate from PostgreSQL Community to Percona Distribution for PostgreSQL on a different server, do the following:</p> <p>On the source server:</p> <ol> <li>Back up your data and all configuration files (such as <code>pg_hba.conf</code>, <code>postgresql.conf</code>, <code>postgresql.auto.conf</code>) using the tool of your choice.</li> <li> <p>Stop the <code>postgresql</code> service</p>  On Debian and Ubuntu On RHEL and derivatives <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> <pre><code>$ sudo systemctl stop postgresql-17\n</code></pre> </li> <li> <p>Optionally, remove PostgreSQL Community packages </p> </li> </ol> <p>On the target server:</p> <ol> <li>Install percona-release  </li> <li> <p>Enable the repository</p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages on the target server.</p> </li> <li>Restore the data from the backup</li> <li> <p>Start <code>postgresql</code> service</p>  On Debian and Ubuntu On RHEL and derivatives <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> <pre><code>$ sudo systemctl start postgresql-17\n</code></pre> </li> </ol> <p></p>"},{"location":"migration.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"minor-upgrade.html","title":"Minor Upgrade of Percona Distribution for PostgreSQL","text":"<p>Minor releases of PostgreSQL include bug fixes and feature enhancements. We recommend that you keep your Percona Distribution for PostgreSQL updated to the latest minor version.</p> <p>Though minor upgrades do not change the behavior, we recommend you to back up your data first, in order to be on the safe side.</p> <p>Minor upgrade of Percona Distribution for PostgreSQL includes the following steps:</p> <ol> <li> <p>Stop the <code>postgresql</code> cluster;</p> </li> <li> <p>Update <code>percona-release</code></p> </li> <li> <p>Install new version packages;</p> </li> <li> <p>Restart the <code>postgresql</code> cluster.</p> </li> </ol> <p>Note</p> <p>These steps apply if you installed Percona Distribution for PostgreSQL from the Major Release repository. In this case, you are always upgraded to the latest available release.</p> <p>If you installed Percona Distribution for PostgreSQL from the Minor Release repository, you will need to enable a new version repository to upgrade.</p> <p>For more information about Percona repositories, refer to Installing Percona Distribution for PostgreSQL.</p> <p>Before the upgrade, update the <code>percona-release</code>  utility to the latest version. This is required to install the new version packages of Percona Distribution for PostgreSQL. </p> <p>Run all commands as root or via sudo:</p> <ol> <li> <p>Stop the <code>postgresql</code> service.</p>  On Debian / Ubuntu On Red Hat Enterprise Linux / derivatives <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> <pre><code>$ sudo systemctl stop postgresql-16\n</code></pre> </li> <li> <p>Update <code>percona-release</code> to the latest version.</p> </li> <li> <p>Install new version packages. See Installing Percona Distribution for PostgreSQL.</p> </li> <li> <p>Restart the <code>postgresql</code> service.</p>  On Debian / Ubuntu On Red Hat Enterprise Linux / derivatives <pre><code>$ sudo systemctl start postgresql.service\n</code></pre> <pre><code>$ sudo systemctl start postgresql-16\n</code></pre> </li> </ol> <p>If you wish to upgrade Percona Distribution for PostgreSQL to the major version, refer to Upgrading Percona Distribution for PostgreSQL from 15 to 16.</p> <p></p>"},{"location":"minor-upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"percona-ext.html","title":"Percona-authored extensions","text":""},{"location":"percona-ext.html#pg_stat_monitor","title":"pg_stat_monitor","text":"<p>A query performance monitoring tool for PostgreSQL that brings more insight and details around query performance, planning statistics and metadata. It improves observability, enabling users to debug and tune query performance with precision.</p> <p>pg_stat_monitor documentation </p>"},{"location":"percona-ext.html#pg_tde","title":"pg_tde","text":"<p>An open-source extension designed to enhance PostgreSQL\u2019s security by encrypting data files on disk. The encryption is transparent for users allowing them to access and manipulate the data and not to worry about the encryption process.</p> <p>pg_tde documentation </p>"},{"location":"percona-ext.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"postgresql-server.html","title":"Percona Server for PostgreSQL","text":"<p>Percona Server for PostgreSQL is a binary-compatible, open source drop-in replacement for PostgreSQL 17. It introduces additional features to the upstream server, including:</p> <ul> <li>Storage Manager (SMGR) API Exposure: Allows PostgreSQL extensions to integrate custom storage managers. This change was inspired by the patchset introduced to the community.</li> <li>WAL Read/Write API Exposure to hook into WAL read and write functions.</li> </ul> <p>These modifications have no impact on existing use cases and operation of PostgreSQL. They are required to enable additional encryption capabilities such as index-level and Write-Ahead Logging (WAL) encryption of indexes through the <code>pg_tde</code>  extension. These encryption features provided by the <code>pg_tde</code> are still under active development and are planned for future releases.</p> <p>Percona Server and upstream PostgreSQL function identically enabling you to migrate from one to another. </p> <p>Get started </p> <p></p>"},{"location":"postgresql-server.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"release-notes-v17.0.html","title":"Percona Distribution for PostgreSQL 17.0.1 (2024-10-03)","text":"<p>Installation Upgrade</p> <p>We are pleased to announce the launch of Percona Distribution for PostgreSQL 17.0.1 - a solution with the collection of tools from PostgreSQL community that are tested to work together and serve to assist you in deploying and managing PostgreSQL. The aim of Percona Distribution for PostgreSQL is to address the operational issues like High-Availability, Disaster Recovery, Security, Observability, Spatial data handling, Performance and Scalability and others that enterprises are facing.</p> <p>This release of Percona Distribution for PostgreSQL is based on Percona Server for PostgreSQL 17.0.1 - a binary compatible, open source drop in replacement of PostgreSQL Community 17.0 . </p> <p>Both Percona Server for PostgreSQL and PostgreSQL Community function identically enabling you to migrate from one to another. </p> <p>Percona Server for PostgreSQL 17.0.1 has the extra digit in version which represents Percona version number. </p> <p>To check what software you\u2019re running, run the following SQL query:</p> <pre><code>SELECT version();\n</code></pre> Sample output <pre><code> version\n----------------------------------------------------------------------------------------------------------------------------------------------\n PostgreSQL 17.0 - Percona Server for PostgreSQL 17.0.1\n</code></pre> <p>Alternatively, you can pass the <code>--version</code> flag when you establish the <code>psql</code> session:</p> <pre><code>$ psql --version\n</code></pre> Sample output <pre><code>psql (PostgreSQL) 17.0 - Percona Server for PostgreSQL 17.0.1\n</code></pre>"},{"location":"release-notes-v17.0.html#release-highlights","title":"Release Highlights","text":""},{"location":"release-notes-v17.0.html#percona-server-for-postgresql-improvements","title":"Percona Server for PostgreSQL improvements","text":"<ul> <li>Exposed Storage Manager API to enable PostgreSQL extensions to hook in custom storage managers.</li> <li>Extended Write-Ahead Log (WAL) API to hook into WAL read and write functions.</li> </ul>"},{"location":"release-notes-v17.0.html#postgresql-community-improvements","title":"PostgreSQL Community improvements","text":"<p>PostgreSQL Community 17 features a lot of new functionalities and enhancements to performance, replication, monitoring, developer experience and more. Among them are the following:</p>"},{"location":"release-notes-v17.0.html#incremental-base-backups","title":"Incremental base backups","text":"<p>Save time and storage space with the ability to back up only the changes since the last backup using <code>pg_basebackup</code> with the <code>--incremental</code> option. The new <code>pg_combinebackup</code> tool allows manipulation of base and incremental file system backups for recovery.</p> <p>Note that you still require a full backup to derive the increments from and to be used during recovery.</p> <p>This feature is especially beneficial for organizations with large data sets where a full backup is a time-consuming and resource-intensive operation.  </p>"},{"location":"release-notes-v17.0.html#performance-improvements","title":"Performance improvements","text":"<ul> <li>Vacuum Process Enhancements: The VACUUM process, responsible for reclaiming storage, now has a new internal data structure, reducing memory usage by up to 20x and improving overall performance.</li> <li>The new stream I/O interface can enhance performance during sequential scans and when running the <code>ANALYZE</code> command.</li> <li>Added support for parallel index builds for <code>BRIN</code> indexes, which can significantly speed up index creation. Additionally, this release significantly improves execution time of queries that use the <code>IN</code> clause with a B-tree index.</li> </ul>"},{"location":"release-notes-v17.0.html#developer-experience","title":"Developer experience","text":"<ul> <li>Developers can now transform JSON objects into a standard database table and convert JSON values to different data types directly within SQL statements. This adds flexibility when working with multiple data formats.</li> <li>Run bulk upload and export data from PostgreSQL up to 2x faster with improved <code>COPY</code> performance. In addition, use the <code>ON_ERROR</code> option to proceed with the copy  operation even if there is an error inserting a row.</li> <li>The RETURNING clause added to the MERGE command enables developers to retrieve and return the rows modified by the MERGE operation in a single step, reducing the need for additional queries and simplifying complex workflows.</li> </ul>"},{"location":"release-notes-v17.0.html#replication-improvements","title":"Replication improvements","text":"<ul> <li>Gain more control for managing PostgreSQL databases in high availability environments with the ability to continue logical replication from a new primary node after the failover. </li> <li>Track inactive and invalid replication slots in the <code>pg_replication_slots</code> view. With the  <code>inactive_since</code> and <code>invalidation_reason</code> columns  added to this view, you can get insights when a slot became inactive as well as the reason for an invalid slot.</li> <li>Convert a physical replica into a logical one using the new <code>pg_createsubscriber</code> command-line tool</li> </ul>"},{"location":"release-notes-v17.0.html#security-improvements","title":"Security improvements","text":"<ul> <li>Enable users to perform maintenance operations such as ANALYZE, VACUUM, REINDEX, CLUSTER, REFRESH MATERIALIZED VIEW, and LOCK TABLE on all relations by assigning the new predefined <code>pg_maintain</code> role to them. In addition, the <code>search_path</code> is safe for maintenance operations like VACUUM, ANALYZE, CLUSTER, REFRESH MATERIALIZED VIEW and INDEX.</li> </ul>"},{"location":"release-notes-v17.0.html#monitoring-improvements","title":"Monitoring improvements","text":"<ul> <li> <p>Get deeper insights about query plans and execution with the new options for the EXPLAIN command: </p> </li> <li> <p>SERIALIZE shows the amount of time it takes to convert data for network transmission</p> </li> <li> <p>MEMORY reports optimizer memory usage </p> </li> <li> <p>Learn about why an active session is waiting using the <code>pg_stat_activity</code> and new <code>pg_wait_events</code> views</p> </li> </ul> <p>See also</p> <ul> <li>PostgreSQL 17 release announcement </li> <li>PostgreSQL 17 release notes </li> <li>Percona Blog: The Powerful Features Released in PostgreSQL 17 Beta 2</li> </ul>"},{"location":"release-notes-v17.0.html#join-percona-squad","title":"Join Percona Squad","text":"<p>Participate in monthly SWAG raffles, get an early access to new product features and invite-only \u201cask me anything\u201d sessions with database performance experts. Interested? Fill in the form</p>"},{"location":"release-notes-v17.0.html#known-limitations","title":"Known Limitations","text":"<p>Percona Monitoring and Management (PMM) 2.43.1 is not compatible with <code>pg_stat_monitor</code> 2.1.0 to monitor PostgreSQL 17. However, PMM is compatible with <code>pg_stat_monitor</code> 2.1.0 for monitoring of PostgreSQL 16 and previous versions. </p> <p>The support for PostgreSQL 17 will be available in the future PMM release.</p> <p>The following is the list of extensions available in Percona Distribution for PostgreSQL.</p> Extension Version Description etcd 3.5.16 A distributed, reliable key-value store for setting up high available Patroni clusters HAProxy  2.8.11 a high-availability and load-balancing solution Patroni  4.0.2 a HA (High Availability) solution for PostgreSQL PgAudit  17.0 provides detailed session or object audit logging via the standard logging facility provided by PostgreSQL pgAudit set_user  4.1.0 provides an additional layer of logging and control when unprivileged users must escalate themselves to superusers or object owner roles in order to perform needed maintenance tasks. pgBackRest  2.53.1 a backup and restore solution for PostgreSQL pgBadger  12.4 a fast PostgreSQL Log Analyzer. PgBouncer  1.23.1 a lightweight connection pooler for PostgreSQL pg_gather  v27 an SQL script for running the diagnostics of the health of PostgreSQL cluster pgpool2  4.5.4 a middleware between PostgreSQL server and client for high availability, connection pooling and load balancing. pg_repack  1.5.1 rebuilds PostgreSQL database objects pg_stat_monitor  2.1.0 collects and aggregates statistics for PostgreSQL and provides histogram information. PostGIS  3.3.7 a spatial extension for PostgreSQL. PostgreSQL Common  264 PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. wal2json  2.6 a PostgreSQL logical decoding JSON output plugin <p>Percona Distribution for PostgreSQL on Red Hat Enterprise Linux 8 and compatible derivatives also includes the following packages:</p> <ul> <li><code>llvm</code> 17.0.6 packages. This fixes compatibility issues with LLVM from upstream.</li> <li>supplemental <code>python3-etcd</code> packages, which can be used for setting up Patroni clusters. </li> </ul> <p>Percona Distribution for PostgreSQL is also shipped with the libpq library. It contains \u201ca set of library functions that allow client programs to pass queries to the PostgreSQL backend server and to receive the results of these queries.\u201d </p> <p></p>"},{"location":"release-notes-v17.0.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"release-notes.html","title":"Percona Distribution for PostgreSQL release notes","text":"<ul> <li>Percona Distribution for PostgreSQL 16 (2023-09-19)</li> </ul>"},{"location":"release-notes.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"repo-overview.html","title":"Repositories overview","text":"<p>Percona provides two repositories for Percona Distribution for PostgreSQL. </p> Major release repository Minor release repository Major Release repository (<code>ppg-17</code>) it includes the latest version packages. Whenever a package is updated, the package manager of your operating system detects that and prompts you to update. As long as you update all Distribution packages at the same time, you can ensure that the packages you\u2019re using have been tested and verified by Percona.  We recommend installing Percona Distribution for PostgreSQL from the Major Release repository Minor Release repository includes a particular minor release of the database and all of the packages that were tested and verified to work with that minor release (e.g. <code>ppg-17.0</code>). You may choose to install Percona Distribution for PostgreSQL from the Minor Release repository if you have decided to standardize on a particular release which has passed rigorous testing procedures and which has been verified to work with your applications. This allows you to deploy to a new host and ensure that you\u2019ll be using the same version of all the Distribution packages, even if newer releases exist in other repositories.   The disadvantage of using a Minor Release repository is that you are locked in this particular release. When potentially critical fixes are released in a later minor version of the database, you will not be prompted for an upgrade by the package manager of your operating system. You would need to change the configured repository in order to install the upgrade."},{"location":"repo-overview.html#repository-contents","title":"Repository contents","text":"<p>Percona Distribution for PostgreSQL provides individual packages for its components. It also includes two meta-packages: <code>percona-ppg-server</code> and <code>percona-ppg-server-ha</code>.</p> <p>Using a meta-package, you can install all components it contains in one go.</p>"},{"location":"repo-overview.html#percona-ppg-server","title":"<code>percona-ppg-server</code>","text":"Package name on Debian/UbuntuPackage name on RHEL/derivatives <p><code>percona-ppg-server-17</code></p> <p><code>percona-ppg-server17</code></p> <p>The <code>percona-ppg-server</code> meta-package installs the PostgreSQL server with the following packages:</p> Package contents Description <code>percona-postgresql17-server</code> The PostgreSQL server package. <code>percona-postgresql-common</code> PostgreSQL database-cluster manager. It provides a structure under which multiple versions of PostgreSQL may be installed and/or multiple clusters maintained at one time. <code>percona-postgresql17-contrib</code> A collection of additional PostgreSQLcontrib extensions <code>percona-pg-stat-monitor17</code> A Query Performance Monitoring tool for PostgreSQL. <code>percona-pgaudit17</code> Provides detailed session or object audit logging via the standard PostgreSQL logging facility. <code>percona-pg_repack17</code> rebuilds PostgreSQL database objects. <code>percona-wal2json17</code> a PostgreSQL logical decoding JSON output plugin."},{"location":"repo-overview.html#percona-ppg-server-ha","title":"<code>percona-ppg-server-ha</code>","text":"Package name on Debian/UbuntuPackage name on RHEL/derivatives <p><code>percona-ppg-server-ha-17</code></p> <p><code>percona-ppg-server-17</code></p> <p>The <code>percona-ppg-server-ha</code> meta-package installs high-availability components that are recommended by Percona:</p> Package contents Description <code>percona-patroni</code> A high-availability solution for PostgreSQL. <code>percona-haproxy</code> A high-availability and load-balancing solution <code>etcd</code> A consistent, distributed key-value store <code>python3-python-etcd</code> A Python client for etcd <p></p>"},{"location":"repo-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions.html","title":"Percona Distribution for PostgreSQL solutions","text":"<p>Find the right solution to help you achieve your organization\u2019s goals.</p> <p></p>"},{"location":"solutions.html#high-availability","title":"High availability","text":"<p>Check out how you can ensure continuous access to your database.</p> <p>High availability </p>"},{"location":"solutions.html#spatial-data-handling","title":"Spatial data handling","text":"<p>Dealing with spatial data? Learn how you can store and manipulate it.</p> <p>Spatial data handling </p>"},{"location":"solutions.html#backup-and-disaster-recovery","title":"Backup and disaster recovery","text":"<p>Protect your database against accidental or malicious data loss or data corruption. </p> <p>Backup and disaster recovery </p>"},{"location":"solutions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"tarball.html","title":"Install Percona Distribiution for PostgreSQL from binary tarballs","text":"<p>You can find the binary tarballs on the Percona website. Select the desired version from a version dropdown and All from the Select Platform dropdown.</p> <p>There are the following tarballs available both for x86_64 and ARM64 architectures: </p> <ul> <li>percona-postgresql-17.0-ssl1.1-linux-aarch64.tar.gz  - for operating systems on ARM64 architecture that run OpenSSL version 1.x</li> <li>percona-postgresql-17.0-ssl1.1-linux-x86_64.tar.gz  - for operating systems on x86_64 architecture that run OpenSSL version 1.x</li> <li>percona-postgresql-17.0-ssl3-linux-aarch64.tar.gz - for operating systems on ARM64 architecture that run OpenSSL version 3.x</li> <li>percona-postgresql-17.0-ssl3-linux-x86_64.tar.gz - for operating systems on x86_64 architecture that run OpenSSL version 3.x</li> </ul> <p>To check what OpenSSL version you have, run the following command: </p> <pre><code>$ openssl version\n</code></pre>"},{"location":"tarball.html#tarball-contents","title":"Tarball contents","text":"<p>The tarballs include the following components:</p> Component Description percona-postgresql17 The latest version of PostgreSQL server and the following extensions:  - <code>pgaudit</code>  - <code>pgAudit_set_user</code>  - <code>pg_repack</code>  - <code>pg_stat_monitor</code>  - <code>pg_gather</code>  - <code>wal2json</code>  -  the set of contrib extensions percona-haproxy A high-availability solution and load-balancing solution percona-patroni A high-availability solution for PostgreSQL percona-pgbackrest A backup and restore tool percona-pgbadger PostgreSQL log analyzer with fully detailed reports and graphs percona-pgbouncer Lightweight connection pooler for PostgreSQL percona-pgpool-II A middleware between PostgreSQL server and client for high availability, connection pooling and load balancing percona-perl A Perl module required to create the <code>plperl</code> extension - a procedural language handler for PostgreSQL that allows writing functions in the Perl programming language percona-python3 A Python3 module required to create <code>plpython</code> extension - a procedural language handler for PostgreSQL that allows writing functions in the Python programming language. Python is also required by Patroni percona-tcl Tcl development libraries required to create the <code>pltcl</code> extension - a loadable procedural language for the PostgreSQL database system that enables the creation of functions and trigger procedures in the Tcl language percona-etcd A key-value distributed store that stores the state of the PostgreSQL cluster"},{"location":"tarball.html#preconditions","title":"Preconditions","text":"Debian and UbuntuRHEL and derivatives <ol> <li>Uninstall the upstream PostgreSQL package. </li> <li> <p>Create the user to own the PostgreSQL process. For example, <code>mypguser</code>. Run the following command:</p> <pre><code>$ sudo useradd -m mypguser\n</code></pre> <p>Set the password for the user:</p> <pre><code>$ sudo passwd mypguser\n</code></pre> </li> </ol> <p>Create the user to own the PostgreSQL process. For example, <code>mypguser</code>, Run the following command: </p> <pre><code>$ sudo useradd mypguser -m \n</code></pre> <p>Set the password for the user:</p> <pre><code>$ sudo passwd mypguser\n</code></pre>"},{"location":"tarball.html#procedure","title":"Procedure","text":"<p>The steps below install the tarballs for OpenSSL 3.x on x86_64 architecture. Use another tarball if your operating system has OpenSSL version 1.x and / or has the ARM64 architecture.</p> <ol> <li> <p>Create the directory where you will store the binaries. For example, <code>/opt/pgdistro</code></p> </li> <li> <p>Grant access to this directory for the <code>mypguser</code> user.</p> <pre><code>$ sudo chown mypguser:mypguser /opt/pgdistro/\n</code></pre> </li> <li> <p>Fetch the binary tarball. </p> <pre><code>$ wget https://downloads.percona.com/downloads/postgresql-distribution-17/17.0/binary/tarball/percona-postgresql-17.0-ssl3-linux-x86_64.tar.gz\n</code></pre> </li> <li> <p>Extract the tarball to the directory for binaries that you created on step 1.</p> <pre><code>$ sudo tar -xfv percona-postgresql-17.0-ssl3-linux-x86_64.tar.gz -C /opt/pgdistro/\n</code></pre> </li> <li> <p>If you extracted the tarball in a directory other than <code>/opt</code>, copy <code>percona-python3</code>, <code>percona-tcl</code> and <code>percona-perl</code> to the <code>/opt</code> directory. This is required for the correct run of libraries that require those modules. </p> <pre><code>$ sudo cp &lt;path_to&gt;/percona-perl &lt;path_to&gt;/percona-python3 &lt;path_to&gt;/percona-tcl /opt/\n</code></pre> </li> <li> <p>Add the location of the binaries to the PATH variable:</p> <pre><code>$ export PATH=:/opt/pgdistro/percona-haproxy/sbin/:/opt/pgdistro/percona-patroni/bin/:/opt/pgdistro/percona-pgbackrest/bin/:/opt/pgdistro/percona-pgbadger/:/opt/pgdistro/percona-pgbouncer/bin/:/opt/pgdistro/percona-pgpool-II/bin/:/opt/pgdistro/percona-postgresql17/bin/:/opt/pgdistro/percona-etcd/bin/:/opt/percona-perl/bin/:/opt/percona-tcl/bin/:/opt/percona-python3/bin/:$PATH\n</code></pre> </li> <li> <p>Create the data directory for PostgreSQL server. For example, <code>/usr/local/pgsql/data</code>.</p> </li> <li> <p>Grant access to this directory for the <code>mypguser</code> user.</p> <pre><code>$ sudo chown mypguser:mypguser /usr/local/pgsql/data\n</code></pre> </li> <li> <p>Switch to the user that owns the Postgres process. In our example, <code>mypguser</code>:</p> <pre><code>$ su - mypguser\n</code></pre> </li> <li> <p>Initiate the PostgreSQL data directory:</p> <pre><code>$ /opt/pgdistro/percona-postgresql17/bin/initdb -D /usr/local/pgsql/data\n</code></pre> Sample output <pre><code>Success. You can now start the database server using:\n\n/opt/pgdistro/percona-postgresql17/bin/pg_ctl -D /usr/local/pgsql/data -l logfile start\n</code></pre> </li> <li> <p>Start the PostgreSQL server:</p> <pre><code>$ /opt/pgdistro/percona-postgresql17/bin/pg_ctl -D /usr/local/pgsql/data -l logfile start\n</code></pre> Sample output <pre><code>waiting for server to start.... done\nserver started\n</code></pre> </li> <li> <p>Connect to <code>psql</code></p> <pre><code>$ /opt/pgdistro/percona-postgresql17/bin/psql -d postgres\n</code></pre> Sample output <pre><code>psql (17.0.1 (Percona Server for PostgreSQL), server 17.0.1 (Percona Server for PostgreSQL))\nType \"help\" for help.\n\npostgres=#\n</code></pre> </li> </ol>"},{"location":"tarball.html#start-the-components","title":"Start the components","text":"<p>After you unpacked the tarball and added the location of the components\u2019 binaries to the <code>$PATH</code> variable, the components are available for use. You can invoke a component by running its command-line tool.</p> <p>For example, to check HAProxy version, type:</p> <pre><code>$ haproxy version\n</code></pre> <p>Some components require additional setup. Check the Enabling extensions page for details.</p> <p></p>"},{"location":"tarball.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"telemetry.html","title":"Telemetry and data collection","text":"<p>Percona collects usage data to improve its software. The telemetry feature helps us identify popular features, detect problems, and plan future improvements. All collected data is anonymized so that it can\u2019t be traced back to any individual user.</p> <p>Currently, telemetry is added only to the Percona packages and to Docker images. It is enabled by default so you must be running the latest version of <code>percona-release</code> to install Percona Distribution for PostgreSQL packages or update it to the latest version.</p>"},{"location":"telemetry.html#what-information-is-collected","title":"What information is collected","text":"<p>Telemetry collects the following information:</p> <ul> <li>The information about the installation environment when you install the software.</li> <li>The information about the operating system such as name, architecture, the list of Percona packages. See more in the Telemetry Agent section.</li> <li>The metrics from the database instance. See more in the percona_pg_telemetry section.</li> </ul>"},{"location":"telemetry.html#what-is-not-collected","title":"What is NOT collected","text":"<p>Percona protects your privacy and doesn\u2019t collect any personal information about you like database names, user names or credentials or any user-entered values. </p> <p>All collected data is anonymous, meaning it can\u2019t be traced back to any individual user. To learn more about how Percona handles your data, read the Percona Privacy statement.</p> <p>You control whether to share this information. Participation in this program is completely voluntary. If don\u2019t want to share anonymous data, you can disable telemetry. </p>"},{"location":"telemetry.html#why-telemetry-matters","title":"Why telemetry matters","text":"<p>Benefits for Percona:</p> Advantages Description See how people use your software Telemetry collects anonymous data on how users interact with our software. This tells developers which features are popular, which ones are confusing, and if anything is causing crashes. Identify issues early Telemetry can catch bugs or performance problems before they become widespread. <p>Benefits for users in the long run:</p> Advantages Description Faster bug fixes With telemetry data, developers can pinpoint issues affecting specific use cases and prioritize fixing them quickly. Improved features Telemetry helps developers understand user needs and preferences. This allows them to focus on features that will be genuinely useful and improve your overall experience. Improved user experience By identifying and resolving issues early, telemetry helps create a more stable and reliable software experience for everyone."},{"location":"telemetry.html#telemetry-components","title":"Telemetry components","text":"<p>Percona collects information using the following components:</p> <ul> <li> <p>Telemetry script that sends the information about the software and the environment where it is installed. This information is collected only once during the installation.</p> </li> <li> <p>The <code>percona_pg_telemetry</code> extension collects the necessary metrics directly from the database and stores them in a Metrics File.</p> </li> <li> <p>The Metrics File stores the metrics and is a standalone file located on the database host\u2019s file system.</p> </li> <li> <p>The Telemetry Agent is an independent process running on your database host\u2019s operating system and carries out the following tasks:</p> <ul> <li> <p>Collects OS-level metrics</p> </li> <li> <p>Reads the Metrics File, adds the OS-level metrics</p> </li> <li> <p>Sends the full set of metrics to the Percona Platform</p> </li> <li> <p>Collects the list of installed Percona packages using the local package manager</p> </li> </ul> </li> </ul> <p>The telemetry also uses the Percona Platform with the following components:</p> <ul> <li> <p>Telemetry Service - offers an API endpoint for sending telemetry. The service handles incoming requests. This service saves the data into Telemetry Storage.</p> </li> <li> <p>Telemetry Storage - stores all telemetry data for the long term.</p> </li> </ul>"},{"location":"telemetry.html#percona_pg_telemetry","title":"<code>percona_pg_telemetry</code>","text":"<p><code>percona_pg_telemetry</code> is an extension to collect telemetry data in PostgreSQL. It is added to Percona Distribution for PostgreSQL and is automatically loaded when you install a PostgreSQL server.</p> <p><code>percona_pg_telemetry</code> collects metrics from the database instance daily to the Metrics File. It creates a new Metrics File for each collection. You can find the Metrics File in its location to inspect what data is collected. </p> <p>Before generating a new file, the <code>percona_pg_telemetry</code> deletes the Metrics Files that are older than seven days. This process ensures that only the most recent week\u2019s data is maintained.</p> <p>The <code>percona_pg_telemetry</code> extension creates a file in the local file system using a timestamp and a randomly generated token as the name with a <code>.json</code> extension.</p>"},{"location":"telemetry.html#metrics-file","title":"Metrics File","text":"<p>The Metrics File is a JSON file with the metrics collected by the <code>percona_pg_telemetry</code> extension. </p>"},{"location":"telemetry.html#locations","title":"Locations","text":"<p>Percona stores the Metrics File in one of the following directories on the local file system. The location depends on the product.</p> <ul> <li> <p>Telemetry root path - <code>/usr/local/percona/telemetry</code></p> </li> <li> <p>PostgreSQL root path - <code>${telemetry root path}/pg/</code></p> </li> <li> <p>Percona Server for MongoDB has two root paths since telemetry is enabled both for the <code>mongod</code> and <code>mongos</code> instances. The paths are the following:  </p> <ul> <li><code>mongod</code> root path -  <code>${telemetry root path}/psmdb/</code></li> <li><code>mongos</code> root path -  <code>${telemetry root path}/psmdbs/</code></li> </ul> </li> <li> <p>PS root path -   <code>${telemetry root path}/ps/</code></p> </li> <li> <p>PXC root path - <code>${telemetry root path}/pxc/</code></p> </li> </ul> <p>Percona archives the telemetry history in <code>${telemetry root path}/history/</code>.</p>"},{"location":"telemetry.html#metrics-file-format","title":"Metrics File format","text":"<p>The Metrics File uses the Javascript Object Notation (JSON) format. Percona reserves the right to extend the current set of JSON structure attributes in the future.</p> <p>The following is an example of the collected data generated by the <code>percona_pg_telemetry</code> extension:    </p> <pre><code>```json\n      {\n        \"db_instance_id\": \"7310358902660071382\",\n        \"pillar_version\": \"17.0\",\n        \"uptime\": \"36\",\n        \"databases_count\": \"2\",\n        \"settings\": [\n          {\n            \"key\": \"setting\",\n            \"value\": [\n              {\n                \"key\": \"name\",\n                \"value\": \"allow_in_place_tablespaces\"\n              },\n              {\n                \"key\": \"unit\",\n                \"value\": \"NULL\"\n              },\n              {\n                \"key\": \"setting\",\n                \"value\": \"off\"\n              },\n              {\n                \"key\": \"reset_val\",\n                \"value\": \"off\"\n              },\n              {\n                \"key\": \"boot_val\",\n                \"value\": \"off\"\n              }\n            ]\n          },\n          ...\n        ],\n        \"databases\": [\n          {\n            \"key\": \"database\",\n            \"value\": [\n              {\n                \"key\": \"database_oid\",\n                \"value\": \"5\"\n              },\n              {\n                \"key\": \"database_size\",\n                \"value\": \"7820895\"\n              },\n              {\n                \"key\": \"active_extensions\",\n                \"value\": [\n                  {\n                    \"key\": \"extension_name\",\n                    \"value\": \"plpgsql\"\n                  },\n                  {\n                    \"key\": \"extension_name\",\n                    \"value\": \"pg_tde\"\n                  },\n                  {\n                    \"key\": \"extension_name\",\n                    \"value\": \"percona_pg_telemetry\"\n                  }\n                ]\n              }\n            ]\n          }\n        ]\n      }\n```\n</code></pre>"},{"location":"telemetry.html#telemetry-agent","title":"Telemetry Agent","text":"<p>The Percona Telemetry Agent runs as a dedicated OS daemon process <code>percona-telemetry-agent</code>. It creates, reads, writes, and deletes JSON files in the <code>${telemetry root path}</code>. You can find the agent\u2019s log file at <code>/var/log/percona/telemetry-agent.log</code>.</p> <p>The agent does not send anything if there are no Percona-specific files in the target directory.</p> <p>The following is an example of a Telemetry Agent payload:</p> <pre><code>{\n  \"reports\": [\n    {\n      \"id\": \"B5BDC47B-B717-4EF5-AEDF-41A17C9C18BB\",\n      \"createTime\": \"2023-09-01T10:56:49Z\",\n      \"instanceId\": \"B5BDC47B-B717-4EF5-AEDF-41A17C9C18BA\",\n      \"productFamily\": \"PRODUCT_FAMILY_POSTGRESQL\",\n      \"metrics\": [\n        {\n          \"key\": \"OS\",\n          \"value\": \"Ubuntu\"\n        },\n        {\n          \"key\": \"pillar_version\",\n          \"value\": \"17.0\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre> <p>The agent sends information about the database and metrics.</p> Key Description \u201cid\u201d A generated Universally Unique Identifier (UUID) version 4 \u201ccreateTime\u201d UNIX timestamp \u201cinstanceId\u201d The DB Host ID. The value can be taken from the <code>instanceId</code>, the <code>/usr/local/percona/telemetry_uuid</code> or generated as a UUID version 4 if the file is absent. \u201cproductFamily\u201d The value from the file path \u201cmetrics\u201d An array of key:value pairs collected from the Metrics File. <p>The following operating system-level metrics are sent with each check:</p> Key Description \u201cOS\u201d The name of the operating system \u201chardware_arch\u201d The type of process used in the environment \u201cdeployment\u201d How the application was deployed.  The possible values could be \u201cPACKAGE\u201d or \u201cDOCKER\u201d. \u201cinstalled_packages\u201d A list of the installed Percona packages. <p>The information includes the following:</p> <ul> <li> <p>Package name</p> </li> <li> <p>Package version - the same format as Red Hat Enterprise Linux or Debian</p> </li> <li> <p>Package repository - if possible</p> </li> </ul> <p>The package names must fit the following pattern:</p> <ul> <li> <p><code>percona-*</code></p> </li> <li> <p><code>Percona-*</code></p> </li> <li> <p><code>proxysql*</code></p> </li> <li> <p><code>pmm</code></p> </li> <li> <p><code>etcd*</code></p> </li> <li> <p><code>haproxy</code></p> </li> <li> <p><code>patroni</code></p> </li> <li> <p><code>pg*</code></p> </li> <li> <p><code>postgis</code></p> </li> <li> <p><code>wal2json</code></p> </li> </ul>"},{"location":"telemetry.html#disable-telemetry","title":"Disable telemetry","text":"<p>Telemetry is enabled by default when you install the software. It is also included in the software packages (Telemetry Subsystem and Telemetry Agent) and enabled by default.</p> <p>If you don\u2019t want to send the telemetry data, here\u2019s how: </p>"},{"location":"telemetry.html#disable-the-telemetry-collected-during-the-installation","title":"Disable the telemetry collected during the installation","text":"<p>If you decide not to send usage data to Percona when you install the software, you can set the <code>PERCONA_TELEMETRY_DISABLE=1</code> environment variable for either the root user or in the operating system prior to the installation process.</p> Debian-derived distributionRed Hat-derived distributionDocker <p>Add the environment variable before the installation process.</p> <pre><code>$ sudo PERCONA_TELEMETRY_DISABLE=1 apt install percona-ppg-server-17\n</code></pre> <p>Add the environment variable before the installation process.</p> <pre><code>$ sudo PERCONA_TELEMETRY_DISABLE=1 yum install percona-ppg-server17\n</code></pre> <p>Add the environment variable when running a command in a new container.</p> <pre><code>$ docker run -d --name pg --restart always \\\n  -e PERCONA_TELEMETRY_DISABLE=1 \\\n  percona/percona-distribution-postgresql:&lt;TAG&gt;-multi\n</code></pre> <p>The command does the following:</p> <ul> <li><code>docker run</code> - This is the command to run a Docker container.</li> <li><code>-d</code> - This flag specifies that the container should run in detached mode (in the background).</li> <li><code>--name pg</code> - Assigns the name \u201cpg\u201d to the container.</li> <li><code>--restart always</code> - Configures the container to restart automatically if it stops or crashes.</li> <li><code>-e PERCONA_TELEMETRY_DISABLE=1</code> - Sets an environment variable within the container. In this case, it disables telemetry for Percona Distribution for PostgreSQL.</li> <li><code>percona/percona-distribution-postgresql:&lt;TAG&gt;-multi</code> - Specifies the image to use for the container. For example, <code>17.0-multi</code>. The <code>multi</code> part of the tag serves to identify the architecture (x86_64 or ARM64) and use the respective image.</li> </ul>"},{"location":"telemetry.html#disable-telemetry-for-the-installed-software","title":"Disable telemetry for the installed software","text":"<p>Percona software you installed includes the telemetry feature that collects information about how you use this software. It is enabled by default. To turn  off telemetry, you need to disable both the Telemetry Agent and the Telemetry Subsystem.</p>"},{"location":"telemetry.html#disable-telemetry-agent","title":"Disable Telemetry Agent","text":"<p>In the first 24 hours, no information is collected or sent.</p> <p>You can either disable the Telemetry Agent temporarily or permanently.</p> Disable temporarilyDisable permanently <p>Turn off Telemetry Agent temporarily until the next server restart with this command:</p> <pre><code>$ systemctl stop percona-telemetry-agent\n</code></pre> <p>Turn off Telemetry Agent permanently with this command:</p> <pre><code>$ systemctl disable percona-telemetry-agent\n</code></pre> <p>Even after stopping the Telemetry Agent service, a different part of the software (<code>percona_pg_telemetry</code>) continues to create the Metrics File related to telemetry every day and saves that file for seven days.</p>"},{"location":"telemetry.html#telemetry-agent-dependencies-and-removal-considerations","title":"Telemetry Agent dependencies and removal considerations","text":"<p>If you decide to remove the Telemetry Agent, this also removes the database. That\u2019s because the Telemetry Agent is a mandatory dependency for Percona Distribution for PostgreSQL. </p> <p>On YUM-based systems, the system removes the Telemetry Agent package when you remove the last dependency package.</p> <p>On APT-based systems, you must use the \u2018\u2013autoremove\u2019 option to remove all dependencies, as the system doesn\u2019t automatically remove the Telemetry Agent when you remove the database package.</p> <p>The \u2018\u2013autoremove\u2019 option only removes unnecessary dependencies. It doesn\u2019t remove dependencies required by other packages or guarantee the removal of all package-associated dependencies.</p>"},{"location":"telemetry.html#disable-the-percona_pg_telemetry-extension","title":"Disable the <code>percona_pg_telemetry</code> extension","text":"<p>To disable the Metrics File creation, stop and drop the <code>percona_pg_telemetry</code> extension. Here\u2019s how to do it:</p> <ol> <li> <p>Stop the extension and reapply the configuration for the changes to take effect:</p> <pre><code>ALTER SYSTEM SET percona_pg_telemetry.enabled = 0;\nSELECT pg_reload_conf();\n</code></pre> </li> <li> <p>Remove the <code>percona_pg_telemetry</code> extension from the database:</p> <pre><code>DROP EXTENSION percona_pg_telemetry;\n</code></pre> </li> <li> <p>Remove <code>percona_pg_telemetry</code> from the <code>shared_preload_libraries</code> configuration parameter:</p> <pre><code>ALTER SYSTEM SET shared_preload_libraries = '';\n</code></pre> <p>Important</p> <p>If the <code>shared_preload_libraries parameter</code> includes other modules, specify them all for the <code>ALTER SYSTEM SET</code> command to keep using them.</p> </li> <li> <p>Restart the PostgreSQL server</p>  On Debian and Ubuntu On Red Hat Enterprise Linux and derivatives <pre><code>$ sudo systemctl restart postgresql.service\n</code></pre> <pre><code>$ sudo systemctl restart postgresql-17\n</code></pre> </li> </ol> <p>Tip</p> <p>If you wish to re-enable the Telemetry Subsystem, complete the above steps in the reverse order:</p> <ol> <li>Add the <code>percona_pg_telemetry</code> to the <code>shared_preload_libraries</code>, </li> <li>Set <code>percona_pg_telemetry.enabled</code> to <code>1</code>, and </li> <li>Restart the PostgreSQL server.</li> </ol> <p></p>"},{"location":"telemetry.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"third-party.html","title":"Third-party components","text":"<p>Percona Distribution for PostgreSQL is supplied with the set of third-party open source components and tools that provide additional functionality such as high-availability or disaster recovery, without the need of modifying PostgreSQL core code. These components are included in the Percona Distribution for PostgreSQL repository and are tested to work together.</p> Name Superuser privileges Description etcd Required A distributed, reliable key-value store for setting up high available Patroni clusters HAProxy Required A high-availability and load-balancing solution Patroni Required An HA (High Availability) solution for PostgreSQL pgAudit Required Provides detailed session or object audit logging via the standard PostgreSQL logging facility pgAudit set_user Required The <code>set_user</code> part of <code>pgAudit</code> extension provides an additional layer of logging and control when unprivileged users must escalate themselves to superuser or object owner roles in order to perform needed maintenance tasks pgBackRest Required A backup and restore solution for PostgreSQL pgBadger Required A fast PostgreSQL Log Analyzer PgBouncer Required A lightweight connection pooler for PostgreSQL pg_gather Required An SQL script to assess the health of PostgreSQL cluster by gathering performance and configuration data from PostgreSQL databases pgpool2 Required A middleware between PostgreSQL server and client for high availability, connection pooling and load balancing pg_repack Required Rebuilds PostgreSQL database objects pg_stat_monitor Required Collects and aggregates statistics for PostgreSQL and provides histogram information PostGIS Required Allows storing and manipulating spacial data in PostgreSQL wal2json Required A PostgreSQL logical decoding JSON output plugin. <p></p>"},{"location":"third-party.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"trademark-policy.html","title":"Trademark Policy","text":"<p>This Trademark Policy  is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p> <p></p>"},{"location":"trademark-policy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"troubleshooting.html","title":"Troubleshooting guide","text":""},{"location":"troubleshooting.html#cannot-create-a-table-permission-denied-in-schema-public","title":"Cannot create a table. Permission denied in schema <code>public</code>","text":"<p>Every database in PostgreSQL has a default schema called <code>public</code>. A schema stores database objects like tables, views, indexes and allows organizing them into logical groups.</p> <p>When you create a table without specifying a schema name, it ends up in the <code>public</code> schema by default. </p> <p>Starting with PostgreSQL 15, non-database owners cannot access the <code>public</code> schema. Therefore, you can either grant privileges to the database for your user using the GRANT command or create your own schema to insert the data.</p> <p>To create a schema, use the following statement:</p> <pre><code>CREATE SCHEMA demo;\n</code></pre> <p>To ensure all tables end up in your newly created schema, use the following statement ot set the schema:</p> <pre><code>SET SCHEMA demo;\n</code></pre> <p>Replace the <code>demo</code> name with your value.</p> <p></p>"},{"location":"troubleshooting.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"uninstalling.html","title":"Uninstalling Percona Distribution for PostgreSQL","text":"<p>To uninstall Percona Distribution for PostgreSQL, remove all the installed packages and data / configuration files.</p> <p>NOTE: Should you need the data files later, back up your data before uninstalling Percona Distribution for PostgreSQL.</p>  On Debian and Ubuntu using <code>apt</code> On Red Hat Enterprise Linux and derivatives using <code>yum</code> <p>To uninstall Percona Distribution for PostgreSQL on platforms that use apt package manager such as Debian  or Ubuntu, complete the following steps.</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Stop the Percona Distribution for PostgreSQL service.</p> <pre><code>$ sudo systemctl stop postgresql.service\n</code></pre> </li> <li> <p>Remove the percona-postgresql packages.</p> <pre><code>$ sudo apt remove percona-postgresql-17* percona-patroni percona-pgbackrest  percona-pgbadger percona-pgbouncer\n</code></pre> </li> <li> <p>Remove configuration and data files.</p> <pre><code>$ rm -rf /etc/postgresql/17/main\n</code></pre> </li> </ol> <p>To uninstall Percona Distribution for PostgreSQL on platforms that use yum package manager such as  Red Hat Enterprise Linux or CentOS, complete the following steps.</p> <p>Run all commands as root or via sudo.</p> <ol> <li> <p>Stop the Percona Distribution for PostgreSQL service.</p> <pre><code>$ sudo systemctl stop postgresql-17\n</code></pre> </li> <li> <p>Remove the percona-postgresql packages</p> <pre><code>$ sudo yum remove percona-postgresql17* percona-pgbadger\n</code></pre> </li> <li> <p>Remove configuration and data files</p> <pre><code>$ rm -rf /var/lib/pgsql/17/data\n</code></pre> </li> </ol>"},{"location":"uninstalling.html#uninstall-from-tarballs","title":"Uninstall from tarballs","text":"<p>If you installed Percona Distribution for PostgreSQL from binary tarballs, stop the PostgreSQL server and remove the folder with the binary tarballs.</p> <ol> <li> <p>Stop the <code>postgres</code> server:</p> <pre><code>$ /path/to/tarballs/percona-postgresql17/bin/pg_ctl -D path/to/datadir -l logfile stop\n</code></pre> Sample output <pre><code>waiting for server to shut down.... done\nserver stopped\n</code></pre> </li> <li> <p>Remove the directory with extracted tarballs</p> <pre><code>$ sudo rm -rf /path/to/tarballs/\n</code></pre> </li> </ol> <p></p>"},{"location":"uninstalling.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"whats-next.html","title":"What\u2019s next?","text":"<p>You\u2019ve just had your first hands-on experience with PostgreSQL! That\u2019s a great start.</p> <p>To become more confident and proficient in developing database applications, let\u2019s expand your knowledge and skills in using PostgreSQL. Dive deeper into these key topics to solidify your PostgreSQL skills:</p> <ul> <li>SQL Syntax  </li> <li>Data definition </li> <li>Queries </li> <li>Functions and Operators </li> <li>Indexes </li> </ul> <p>To effectively solve database administration tasks, master these essential topics: </p> <ul> <li>Backup and restore  </li> <li>Authentication  and role-based access control</li> <li>PostgreSQL contrib extensions and modules</li> <li>Monitor PostgreSQL with Percona Monitoring and Management </li> </ul> <p>Also, check out our solutions to help you meet the requirements of your organization.</p> <p>Solutions</p> <p></p>"},{"location":"whats-next.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"yum.html","title":"Install Percona Distribution for PostgreSQL on Red Hat Enterprise Linux and derivatives","text":"<p>This document describes how to install Percona Distribution for PostgreSQL from Percona repositories on RPM-based distributions such as Red Hat Enterprise Linux and compatible derivatives. Read more about Percona repositories.</p>"},{"location":"yum.html#platform-specific-notes","title":"Platform specific notes","text":"<p>Depending on what operating system you are using, you may need to enable or disable specific modules to install Percona Distribution for PostgreSQL packages and to resolve dependencies conflicts for its specific components. </p>"},{"location":"yum.html#for-percona-distribution-for-postgresql-packages","title":"For Percona Distribution for PostgreSQL packages","text":"CentOS 7RHEL8/Oracle Linux 8/Rocky Linux 8 <p>Install the <code>epel-release</code> package:</p> <pre><code>$ sudo yum -y install epel-release\n$ sudo yum repolist\n</code></pre> <p>Disable the <code>postgresql</code>  and <code>llvm-toolset</code>modules:    </p> <pre><code>$ sudo dnf module disable postgresql llvm-toolset\n</code></pre>"},{"location":"yum.html#for-percona-postgresql17-devel-package","title":"For <code>percona-postgresql17-devel</code> package","text":"<p>You may need to install the <code>percona-postgresql17-devel</code> package when working with some extensions or creating programs that interface with PostgreSQL database. This package requires dependencies that are not part of the Distribution, but can be installed from the specific repositories:</p> RHEL8Rocky Linux 8Oracle Linux 8Rocky Linux 9Oracle Linux 9 <pre><code>$ sudo yum --enablerepo=codeready-builder-for-rhel-8-rhui-rpms install perl-IPC-Run -y\n</code></pre> <pre><code>$ sudo dnf install dnf-plugins-core\n$ sudo dnf module enable llvm-toolset\n$ sudo dnf config-manager --set-enabled powertools\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled ol8_codeready_builder install perl-IPC-Run -y\n</code></pre> <pre><code>$ sudo dnf install dnf-plugins-core\n$ sudo dnf module enable llvm-toolset\n$ sudo dnf config-manager --set-enabled crb\n$ sudo dnf install perl-IPC-Run -y\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled ol9_codeready_builder install perl-IPC-Run -y\n</code></pre>"},{"location":"yum.html#for-percona-patroni-package","title":"For <code>percona-patroni</code> package","text":"<p>To install Patroni on Red Hat Enterprise Linux 9 and compatible derivatives, enable the <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre>"},{"location":"yum.html#for-pgpool2-extension","title":"For <code>pgpool2</code> extension","text":"<p>To install <code>pgpool2</code> on Red Hat Enterprise Linux and compatible derivatives, enable the codeready builder repository first to resolve dependencies conflict for <code>pgpool2</code>.</p> <p>The following are commands for Red Hat Enterprise Linux 9 and derivatives. For Red Hat Enterprise Linux 8, replace the operating system version in the commands accordingly. </p> RHEL 9Rocky Linux 9Oracle Linux 9 <pre><code>$ sudo dnf config-manager --set-enabled codeready-builder-for-rhel-9-x86_64-rpms\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled crb\n</code></pre> <pre><code>$ sudo dnf config-manager --set-enabled ol9_codeready_builder\n</code></pre>"},{"location":"yum.html#for-postgis","title":"For PostGIS","text":"<p>For Red Hat Enterprise Linux 8 and derivatives, replace the operating system version in the following commands accordingly.</p> RHEL 9Rocky Linux 9Oracle Linux 9RHEL UBI 9 <p>Run the following commands:</p> <ol> <li> <p>Install <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Enable the <code>llvm-toolset dnf</code> module</p> <pre><code>$ sudo dnf module enable llvm-toolset\n</code></pre> </li> <li> <p>Enable the codeready builder repository to resolve dependencies conflict. </p> <pre><code>$ sudo dnf config-manager --set-enabled codeready-builder-for-rhel-9-x86_64-rpms\n</code></pre> </li> </ol> <p>Run the following commands:</p> <ol> <li> <p>Install <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Enable the <code>llvm-toolset dnf</code> module</p> <pre><code>$ sudo dnf module enable llvm-toolset\n</code></pre> </li> <li> <p>Enable the codeready builder repository to resolve dependencies conflict.</p> <pre><code>$ sudo dnf install dnf-plugins-core\n$ sudo dnf config-manager --set-enabled crb\n</code></pre> </li> </ol> <p>Run the following commands:</p> <ol> <li> <p>Install <code>epel</code> repository</p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Enable the <code>llvm-toolset dnf</code> module</p> <pre><code>$ sudo dnf module enable llvm-toolset\n</code></pre> </li> <li> <p>Enable the codeready builder repository to resolve dependencies conflict.</p> <pre><code>$ sudo dnf config-manager --set-enabled ol9_codeready_builder\n</code></pre> </li> </ol> <p>Run the following commands:</p> <ol> <li> <p>Configure the Oracle-Linux repository. Create the <code>/etc/yum.repos.d/oracle-linux-ol9.repo</code> file to install the required dependencies: </p> /etc/yum.repos.d/oracle-linux-ol9.repo<pre><code>[ol9_baseos_latest]\nname=Oracle Linux 9 BaseOS Latest ($basearch)\nbaseurl=https://yum.oracle.com/repo/OracleLinux/OL9/baseos/latest/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1     \n\n[ol9_appstream]\nname=Oracle Linux 9 Application Stream ($basearch)\nbaseurl=https://yum.oracle.com/repo/OracleLinux/OL9/appstream/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1     \n\n[ol9_codeready_builder]\nname=Oracle Linux 9 CodeReady Builder ($basearch) - Unsupported\nbaseurl=https://yum.oracle.com/repo/OracleLinux/OL9/codeready/builder/$basearch/\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\ngpgcheck=1\nenabled=1\n</code></pre> </li> <li> <p>Download the right GPG key for the Oracle Yum Repository:    </p> <pre><code>$ wget https://yum.oracle.com/RPM-GPG-KEY-oracle-ol9 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle\n</code></pre> </li> <li> <p>Install <code>epel</code> repository    </p> <pre><code>$ sudo yum install epel-release\n</code></pre> </li> <li> <p>Disable the upstream <code>postgresql</code> package:    </p> <pre><code>$ sudo dnf module disable postgresql\n</code></pre> </li> </ol>"},{"location":"yum.html#procedure","title":"Procedure","text":"<p>Run all the commands in the following sections as root or using the <code>sudo</code> command:</p>"},{"location":"yum.html#install-dependencies","title":"Install dependencies","text":"<p>Install <code>curl</code> for Telemetry. We use it to better understand the use of our products and improve them.</p> <pre><code>$ sudo yum -y install curl\n</code></pre>"},{"location":"yum.html#configure-the-repository","title":"Configure the repository","text":"<ol> <li> <p>Install the <code>percona-release</code> repository management tool to subscribe to Percona repositories:</p> <pre><code>$ sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n</code></pre> </li> <li> <p>Enable the repository</p> </li> </ol> <p>Percona provides two repositories for Percona Distribution for PostgreSQL. We recommend enabling the Major release repository to timely receive the latest updates. </p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre>"},{"location":"yum.html#install-packages","title":"Install packages","text":"Install using meta-packageInstall packages individually <p>The meta package enables you to install several components of the distribution in one go.</p> <pre><code>$ sudo yum install percona-ppg-server17\n</code></pre> <p>Run the following commands:</p> <ol> <li> <p>Install the PostgreSQL server package:</p> <pre><code>$ sudo yum install percona-postgresql17-server\n</code></pre> </li> <li> <p>Install the components:</p> <p>Install <code>pg_repack</code>:</p> <pre><code>$ sudo yum install percona-pg_repack17\n</code></pre> <p>Install <code>pgaudit</code>:</p> <pre><code>$ sudo yum install percona-pgaudit17\n</code></pre> <p>Install <code>pgBackRest</code>:</p> <pre><code>$ sudo yum install percona-pgbackrest\n</code></pre> <p>Install <code>Patroni</code>:</p> <pre><code>$ sudo yum install percona-patroni\n</code></pre> <p>Install <code>pg_stat_monitor</code> </p> <p>Install <code>pgBouncer</code>:</p> <pre><code>$ sudo yum install percona-pgbouncer\n</code></pre> <p>Install <code>pgAudit-set_user</code>:</p> <pre><code>$ sudo yum install percona-pgaudit17_set_user\n</code></pre> <p>Install <code>pgBadger</code>:</p> <pre><code>$ sudo yum install percona-pgbadger\n</code></pre> <p>Install <code>wal2json</code>:</p> <pre><code>$ sudo yum install percona-wal2json17\n</code></pre> <p>Install PostgreSQL contrib extensions:</p> <pre><code>$ sudo yum install percona-postgresql17-contrib\n</code></pre> <p>Install HAProxy</p> <pre><code>$ sudo yum install percona-haproxy\n</code></pre> <p>Install <code>pg_gather</code></p> <pre><code>$ sudo yum install percona-pg_gather\n</code></pre> <p>Install pgpool2</p> <ol> <li>Check the platform specific notes</li> <li> <p>Install the extension</p> <pre><code>$ sudo yum install percona-pgpool-II-pg17\n</code></pre> </li> </ol> <p>Some extensions require additional setup in order to use them with Percona Distribution for PostgreSQL. For more information, refer to Enabling extensions.</p> </li> </ol>"},{"location":"yum.html#start-the-service","title":"Start the service","text":"<p>After the installation, the default database storage is not automatically initialized. To complete the installation and start Percona Distribution for PostgreSQL, initialize the database using the following command:</p> <pre><code>$ /usr/pgsql-17/bin/postgresql-17-setup initdb\n</code></pre> <p>Start the PostgreSQL service:</p> <pre><code>$ sudo systemctl start postgresql-17\n</code></pre> <p>Check the Percona Distribution for PostgreSQL version:</p> <pre><code>$ psql --version\n</code></pre> Sample output <pre><code>psql (PostgreSQL) 17.0.1 (Percona Server for PostgreSQL) 17.0.1\n</code></pre> <p>Congratulations! Your Percona Distribution for PostgreSQL is up and running.</p>"},{"location":"yum.html#next-steps","title":"Next steps","text":"<p>Enable extensions </p> <p>Connect to PostgreSQL </p> <p></p>"},{"location":"yum.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/backup-recovery.html","title":"Backup and disaster recovery in Percona Distribution for PostgreSQL","text":"<p>Summary</p> <ul> <li>Overview</li> <li>Architecture</li> <li>Deployment </li> <li>Testing</li> </ul>"},{"location":"solutions/backup-recovery.html#overview","title":"Overview","text":"<p>A Disaster Recovery (DR) solution ensures that a system can be quickly restored to a normal operational state if something unexpected happens. When operating a database, you would back up the data as frequently as possible and have a mechanism to restore that data when needed. Disaster Recovery is often mistaken for high availability (HA), but they are two different concepts altogether:</p> <ul> <li>High availability ensures guaranteed service levels at all times. This solution involves configuring one or more standby systems to an active database, and the ability to switch seamlessly to that standby when the primary database becomes unavailable, for example, during a power outage or a server crash. To learn more about high-availability solutions with Percona Distribution for PostgreSQL, refer to High Availability in PostgreSQL with Patroni.</li> <li>Disaster Recovery protects the database instance against accidental or malicious data loss or data corruption. Disaster recovery can be achieved by using either the options provided by PostgreSQL, or external extensions.</li> </ul> <p></p> PostgreSQL disaster recovery options <p> PostgreSQL offers multiple options for setting up database disaster recovery. </p> <ul> <li>pg_dump  or the pg_dumpall  utilities</li> </ul> <p>This is the basic backup approach. These tools can generate the backup of one or more PostgreSQL databases (either just the structure, or both the structure and data), then restore them through the pg_restore  command. </p> Advantages Disadvantages Easy to use 1. Backup of only one database at a time.2. No incremental backups.3. No point-in-time recovery since the backup is a snapshot in time.4. Performance degradation when the database size is large. <ul> <li>File-based backup and restore</li> </ul> <p>This method involves backing up the PostgreSQL data directory to a different location, and restoring it when needed. </p> Advantages Disadvantages Consistent snapshot of the data directory or the whole data disk volume 1. Requires stopping PostgreSQL in order to copy the files. This is not practical for most production setups. 2. No backup of individual databases or tables. <ul> <li>PostgreSQL pg_basebackup </li> </ul> <p>This backup tool is provided by PostgreSQL. It is used to back up data when the database instance is running. <code>pgasebackup</code> makes a binary copy of the database cluster files, while making sure the system is put in and out of backup mode automatically. </p> Advantages Disadvantages 1. Supports backups when the database is running.2. Supports point-in-time recovery 1. No incremental backups.2. No backup of individual databases or tables. <p></p> <p>To achieve a production grade PostgreSQL disaster recovery solution, you need something that can take full or incremental database backups from a running instance, and restore from those backups at any point in time. Percona Distribution for PostgreSQL is supplied with pgBackRest: a reliable, open-source backup and recovery solution for PostgreSQL.</p> <p>This document focuses on the Disaster recovery solution in Percona Distribution for PostgreSQL. The Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL tutorial provides guidelines of how to set up and test this solution.</p>"},{"location":"solutions/backup-recovery.html#pgbackrest","title":"pgBackRest","text":"<p>pgBackRest  is an easy-to-use, open-source solution that can reliably back up even the largest of PostgreSQL databases. <code>pgBackRest</code> supports the following backup types:</p> <ul> <li>full backup - a complete copy of your entire data set.</li> <li>differential backup - includes all data that has changed since the last full backup. While this means the backup time is slightly higher, it enables a faster restore.</li> <li>incremental backup - only backs up the files that have changed since the last full or differential backup, resulting in a quick backup time. To restore to a point in time, however, you will need to restore each incremental backup in the order they were taken.</li> </ul> <p>When it comes to restoring, <code>pgBackRest</code> can do a full or a delta restore. A full restore needs an empty PostgreSQL target directory. A delta restore is intelligent enough to recognize already-existing files in the PostgreSQL data directory, and update only the ones the backup contains. </p> <p><code>pgBackRest</code> supports remote repository hosting and can even use cloud-based services like AWS S3, Google Cloud Services Cloud Storage, Azure Blob Storage for saving backup files. It supports parallel backup through multi-core processing and compression. By default, backup integrity is verified through checksums, and saved files can be encrypted for enhanced security.</p> <p><code>pgBackRest</code> can restore a database to a specific point in time in the past. This is the case where a database is not inaccessible but perhaps contains corrupted data. Using the point-in-time recovery, a database administrator can restore the database to the last known good state.  </p> <p>Finally, <code>pgBackRest</code> also supports restoring PostgreSQL databases to a different PostgreSQL instance or a separate data directory.</p>"},{"location":"solutions/backup-recovery.html#setup-overview","title":"Setup overview","text":"<p>This section describes the architecture of the backup and disaster recovery solution. For the configuration steps, refer to the Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL.</p>"},{"location":"solutions/backup-recovery.html#system-architecture","title":"System architecture","text":"<p>As the configuration example, we will use a three server architecture where <code>pgBackRest</code> resides on a dedicated remote host. The servers communicate with each other via passwordless SSH.</p> <p>Important</p> <p>Passwordless SSH may not be an ideal solution for your environment. In this case, consider using other methods, for example, TLS with client certificates .</p> <p>The following diagram illustrates the architecture layout:</p> <p></p>"},{"location":"solutions/backup-recovery.html#components","title":"Components:","text":"<p>The architecture consists of three server instances:</p> <ul> <li><code>pg-primary</code> hosts the primary PostgreSQL server. Note that \u201cprimary\u201d here means the main database instance and does not refer to the primary node of a PostgreSQL replication cluster or a HA setup.</li> <li><code>pg-repo</code> is the remote backup repository and hosts <code>pgBackRest</code>. It\u2019s important to host the backup repository on a physically separate instance, to be accessed when the target goes down. </li> <li><code>pg-secondary</code> is the secondary PostgreSQL node. Don\u2019t confuse it with a hot standby. \u201cSecondary\u201d in this context means a PostgreSQL instance that\u2019s idle. We will restore the database backup to this instance when the primary PostgreSQL instance goes down. </li> </ul> <p>Note</p> <p>For simplicity, we use a single-node PostgreSQL instance as the primary database server. In a production scenario, you will use some form of high-availability solution to protect the primary instance. When you are using a high-availability setup, we recommend configuring <code>pgBackRest</code> to back up the hot standby server so the primary node is not unnecessarily loaded.</p>"},{"location":"solutions/backup-recovery.html#deployment","title":"Deployment","text":"<p>Refer to the Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL tutorial.  </p> <p></p>"},{"location":"solutions/backup-recovery.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/dr-pgbackrest-setup.html","title":"Deploying backup and disaster recovery solution in Percona Distribution for PostgreSQL","text":"<p>This document provides instructions of how to set up and test the backup and disaster recovery solution in Percona Distribution for PostgreSQL with <code>pgBackRest</code>. For technical overview and architecture description of this solution, refer to Backup and disaster recovery in Percona Distribution for PostgreSQL.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#deployment","title":"Deployment","text":"<p>As the example configuration, we will use the nodes with the following IP addresses:</p> Node name Internal IP address pg-primary 10.104.0.3 pg-repo 10.104.0.5 pg-secondary 10.104.0.4"},{"location":"solutions/dr-pgbackrest-setup.html#set-up-hostnames","title":"Set up hostnames","text":"<p>In our architecture, the <code>pgBackRest</code> repository is located on a remote host. To allow communication among the nodes, passwordless SSH is required. To achieve this, properly setting up hostnames in the <code>/etc/hosts</code> files is very important.</p> <ol> <li> <p>Define the hostname for every server in the <code>/etc/hostname</code> file. The following are the examples of how the <code>/etc/hostname</code> file in three nodes looks like:</p> <pre><code>cat /etc/hostname\npg-primary\n</code></pre> <pre><code>cat /etc/hostname\npg-repo\n</code></pre> <pre><code>cat /etc/hostname\npg-secondary\n</code></pre> </li> <li> <p>For the nodes to communicate seamlessly across the network, resolve their hostnames to their IP addresses in the <code>/etc/hosts</code> file.  (Alternatively, you can make appropriate entries in your internal DNS servers)</p> </li> </ol> <p>The <code>/etc/hosts</code> file  for the <code>pg-primary node</code> looks like this:</p> <pre><code>```\n127.0.1.1 pg-primary pg-primary\n127.0.0.1 localhost\n10.104.0.5 pg-repo\n```\n</code></pre> <p>The <code>/etc/hosts</code> file in the <code>pg-repo</code> node looks like this:</p> <pre><code>```\n127.0.1.1 pg-repo pg-repo\n127.0.0.1 localhost\n10.104.0.3 pg-primary\n10.104.0.4 pg-secondary\n```\n</code></pre> <p>The <code>/etc/hosts</code> file in the <code>pg-secondary</code> node is shown below:</p> <pre><code>```\n127.0.1.1 pg-secondary pg-secondary\n127.0.0.1 localhost\n10.104.0.3 pg-primary\n10.104.0.5 pg-repo\n```\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#set-up-passwordless-ssh","title":"Set up passwordless SSH","text":"<p>Before setting up passwordless SSH, ensure that the postgres user in all three instances has a password. </p> <ol> <li> <p>To set or change the password, run the following command as a root user:</p> <pre><code>$ passwd postgres\n</code></pre> </li> <li> <p>Type the new password and confirm it. </p> </li> <li> <p>After setting up the password, edit the <code>/etc/ssh/sshd_config</code> file and ensure the <code>PasswordAuthentication</code> variable is set as <code>yes</code>. </p> <pre><code>PasswordAuthentication yes \n</code></pre> </li> <li> <p>In the <code>pg-repo</code> node, restart the <code>sshd</code> service. Without the restart, the SSH server will not allow you to connect to it using a password while adding the keys.</p> <pre><code>$ sudo service sshd restart\n</code></pre> </li> <li> <p>In the <code>pg-primary</code> node, generate an SSH key pair and add the public key to the <code>pg-repo</code> node. </p> <p>Important</p> <p>Run the commands as the postgres user. </p> <ul> <li> <p>Generate SSH keys:   </p> <pre><code>$ ssh-keygen -t rsa\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa\nYour public key has been saved in /root/.ssh/id_rsa.pub\nThe key fingerprint is:\n...\n</code></pre> </li> <li> <p>Copy the public key to the <code>pg-repo</code> node:</p> <pre><code>$ ssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pg-repo\n/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\"\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\npostgres@pg-repo's password: \n\nNumber of key(s) added: 1\n\n\nNow try logging into the machine, with:   \"ssh 'postgres@pg-repo'\"\nand check to make sure that only the key(s) you wanted were added.\n</code></pre> </li> </ul> </li> <li> <p>To verify everything has worked as expected, run the following command from the <code>pg-primary</code> node. </p> <pre><code>$ ssh postgres@pg-repo\n</code></pre> <p>You should be able to connect to the <code>pg-repo</code> terminal without a password.</p> </li> <li> <p>Repeat the SSH connection from <code>pg-repo</code> to <code>pg-primary</code> to ensure that passwordless SSH is working. </p> </li> <li>Set up bidirectional passwordless SSH between <code>pg-repo</code> and <code>pg-secondary</code> using the same method. This will allow <code>pg-repo</code> to recover the backups to <code>pg-secondary</code>. </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#install-percona-distribution-for-postgresql","title":"Install Percona Distribution for PostgreSQL","text":"<p>Install Percona Distribution for PostgreSQL in the primary and the secondary nodes from Percona repository. </p> <ol> <li>Install <code>percona-release</code> .</li> <li> <p>Enable the repository:</p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages</p>  On Debian and Ubuntu On RedHat Enterprise Linux and derivatives <pre><code>$ sudo apt install percona-postgresql-17 -y\n</code></pre> <pre><code>$ sudo yum install percona-postgresql17-server\n</code></pre> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#configure-postgresql-on-the-primary-node-for-continuous-backup","title":"Configure PostgreSQL on the primary node for continuous backup","text":"<p>At this step, configure the PostgreSQL instance on the <code>pg-primary</code> node for continuous archiving of the WAL files. </p> <p>Note</p> <p> On Debian and Ubuntu, the path to the configuration file is <code>/etc/postgresql17/main/postgresql.conf</code>.</p> <p>On RHEL and CentOS, the path to the configuration file is <code>/var/lib/pgsql/17/data/</code>.</p> <ol> <li> <p>Edit the <code>postgresql.conf</code> configuration file to include the following changes:</p> <pre><code>archive_command = 'pgbackrest --stanza=prod_backup archive-push %p'\narchive_mode = on\nlisten_addresses = '*'\nlog_line_prefix = ''\nmax_wal_senders = 3\nwal_level = replica\n</code></pre> </li> <li> <p>Once the changes are saved, restart PostgreSQL.</p> <pre><code>$ sudo systemctl restart postgresql\n</code></pre> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#install-pgbackrest","title":"Install pgBackRest","text":"<p>Install <code>pgBackRest</code> in all three instances from Percona repository. Use the following command:</p>  On Debian / Ubuntu On RHEL / derivatives <pre><code>$ sudo apt-get install percona-pgbackrest\n</code></pre> <pre><code>$ sudo yum install percona-pgbackrest\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#create-the-pgbackrest-configuration-file","title":"Create the <code>pgBackRest</code> configuration file","text":"<p>Run the following commands on all three nodes to set up the required configuration file for <code>pgBackRest</code>.</p> <ol> <li> <p>Configure a location and permissions for the <code>pgBackRest</code> log rotation:</p> <pre><code>$ sudo mkdir -p -m 770 /var/log/pgbackrest\n$ sudo chown postgres:postgres /var/log/pgbackrest\n</code></pre> </li> <li> <p>Configure the location and permissions for the <code>pgBackRest</code> configuration file:</p> </li> </ol> <pre><code>$ sudo mkdir -p /etc/pgbackrest\n$ sudo mkdir -p /etc/pgbackrest/conf.d\n$ sudo touch /etc/pgbackrest/pgbackrest.conf\n$ sudo chmod 640 /etc/pgbackrest/pgbackrest.conf\n$ sudo chown postgres:postgres /etc/pgbackrest/pgbackrest.conf\n$ sudo mkdir -p /home/pgbackrest\n$ sudo chmod postgres:postgres /home/pgbackrest\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#update-pgbackrest-configuration-file-in-the-primary-node","title":"Update <code>pgBackRest</code> configuration file in the primary node","text":"<p>Configure <code>pgBackRest</code> on the <code>pg-primary</code> node by setting up a stanza. A stanza is a set of configuration parameters that tells <code>pgBackRest</code> where to backup its files. Edit the <code>/etc/pgbackrest/pgbackrest.conf</code> file in the <code>pg-primary</code> node to include the following lines:</p> <pre><code>[global]\nrepo1-host=pg-repo \nrepo1-host-user=postgres\nprocess-max=2\nlog-level-console=info\nlog-level-file=debug\n\n[prod_backup]\npg1-path=/var/lib/postgresql/14/main\n</code></pre> <p>You can see the <code>pg1-path</code> attribute for the <code>prod_backup</code> stanza has been set to the PostgreSQL data folder.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#update-pgbackrest-configuration-file-in-the-remote-backup-repository-node","title":"Update <code>pgBackRest</code> configuration file in the remote backup repository node","text":"<p>Add a stanza for the <code>pgBackRest</code> in the <code>pg-repo</code> node. Edit the <code>/etc/pgbackrest/pgbackrest.conf</code> configuration file to include the following lines:</p> <pre><code>[global]\nrepo1-path=/home/pgbackrest/pg_backup\nrepo1-retention-full=2\nprocess-max=2\nlog-level-console=info\nlog-level-file=debug\nstart-fast=y\nstop-auto=y\n\n[prod_backup]\npg1-path=/var/lib/postgresql/14/main\npg1-host=pg-primary\npg1-host-user=postgres\npg1-port = 5432\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#initialize-pgbackrest-stanza-in-the-remote-backup-repository-node","title":"Initialize <code>pgBackRest</code> stanza in the remote backup repository node","text":"<p>After the configuration files are set up, it\u2019s now time to initialize the <code>pgBackRest</code> stanza. Run the following command in the remote backup repository node (<code>pg-repo</code>).</p> <pre><code>$ sudo -u postgres pgbackrest --stanza=prod_backup stanza-create\n2021-11-07 11:08:18.157 P00   INFO: stanza-create command begin 2.36: --exec-id=155883-2277a3e7 --log-level-console=info --log-level-file=off --pg1-host=pg-primary --pg1-host-user=postgres --pg1-path=/var/lib/postgresql/14/main --pg1-port=5432 --repo1-path=/home/pgbackrest/pg_backup --stanza=prod_backup\n2021-11-07 11:08:19.453 P00   INFO: stanza-create for stanza 'prod_backup' on repo1\n2021-11-07 11:08:19.566 P00   INFO: stanza-create command end: completed successfully (1412ms)\n</code></pre> <p>Once the stanza is created successfully, you can try out the different use cases for disaster recovery.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#testing-backup-and-restore-with-pgbackrest","title":"Testing Backup and Restore with <code>pgBackRest</code>","text":"<p>This section covers a few use cases where <code>pgBackRest</code> can back up and restore databases either in the same instance or a different node.</p>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-1-create-a-backup-with-pgbackrest","title":"Use Case 1: Create a backup with <code>pgBackRest</code>","text":"<ol> <li> <p>To start our testing, let\u2019s create a table in the <code>postgres</code> database in the <code>pg-primary</code> node and add some data.</p> <pre><code>CREATE TABLE CUSTOMER (id integer, name text);\nINSERT INTO CUSTOMER VALUES (1,'john');\nINSERT INTO CUSTOMER VALUES (2,'martha');\nINSERT INTO CUSTOMER VALUES (3,'mary');\n</code></pre> </li> <li> <p>Take a full backup of the database instance. Run the following commands from the <code>pg-repo</code> node:</p> </li> </ol> <pre><code>$ pgbackrest -u postgres  --stanza=prod_backup backup --type=full\n</code></pre> <p>If you want an incremental backup, you can omit the <code>type</code> attribute. By default, <code>pgBackRest</code> always takes an incremental backup except the first backup of the cluster which is always a full backup. </p> <p>If you need a differential backup,  use diff for the <code>type</code> field:</p> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup backup --type=diff\n</code></pre>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-2-restore-a-postgresql-instance-from-a-full-backup","title":"Use Case 2: Restore a PostgreSQL Instance from a full backup","text":"<p>For testing purposes, let\u2019s \u201cdamage\u201d the PostgreSQL instance. </p> <ol> <li> <p>Run the following command in the <code>pg-primary</code> node to delete the main data directory.</p> <pre><code>$ rm -rf /var/lib/postgresql/14/main/*\n</code></pre> </li> <li> <p>To restore the backup, run the following commands. </p> <ul> <li>Stop the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl stop postgresql\n</code></pre> <ul> <li>Restore the backup:</li> </ul> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup restore\n</code></pre> <ul> <li>Start the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl start postgresql\n</code></pre> </li> <li> <p>After the command executes successfully, you can access PostgreSQL from the <code>psql</code> command line tool and check if the table and data rows have been restored.</p> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-3-point-in-time-recovery","title":"Use Case 3: Point-In-Time Recovery","text":"<p>If your target PostgreSQL instance has an already existing data directory, the full restore option will fail. You will get an error message stating there are existing data files.  In this case, you can use the <code>--delta</code> option to restore only the corrupted files. </p> <p>For example, let\u2019s say one of your developers mistakenly deleted a few rows from a table. You can use <code>pgBackRest</code> to revert your database to a previous point in time to recover the lost rows.</p> <p>To test this use case, do the following:</p> <ol> <li> <p>Take a timestamp when the database is stable and error-free. Run the following command from the <code>psql</code>prompt.</p> <pre><code>SELECT CURRENT_TIMESTAMP;\n       current_timestamp       \n-------------------------------\n 2021-11-07 11:55:47.952405+00\n(1 row)\n</code></pre> <p>Note down the above timestamp since we will use this time in the restore command. Note that in a real life scenario, finding the correct point in time when the database was error-free may require extensive investigation. It is also important to note that all changes after the selected point will be lost after the roll back. </p> </li> <li> <p>Delete one of the customer records added before.</p> <pre><code>DELETE FROM CUSTOMER WHERE ID=3;\n</code></pre> </li> <li> <p>To recover the data, run a command with the noted timestamp as an argument. Run the commands below to recover the database up to that time.</p> <ul> <li>Stop the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl stop postgresql\n</code></pre> <ul> <li>Restore the backup</li> </ul> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup --delta \\\n--type=time \"--target= 2021-11-07 11:55:47.952405+00\" \\\n--target-action=promote restore\n</code></pre> <ul> <li>Start the <code>postgresql</code> instance</li> </ul> <pre><code>$ sudo systemctl start postgresql\n</code></pre> </li> <li> <p>Check the database table to see if the record has been restored.</p> <pre><code>SELECT * FROM customer;\n id |  name  \n----+--------\n  1 | john\n  2 | martha\n  3 | mary\n(3 rows)\n</code></pre> </li> </ol>"},{"location":"solutions/dr-pgbackrest-setup.html#use-case-4-restoring-to-a-separate-postgresql-instance","title":"Use Case 4: Restoring to a Separate PostgreSQL Instance","text":"<p>Sometimes a PostgreSQL server may encounter hardware issues and become completely inaccessible. In such cases, we will need to recover the database to a separate instance where <code>pgBackRest</code> is not initially configured. To restore the instance to a separate host, you have to first install both PostgreSQL and <code>pgBackRest</code> in this host. </p> <p>In our test setup, we already have PostgreSQL and <code>pgBackRest</code> installed in the third node, <code>pg-secondary</code>. Change the <code>pgBackRest</code> configuration file in the <code>pg-secondary</code> node as shown below.</p> <pre><code>[global]\nrepo1-host=pg-repo\nrepo1-host-user=postgres\nprocess-max=2\nlog-level-console=info\nlog-level-file=debug\n\n[prod_backup]\npg1-path=/var/lib/postgresql/14/main\n</code></pre> <p>There should be bidirectional passwordless SSH communication between <code>pg-repo</code> and <code>pg-secondary</code>. Refer to the Set up passwordless SSH section for the steps, if you haven\u2019t configured it. </p> <p>Stop the PostgreSQL instance</p> <pre><code>$ sudo systemctl stop postgresql\n</code></pre> <p>Restore the database backup from <code>pg-repo</code> to <code>pg-secondary</code>.</p> <pre><code>$ pgbackrest -u postgres --stanza=prod_backup --delta restore\n\n2021-11-07 13:34:08.897 P00   INFO: restore command begin 2.36: --delta --exec-id=109728-d81c7b0b --log-level-console=info --log-level-file=debug --pg1-path=/var/lib/postgresql/14/main --process-max=2 --repo1-host=pg-repo --repo1-host-user=postgres --stanza=prod_backup\n2021-11-07 13:34:09.784 P00   INFO: repo1: restore backup set 20211107-111534F_20211107-131807I, recovery will start at 2021-11-07 13:18:07\n2021-11-07 13:34:09.786 P00   INFO: remove invalid files/links/paths from '/var/lib/postgresql/14/main'\n2021-11-07 13:34:11.803 P00   INFO: write updated /var/lib/postgresql/14/main/postgresql.auto.conf\n2021-11-07 13:34:11.819 P00   INFO: restore global/pg_control (performed last to ensure aborted restores cannot be started)\n2021-11-07 13:34:11.819 P00   INFO: restore size = 23.2MB, file total = 937\n2021-11-07 13:34:11.820 P00   INFO: restore command end: completed successfully (2924ms)\n</code></pre> <p>After the restore completes successfully, restart PostgreSQL:</p> <pre><code>$ sudo systemctl start postgresql\n</code></pre> <p>Check the database contents from the local <code>psql</code> shell. </p> <pre><code>SELECT * FROM customer;\n id |  name  \n----+--------\n  1 | john\n  2 | martha\n  3 | mary\n(3 rows)\n</code></pre> <p></p>"},{"location":"solutions/dr-pgbackrest-setup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/ha-setup-apt.html","title":"Deploying PostgreSQL for high availability with Patroni on Debian or Ubuntu","text":"<p>This guide provides instructions on how to set up a highly available PostgreSQL cluster with Patroni on Debian or Ubuntu. </p>"},{"location":"solutions/ha-setup-apt.html#preconditions","title":"Preconditions","text":"<ol> <li> <p>This is an example deployment where etcd runs on the same host machines as the Patroni and PostgreSQL and there is a single dedicated HAProxy host. Alternatively etcd can run on different set of nodes. </p> <p>If etcd is deployed on the same host machine as Patroni and PostgreSQL, separate disk system for etcd and PostgreSQL is recommended due to performance reasons.</p> </li> <li> <p>For this setup, we will use the nodes running on Ubuntu 22.04 as the base operating system:</p> </li> </ol> Node name Public IP address Internal IP address node1 157.230.42.174 10.104.0.7 node2 68.183.177.183 10.104.0.2 node3 165.22.62.167 10.104.0.8 HAProxy-demo 134.209.111.138 10.104.0.6 <p>Note</p> <p>We recommend not to expose the hosts/nodes where Patroni / etcd / PostgreSQL are running to public networks due to security risks.  Use Firewalls, Virtual networks, subnets or the like to protect the database hosts from any kind of attack. </p>"},{"location":"solutions/ha-setup-apt.html#initial-setup","title":"Initial setup","text":"<p>It\u2019s not necessary to have name resolution, but it makes the whole setup more readable and less error prone. Here, instead of configuring a DNS, we use a local name resolution by updating the file <code>/etc/hosts</code>. By resolving their hostnames to their IP addresses, we make the nodes aware of each other\u2019s names and allow their seamless communication.</p> <ol> <li> <p>Run the following command on each node. Change the node name to <code>node1</code>, <code>node2</code> and <code>node3</code> respectively:</p> <pre><code>$ sudo hostnamectl set-hostname node-1\n</code></pre> </li> <li> <p>Modify the <code>/etc/hosts</code> file of each PostgreSQL node to include the hostnames and IP addresses of the remaining nodes. Add the following at the end of the <code>/etc/hosts</code> file on all nodes:</p> node1node2node3HAproxy-demo <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <p>The HAProxy instance should have the name resolution for all the three nodes in its <code>/etc/hosts</code> file. Add the following lines at the end of the file:    </p> <pre><code># Cluster IP and names\n10.104.0.6 HAProxy-demo\n10.104.0.1 node1\n10.104.0.2 node2\n10.104.0.3 node3\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#install-the-software","title":"Install the software","text":"<p>Run the following commands on <code>node1</code>, <code>node2</code> and <code>node3</code>:</p> <ol> <li> <p>Install Percona Distribution for PostgreSQL</p> <ul> <li> <p>Install <code>percona-release</code> .</p> </li> <li> <p>Enable the repository:</p> </li> </ul> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> <ul> <li>Install Percona Distribution for PostgreSQL packages.</li> </ul> </li> <li> <p>Install some Python and auxiliary packages to help with Patroni and etcd</p> <pre><code>$ sudo apt install python3-pip python3-dev binutils\n</code></pre> </li> <li> <p>Install etcd, Patroni, pgBackRest packages:</p> <pre><code>$ sudo apt install percona-patroni \\\netcd etcd-server etcd-client \\\npercona-pgbackrest\n</code></pre> </li> <li> <p>Stop and disable all installed services:</p> <pre><code>$ sudo systemctl stop {etcd,patroni,postgresql}\n$ systemctl disable {etcd,patroni,postgresql}\n</code></pre> </li> <li> <p>Even though Patroni can use an existing Postgres installation, remove the data directory to force it to initialize a new Postgres cluster instance.</p> </li> </ol> <pre><code>$ sudo systemctl stop postgresql\n$ sudo rm -rf /var/lib/postgresql/17/main\n</code></pre>"},{"location":"solutions/ha-setup-apt.html#configure-etcd-distributed-store","title":"Configure etcd distributed store","text":"<p>The distributed configuration store provides a reliable way to store data that needs to be accessed by large scale distributed systems. The most popular implementation of the distributed configuration store is etcd. etcd is deployed as a cluster for fault-tolerance and requires an odd number of members (n/2+1) to agree on updates to the cluster state. An etcd cluster helps establish a consensus among nodes during a failover and manages the configuration for the three PostgreSQL instances.</p> <p>This document provides configuration for etcd version 3.5.x. For how to configure etcd cluster with earlier versions of etcd, read the blog post by Fernando Laudares Camargos and Jobin Augustine PostgreSQL HA with Patroni: Your Turn to Test Failure Scenarios</p> <p>If you installed the software from tarballs, check how you enable etcd.</p> <p>The <code>etcd</code> cluster is first started in one node and then the subsequent nodes are added to the first node using the <code>add</code>command. </p> <p>Note</p> <p>Users with deeper understanding of how etcd works can configure and start all etcd nodes at a time and bootstrap the cluster using one of the following methods:</p> <ul> <li>Static in the case when the IP addresses of the cluster nodes are known</li> <li>Discovery  service - for cases when the IP addresses of the cluster are not known ahead of time.</li> </ul> <p>See the How to configure etcd nodes simultaneously section for details.</p>"},{"location":"solutions/ha-setup-apt.html#configure-node1","title":"Configure <code>node1</code>","text":"<ol> <li> <p>Create the configuration file. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node name and IP address with the actual name and IP address of your node.</p> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node1'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: new\ninitial-cluster: node1=http://10.104.0.1:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.1:2380 \nlisten-peer-urls: http://10.104.0.1:2380\nadvertise-client-urls: http://10.104.0.1:2379\nlisten-client-urls: http://10.104.0.1:2379\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service to apply the changes on <code>node1</code>.</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>Sample output:</p> <pre><code>21d50d7f768f153a: name=default peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379 isLeader=true\n</code></pre> </li> <li> <p>Add the <code>node2</code> to the cluster. Run the following command on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member add node2 http://10.104.0.2:2380\n</code></pre> Sample output <pre><code>Added member named node2 with ID 10042578c504d052 to cluster\n\netcd_NAME=\"node2\"\netcd_INITIAL_CLUSTER=\"node2=http://10.104.0.2:2380,node1=http://10.104.0.1:2380\"\netcd_INITIAL_CLUSTER_STATE=\"existing\"\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#configure-node2","title":"Configure <code>node2</code>","text":"<ol> <li> <p>Create the configuration file. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node names and IP addresses with the actual names and IP addresses of your nodes.</p> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node2'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: existing\ninitial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.2:2380 \nlisten-peer-urls: http://10.104.0.2:2380\nadvertise-client-urls: http://10.104.0.2:2379\nlisten-client-urls: http://10.104.0.2:2379\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service to apply the changes on <code>node2</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#configure-node3","title":"Configure <code>node3</code>","text":"<ol> <li> <p>Add <code>node3</code> to the cluster. Run the following command on <code>node1</code></p> <pre><code>$ sudo etcdctl member add node3 http://10.104.0.3:2380\n</code></pre> </li> <li> <p>On <code>node3</code>, create the configuration file. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node names and IP addresses with the actual names and IP addresses of your nodes.</p> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node1'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: existing\ninitial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,node3=http://10.104.0.3:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.3:2380 \nlisten-peer-urls: http://10.104.0.3:2380\nadvertise-client-urls: http://10.104.0.3:2379\nlisten-client-urls: http://10.104.0.3:2379\n</code></pre> </li> <li> <p>Start the <code>etcd</code> service to apply the changes.</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl start etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members. </p> <pre><code>$ sudo etcdctl member list\n</code></pre> Sample output <pre><code>2d346bd3ae7f07c4: name=node2 peerURLs=http://10.104.0.2:2380 clientURLs=http://10.104.0.2:2379     isLeader=false\n8bacb519ebdee8db: name=node3 peerURLs=http://10.104.0.3:2380 clientURLs=http://10.104.0.3:2379     isLeader=false\nc5f52ea2ade25e1b: name=node1 peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379     isLeader=true\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#configure-patroni","title":"Configure Patroni","text":"<p>Run the following commands on all nodes. You can do this in parallel:</p> <ol> <li> <p>Export and create environment variables to simplify the config file creation:</p> <ul> <li>Node name:</li> </ul> <pre><code>$ export NODE_NAME=`hostname -f`\n</code></pre> <ul> <li>Node IP:</li> </ul> <pre><code>$ export NODE_IP=`hostname -i | awk '{print $1}'`\n</code></pre> <ul> <li>Create variables to store the PATH:</li> </ul> <pre><code>DATA_DIR=\"/var/lib/postgresql/17/main\"\nPG_BIN_DIR=\"/usr/lib/postgresql/17/bin\"\n</code></pre> <p>NOTE: Check the path to the data and bin folders on your operating system and change it for the variables accordingly.</p> <ul> <li>Patroni information:</li> </ul> <pre><code>NAMESPACE=\"percona_lab\"\nSCOPE=\"cluster_1\"\n</code></pre> </li> <li> <p>Create the <code>/etc/patroni/patroni.yml</code> configuration file. Add the following configuration for <code>node1</code>:</p> <pre><code>echo \"\nnamespace: ${NAMESPACE}\nscope: ${SCOPE}\nname: ${NODE_NAME}\n\nrestapi:\n    listen: 0.0.0.0:8008\n    connect_address: ${NODE_IP}:8008\n\netcd3:\n    host: ${NODE_IP}:2379\n\nbootstrap:\n  # this section will be written into Etcd:/&lt;namespace&gt;/&lt;scope&gt;/config after initializing new cluster\n  dcs:\n      ttl: 30\n      loop_wait: 10\n      retry_timeout: 10\n      maximum_lag_on_failover: 1048576\n\n      postgresql:\n          use_pg_rewind: true\n          use_slots: true\n          parameters:\n              wal_level: replica\n              hot_standby: \"on\"\n              wal_keep_segments: 10\n              max_wal_senders: 5\n              max_replication_slots: 10\n              wal_log_hints: \"on\"\n              logging_collector: 'on'\n              max_wal_size: '10GB'\n              archive_mode: \"on\"\n              archive_timeout: 600s\n              archive_command: \"cp -f %p /home/postgres/archived/%f\"\n\n  # some desired options for 'initdb'\n  initdb: # Note: It needs to be a list (some options need values, others are switches)\n      - encoding: UTF8\n      - data-checksums\n\n  pg_hba: # Add following lines to pg_hba.conf after running 'initdb'\n      - host replication replicator 127.0.0.1/32 trust\n      - host replication replicator 0.0.0.0/0 md5\n      - host all all 0.0.0.0/0 md5\n      - host all all ::0/0 md5\n\n  # Some additional users which needs to be created after initializing new cluster\n  users:\n      admin:\n          password: qaz123\n          options:\n              - createrole\n              - createdb\n      percona:\n          password: qaz123\n          options:\n              - createrole\n              - createdb \n\npostgresql:\n    cluster_name: cluster_1\n    listen: 0.0.0.0:5432\n    connect_address: ${NODE_IP}:5432\n    data_dir: ${DATA_DIR}\n    bin_dir: ${PG_BIN_DIR}\n    pgpass: /tmp/pgpass0\n    authentication:\n        replication:\n            username: replicator\n            password: replPasswd\n        superuser:\n            username: postgres\n            password: qaz123\n    parameters:\n        unix_socket_directories: \"/var/run/postgresql/\"\n    create_replica_methods:\n        - basebackup\n    basebackup:\n        checkpoint: 'fast'\n\ntags:\n    nofailover: false\n    noloadbalance: false\n    clonefrom: false\n    nosync: false\n\" | sudo tee -a /etc/patroni/patroni.yml\n</code></pre> Patroni configuration file <p>Let\u2019s take a moment to understand the contents of the <code>patroni.yml</code> file. </p> <p>The first section provides the details of the node and its connection ports. After that, we have the <code>etcd</code> service and its port details.</p> <p>Following these, there is a <code>bootstrap</code> section that contains the PostgreSQL configurations and the steps to run once the database is initialized. The <code>pg_hba.conf</code> entries specify all the other nodes that can connect to this node and their authentication mechanism. </p> </li> <li> <p>Check that the systemd unit file <code>patroni.service</code> is created in <code>/etc/systemd/system</code>. If it is created, skip this step. </p> <p>If it\u2019s not created, create it manually and specify the following contents within:</p> /etc/systemd/system/patroni.service<pre><code>[Unit]\n Description=Runners to orchestrate a high-availability PostgreSQL\n After=syslog.target network.target \n\n [Service]\n Type=simple \n\n User=postgres\n Group=postgres \n\n # Start the patroni process\n ExecStart=/bin/patroni /etc/patroni/patroni.yml \n\n # Send HUP to reload from patroni.yml\n ExecReload=/bin/kill -s HUP $MAINPID \n\n # only kill the patroni process, not its children, so it will gracefully stop postgres\n KillMode=process \n\n # Give a reasonable amount of time for the server to start up/shut down\n TimeoutSec=30 \n\n # Do not restart the service if it crashes, we want to manually inspect database on failure\n Restart=no \n\n [Install]\n WantedBy=multi-user.target\n</code></pre> </li> <li> <p>Make systemd aware of the new service:</p> <pre><code>$ sudo systemctl daemon-reload\n</code></pre> </li> <li> <p>Now it\u2019s time to start Patroni. You need the following commands on all nodes but not in parallel. Start with the <code>node1</code> first, wait for the service to come to live, and then proceed with the other nodes one-by-one, always waiting for them to sync with the primary node:</p> <pre><code>$ sudo systemctl enable --now patroni\n$ sudo systemctl restart patroni\n</code></pre> <p>When Patroni starts, it initializes PostgreSQL (because the service is not currently running and the data directory is empty) following the directives in the bootstrap section of the configuration file. </p> </li> <li> <p>Check the service to see if there are errors:</p> <pre><code>$ sudo journalctl -fu patroni\n</code></pre> <p>A common error is Patroni complaining about the lack of proper entries in the pg_hba.conf file. If you see such errors, you must manually add or fix the entries in that file and then restart the service.</p> <p>Changing the patroni.yml file and restarting the service will not have any effect here because the bootstrap section specifies the configuration to apply when PostgreSQL is first started in the node. It will not repeat the process even if the Patroni configuration file is modified and the service is restarted.</p> </li> <li> <p>Check the cluster:</p> <pre><code>$ patronictl -c /etc/patroni/patroni.yml list $SCOPE\n</code></pre> <p>The output on <code>node1</code> resembles the following:</p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> <p>On the remaining nodes:</p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n| node-2 | 10.0.100.2  | Replica | running |  1 |         0 |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> </li> </ol> <p>If Patroni has started properly, you should be able to locally connect to a PostgreSQL node using the following command:</p> <pre><code>$ sudo psql -U postgres\n</code></pre> <p>The command output is the following:</p> <pre><code>psql (17.0)\nType \"help\" for help.\n\npostgres=#\n</code></pre>"},{"location":"solutions/ha-setup-apt.html#configure-haproxy","title":"Configure HAProxy","text":"<p>HAproxy is the load balancer and the single point of entry to your PostgreSQL cluster for client applications. A client application accesses the HAPpoxy URL and sends its read/write requests there. Behind-the-scene, HAProxy routes write requests to the primary node and read requests - to the secondaries in a round-robin fashion so that no secondary instance is unnecessarily loaded. To make this happen, provide different ports in the HAProxy configuration file. In this deployment, writes are routed to port 5000 and reads  - to port 5001</p> <p>This way, a client application doesn\u2019t know what node in the underlying cluster is the current primary. HAProxy sends connections to a healthy node (as long as there is at least one healthy node available) and ensures that client application requests are never rejected. </p> <ol> <li> <p>Install HAProxy on the <code>HAProxy-demo</code> node:</p> <pre><code>$ sudo apt install percona-haproxy\n</code></pre> </li> <li> <p>The HAProxy configuration file path is: <code>/etc/haproxy/haproxy.cfg</code>. Specify the following configuration in this file.</p> <pre><code>global\n    maxconn 100\n\ndefaults\n    log global\n    mode tcp\n    retries 2\n    timeout client 30m\n    timeout connect 4s\n    timeout server 30m\n    timeout check 5s\n\nlisten stats\n    mode http\n    bind *:7000\n    stats enable\n    stats uri /\n\nlisten primary\n    bind *:5000\n    option httpchk /primary \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n\nlisten standbys\n    balance roundrobin\n    bind *:5001\n    option httpchk /replica \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n</code></pre> <p>HAProxy will use the REST APIs hosted by Patroni to check the health status of each PostgreSQL node and route the requests appropriately. </p> </li> <li> <p>Restart HAProxy:</p> <pre><code>$ sudo systemctl restart haproxy\n</code></pre> </li> <li> <p>Check the HAProxy logs to see if there are any errors:</p> <pre><code>$ sudo journalctl -u haproxy.service -n 100 -f\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-apt.html#next-steps","title":"Next steps","text":"<p>Configure pgBackRest</p> <p></p>"},{"location":"solutions/ha-setup-apt.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/ha-setup-yum.html","title":"Deploying PostgreSQL for high availability with Patroni on RHEL or CentOS","text":"<p>This guide provides instructions on how to set up a highly available PostgreSQL cluster with Patroni on Red Hat Enterprise Linux or CentOS. </p>"},{"location":"solutions/ha-setup-yum.html#considerations","title":"Considerations","text":"<ol> <li> <p>This is an example deployment where etcd runs on the same host machines as the Patroni and PostgreSQL and there is a single dedicated HAProxy host. Alternatively etcd can run on different set of nodes. </p> <p>If etcd is deployed on the same host machine as Patroni and PostgreSQL, separate disk system for etcd and PostgreSQL is recommended due to performance reasons.</p> </li> <li> <p>For this setup, we use the nodes running on Red Hat Enterprise Linux 8 as the base operating system:</p> Node name Application IP address node1 Patroni, PostgreSQL, etcd 10.104.0.1 node2 Patroni, PostgreSQL, etcd 10.104.0.2 node3 Patroni, PostgreSQL, etcd 10.104.0.3 HAProxy-demo HAProxy 10.104.0.6 </li> </ol> <p>Note</p> <p>We recommend not to expose the hosts/nodes where Patroni / etcd / PostgreSQL are running to public networks due to security risks.  Use Firewalls, Virtual networks, subnets or the like to protect the database hosts from any kind of attack.   </p>"},{"location":"solutions/ha-setup-yum.html#initial-setup","title":"Initial setup","text":""},{"location":"solutions/ha-setup-yum.html#set-up-hostnames-in-the-etchosts-file","title":"Set up hostnames in the <code>/etc/hosts</code> file","text":"<p>It\u2019s not necessary to have name resolution, but it makes the whole setup more readable and less error prone. Here, instead of configuring a DNS, we use a local name resolution by updating the file <code>/etc/hosts</code>. By resolving their hostnames to their IP addresses, we make the nodes aware of each other\u2019s names and allow their seamless communication. </p> <ol> <li> <p>Run the following command on each node. Change the node name to <code>node1</code>, <code>node2</code> and <code>node3</code> respectively:</p> <pre><code>$ sudo hostnamectl set-hostname node-1\n</code></pre> </li> <li> <p>Modify the <code>/etc/hosts</code> file of each PostgreSQL node to include the hostnames and IP addresses of the remaining nodes. Add the following at the end of the <code>/etc/hosts</code> file on all nodes:</p> node1node2node3HAproxy-demo <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <pre><code># Cluster IP and names \n10.104.0.1 node1 \n10.104.0.2 node2 \n10.104.0.3 node3\n</code></pre> <p>The HAProxy instance should have the name resolution for all the three nodes in its <code>/etc/hosts</code> file. Add the following lines at the end of the file:    </p> <pre><code># Cluster IP and names\n10.104.0.6 HAProxy-demo\n10.104.0.1 node1\n10.104.0.2 node2\n10.104.0.3 node3\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#install-the-software","title":"Install the software","text":"<ol> <li> <p>Install Percona Distribution for PostgreSQL on <code>node1</code>, <code>node2</code> and <code>node3</code> from Percona repository:</p> <ul> <li>Install <code>percona-release</code> .</li> <li> <p>Enable the repository:    </p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install Percona Distribution for PostgreSQL packages.    </p> </li> </ul> <p>Important</p> <p>Don\u2019t initialize the cluster and start the <code>postgresql</code> service. The cluster initialization and setup are handled by Patroni during the bootsrapping stage.</p> </li> <li> <p>Install some Python and auxiliary packages to help with Patroni and etcd</p> <pre><code>$ sudo yum install python3-pip python3-devel binutils\n</code></pre> </li> <li> <p>Install etcd, Patroni, pgBackRest packages. Check platform specific notes for Patroni:</p> <pre><code>$ sudo yum install percona-patroni \\\netcd python3-python-etcd\\\npercona-pgbackrest\n</code></pre> </li> <li> <p>Stop and disable all installed services:</p> <pre><code>$ sudo systemctl stop {etcd,patroni,postgresql}\n$ systemctl disable {etcd,patroni,postgresql}\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-etcd-distributed-store","title":"Configure etcd distributed store","text":"<p>The distributed configuration store provides a reliable way to store data that needs to be accessed by large scale distributed systems. The most popular implementation of the distributed configuration store is etcd. etcd is deployed as a cluster for fault-tolerance and requires an odd number of members (n/2+1) to agree on updates to the cluster state. An etcd cluster helps establish a consensus among nodes during a failover and manages the configuration for the three PostgreSQL instances.</p> <p>This document provides configuration for etcd version 3.5.x. For how to configure etcd cluster with earlier versions of etcd, read the blog post by Fernando Laudares Camargos and Jobin Augustine PostgreSQL HA with Patroni: Your Turn to Test Failure Scenarios.</p> <p>If you installed the software from tarballs, check how you enable etcd.</p> <p>The <code>etcd</code> cluster is first started in one node and then the subsequent nodes are added to the first node using the <code>add</code>command. </p> <p>Note</p> <p>Users with deeper understanding of how etcd works can configure and start all etcd nodes at a time and bootstrap the cluster using one of the following methods:</p> <ul> <li>Static in the case when the IP addresses of the cluster nodes are known</li> <li>Discovery  service - for cases when the IP addresses of the cluster are not known ahead of time.</li> </ul> <p>See the How to configure etcd nodes simultaneously section for details.</p>"},{"location":"solutions/ha-setup-yum.html#configure-node1","title":"Configure <code>node1</code>","text":"<ol> <li> <p>Create the configuration file. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node name and IP address with the actual name and IP address of your node.</p> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node1'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: new\ninitial-cluster: node1=http://10.104.0.1:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.1:2380 \nlisten-peer-urls: http://10.104.0.1:2380\nadvertise-client-urls: http://10.104.0.1:2379\nlisten-client-urls: http://10.104.0.1:2379\n</code></pre> </li> <li> <p>Enable and start the <code>etcd</code> service to apply the changes on <code>node1</code>.</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member list\n</code></pre> <p>Sample output:</p> <pre><code>21d50d7f768f153a: name=default peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379 isLeader=true\n</code></pre> </li> <li> <p>Add the <code>node2</code> to the cluster. Run the following command on <code>node1</code>:</p> <pre><code>$ sudo etcdctl member add node2 http://10.104.0.2:2380\n</code></pre> Sample output <pre><code>Added member named node2 with ID 10042578c504d052 to cluster\n\netcd_NAME=\"node2\"\netcd_INITIAL_CLUSTER=\"node2=http://10.104.0.2:2380,node1=http://10.104.0.1:2380\"\netcd_INITIAL_CLUSTER_STATE=\"existing\"\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-node2","title":"Configure <code>node2</code>","text":"<ol> <li> <p>Create the configuration file. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node names and IP addresses with the actual names and IP addresses of your nodes.</p> /etc/etcd/etcd.conf.yaml<pre><code>name: 'node2'\ninitial-cluster-token: PostgreSQL_HA_Cluster_1\ninitial-cluster-state: existing\ninitial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380\ndata-dir: /var/lib/etcd\ninitial-advertise-peer-urls: http://10.104.0.2:2380 \nlisten-peer-urls: http://10.104.0.2:2380\nadvertise-client-urls: http://10.104.0.2:2379\nlisten-client-urls: http://10.104.0.2:2379\n</code></pre> </li> <li> <p>Enable and start the <code>etcd</code> service to apply the changes on <code>node2</code>:</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl status etcd\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-node3","title":"Configure <code>node3</code>","text":"<ol> <li> <p>Add <code>node3</code> to the cluster. Run the following command on <code>node1</code></p> <pre><code>$ sudo etcdctl member add node3 http://10.104.0.3:2380\n</code></pre> </li> <li> <p>On <code>node3</code>, create the configuration file. You can edit the sample configuration file <code>/etc/etcd/etcd.conf.yaml</code> or create your own one. Replace the node names and IP addresses with the actual names and IP addresses of your nodes.</p> <pre><code> ```yaml title=\"/etc/etcd/etcd.conf.yaml\"\n name: 'node1'\n initial-cluster-token: PostgreSQL_HA_Cluster_1\n initial-cluster-state: existing\n initial-cluster: node1=http://10.104.0.1:2380,node2=http://10.104.0.2:2380,node3=http://10.104.0.3:2380\n data-dir: /var/lib/etcd\n initial-advertise-peer-urls: http://10.104.0.3:2380 \n listen-peer-urls: http://10.104.0.3:2380\n advertise-client-urls: http://10.104.0.3:2379\n listen-client-urls: http://10.104.0.3:2379\n ```\n</code></pre> </li> <li> <p>Enable and start the <code>etcd</code> service to apply the changes.</p> <pre><code>$ sudo systemctl enable --now etcd\n$ sudo systemctl status etcd\n</code></pre> </li> <li> <p>Check the etcd cluster members. </p> <pre><code>$ sudo etcdctl member list\n</code></pre> Sample output <pre><code>2d346bd3ae7f07c4: name=node2 peerURLs=http://10.104.0.2:2380 clientURLs=http://10.104.0.2:2379     isLeader=false\n8bacb519ebdee8db: name=node3 peerURLs=http://10.104.0.3:2380 clientURLs=http://10.104.0.3:2379     isLeader=false\nc5f52ea2ade25e1b: name=node1 peerURLs=http://10.104.0.1:2380 clientURLs=http://10.104.0.1:2379     isLeader=true\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-patroni","title":"Configure Patroni","text":"<p>Run the following commands on all nodes. You can do this in parallel:</p> <ol> <li> <p>Export and create environment variables to simplify the config file creation:</p> <ul> <li>Node name:</li> </ul> <pre><code>$ export NODE_NAME=`hostname -f`\n</code></pre> <ul> <li>Node IP:</li> </ul> <pre><code>$ export NODE_IP=`hostname -i | awk '{print $1}'`\n</code></pre> <ul> <li>Create variables to store the PATH:</li> </ul> <pre><code>DATA_DIR=\"/var/lib/pgsql/data/\"\nPG_BIN_DIR=\"/usr/pgsql-17/bin\"\n</code></pre> <p>NOTE: Check the path to the data and bin folders on your operating system and change it for the variables accordingly.</p> <ul> <li>Patroni information:</li> </ul> <pre><code>NAMESPACE=\"percona_lab\"\nSCOPE=\"cluster_1\n</code></pre> </li> <li> <p>Create the directories required by Patroni</p> <ul> <li>Create the directory to store the configuration file and make it owned by the <code>postgres</code> user.</li> </ul> <pre><code>$ sudo mkdir -p /etc/patroni/\n$ sudo chown -R  postgres:postgres /etc/patroni/\n</code></pre> <ul> <li>Create the data directory to store PostgreSQL data. Change its ownership to the <code>postgres</code> user and restrict the access to it </li> </ul> <pre><code>$ sudo mkdir /data/pgsql -p\n$ sudo chown -R postgres:postgres /data/pgsql\n$ sudo chmod 700 /data/pgsql\n</code></pre> </li> <li> <p>Create the <code>/etc/patroni/patroni.yml</code> configuration file. Add the following configuration:</p> <pre><code>echo \"\nnamespace: ${NAMESPACE}\nscope: ${SCOPE}\nname: ${NODE_NAME}\n\nrestapi:\n    listen: 0.0.0.0:8008\n    connect_address: ${NODE_IP}:8008\n\netcd3:\n    host: ${NODE_IP}:2379\n\nbootstrap:\n  # this section will be written into Etcd:/&lt;namespace&gt;/&lt;scope&gt;/config after initializing new cluster\n  dcs:\n      ttl: 30\n      loop_wait: 10\n      retry_timeout: 10\n      maximum_lag_on_failover: 1048576\n\n      postgresql:\n          use_pg_rewind: true\n          use_slots: true\n          parameters:\n              wal_level: replica\n              hot_standby: \"on\"\n              wal_keep_segments: 10\n              max_wal_senders: 5\n              max_replication_slots: 10\n              wal_log_hints: \"on\"\n              logging_collector: 'on'\n              max_wal_size: '10GB'\n              archive_mode: \"on\"\n              archive_timeout: 600s\n              archive_command: \"cp -f %p /home/postgres/archived/%f\"\n\n  # some desired options for 'initdb'\n  initdb: # Note: It needs to be a list (some options need values, others are switches)\n      - encoding: UTF8\n      - data-checksums\n\n  pg_hba: # Add following lines to pg_hba.conf after running 'initdb'\n      - host replication replicator 127.0.0.1/32 trust\n      - host replication replicator 0.0.0.0/0 md5\n      - host all all 0.0.0.0/0 md5\n      - host all all ::0/0 md5\n\n  # Some additional users which needs to be created after initializing new cluster\n  users:\n      admin:\n          password: qaz123\n          options:\n              - createrole\n              - createdb\n      percona:\n          password: qaz123\n          options:\n              - createrole\n              - createdb \n\npostgresql:\n    cluster_name: cluster_1\n    listen: 0.0.0.0:5432\n    connect_address: ${NODE_IP}:5432\n    data_dir: ${DATA_DIR}\n    bin_dir: ${PG_BIN_DIR}\n    pgpass: /tmp/pgpass0\n    authentication:\n        replication:\n            username: replicator\n            password: replPasswd\n        superuser:\n            username: postgres\n            password: qaz123\n    parameters:\n        unix_socket_directories: \"/var/run/postgresql/\"\n    create_replica_methods:\n        - basebackup\n    basebackup:\n        checkpoint: 'fast'\n\ntags:\n    nofailover: false\n    noloadbalance: false\n    clonefrom: false\n    nosync: false\n\" | sudo tee -a /etc/patroni/patroni.yml\n</code></pre> </li> <li> <p>Check that the systemd unit file <code>patroni.service</code> is created in <code>/etc/systemd/system</code>. If it is created, skip this step. </p> <p>If it\u2019s not created, create it manually and specify the following contents within:</p> /etc/systemd/system/patroni.service<pre><code>[Unit]\nDescription=Runners to orchestrate a high-availability PostgreSQL\nAfter=syslog.target network.target \n\n[Service]\nType=simple \n\nUser=postgres\nGroup=postgres \n\n# Start the patroni process\nExecStart=/bin/patroni /etc/patroni/patroni.yml \n\n# Send HUP to reload from patroni.yml\nExecReload=/bin/kill -s HUP $MAINPID \n\n# only kill the patroni process, not its children, so it will gracefully stop postgres\nKillMode=process \n\n# Give a reasonable amount of time for the server to start up/shut down\nTimeoutSec=30 \n\n# Do not restart the service if it crashes, we want to manually inspect database on failure\nRestart=no \n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Make <code>systemd</code> aware of the new service:</p> <pre><code>$ sudo systemctl daemon-reload\n</code></pre> </li> <li> <p>Now it\u2019s time to start Patroni. You need the following commands on all nodes but not in parallel. Start with the <code>node1</code> first, wait for the service to come to live, and then proceed with the other nodes one-by-one, always waiting for them to sync with the primary node:</p> <pre><code>$ sudo systemctl enable --now patroni\n$ sudo systemctl restart patroni\n</code></pre> </li> </ol> <p>When Patroni starts, it initializes PostgreSQL (because the service is not currently running and the data directory is empty) following the directives in the bootstrap section of the configuration file. </p> <ol> <li> <p>Check the service to see if there are errors:</p> <pre><code>$ sudo journalctl -fu patroni\n</code></pre> <p>A common error is Patroni complaining about the lack of proper entries in the pg_hba.conf file. If you see such errors, you must manually add or fix the entries in that file and then restart the service.</p> <p>Changing the patroni.yml file and restarting the service will not have any effect here because the bootstrap section specifies the configuration to apply when PostgreSQL is first started in the node. It will not repeat the process even if the Patroni configuration file is modified and the service is restarted. </p> <p>If Patroni has started properly, you should be able to locally connect to a PostgreSQL node using the following command:</p> <pre><code>$ sudo psql -U postgres\n\npsql (17.0)\nType \"help\" for help.\n\npostgres=#\n</code></pre> </li> <li> <p>When all nodes are up and running, you can check the cluster status using the following command:</p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml list\n</code></pre> <p>The output on <code>node1</code> resembles the following: </p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> <p>On the remaining nodes:</p> <pre><code>+ Cluster: cluster_1 --+---------+---------+----+-----------+\n| Member | Host        | Role    | State   | TL | Lag in MB |\n+--------+-------------+---------+---------+----+-----------+\n| node-1 | 10.0.100.1  | Leader  | running |  1 |           |\n| node-2 | 10.0.100.2  | Replica | running |  1 |         0 |\n+--------+-------------+---------+---------+----+-----------+\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#configure-haproxy","title":"Configure HAProxy","text":"<p>HAproxy is the load balancer and the single point of entry to your PostgreSQL cluster for client applications. A client application accesses the HAPpoxy URL and sends its read/write requests there. Behind-the-scene, HAProxy routes write requests to the primary node and read requests - to the secondaries in a round-robin fashion so that no secondary instance is unnecessarily loaded. To make this happen, provide different ports in the HAProxy configuration file. In this deployment, writes are routed to port 5000 and reads  - to port 5001</p> <p>This way, a client application doesn\u2019t know what node in the underlying cluster is the current primary. HAProxy sends connections to a healthy node (as long as there is at least one healthy node available) and ensures that client application requests are never rejected. </p> <ol> <li> <p>Install HAProxy on the <code>HAProxy-demo</code> node:</p> <pre><code>$ sudo yum install percona-haproxy\n</code></pre> </li> <li> <p>The HAProxy configuration file path is: <code>/etc/haproxy/haproxy.cfg</code>. Specify the following configuration in this file.</p> <pre><code>global\n    maxconn 100\n\ndefaults\n    log global\n    mode tcp\n    retries 2\n    timeout client 30m\n    timeout connect 4s\n    timeout server 30m\n    timeout check 5s\n\nlisten stats\n    mode http\n    bind *:7000\n    stats enable\n    stats uri /\n\nlisten primary\n    bind *:5000\n    option httpchk /primary \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n\nlisten standbys\n    balance roundrobin\n    bind *:5001\n    option httpchk /replica \n    http-check expect status 200\n    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions\n    server node1 node1:5432 maxconn 100 check port 8008\n    server node2 node2:5432 maxconn 100 check port 8008\n    server node3 node3:5432 maxconn 100 check port 8008\n</code></pre> <p>HAProxy will use the REST APIs hosted by Patroni to check the health status of each PostgreSQL node and route the requests appropriately. </p> </li> <li> <p>Enable a SELinux boolean to allow HAProxy to bind to non standard ports:</p> <pre><code>$ sudo setsebool -P haproxy_connect_any on\n</code></pre> </li> <li> <p>Restart HAProxy:</p> <pre><code>$ sudo systemctl restart haproxy\n</code></pre> </li> <li> <p>Check the HAProxy logs to see if there are any errors:</p> <pre><code>$ sudo journalctl -u haproxy.service -n 100 -f\n</code></pre> </li> </ol>"},{"location":"solutions/ha-setup-yum.html#next-steps","title":"Next steps","text":"<p>Configure pgBackRest</p> <p></p>"},{"location":"solutions/ha-setup-yum.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/ha-test.html","title":"Testing the Patroni PostgreSQL Cluster","text":"<p>This document covers the following scenarios to test the PostgreSQL cluster:</p> <ul> <li>replication, </li> <li>connectivity, </li> <li>failover, and </li> <li>manual switchover.</li> </ul>"},{"location":"solutions/ha-test.html#testing-replication","title":"Testing replication","text":"<ol> <li> <p>Connect to the cluster and establish the <code>psql</code> session from a client machine that can connect to the HAProxy node. Use the HAProxy-demo node\u2019s public IP address:</p> <pre><code>$ psql -U postgres -h 134.209.111.138 -p 5000\n</code></pre> </li> <li> <p>Run the following commands to create a table and insert a few rows:</p> <pre><code>CREATE TABLE customer(name text,age integer);\nINSERT INTO CUSTOMER VALUES('john',30);\nINSERT INTO CUSTOMER VALUES('dawson',35);\n</code></pre> </li> <li> <p>To ensure that the replication is working, we can log in to each PostgreSQL node and run a simple SQL statement against the locally running instance:</p> <pre><code>$ sudo psql -U postgres -c \"SELECT * FROM CUSTOMER;\"\n</code></pre> <p>The results on each node should be the following:</p> <pre><code>  name  | age\n--------+-----\n john   |  30\n dawson |  35\n(2 rows)\n</code></pre> </li> </ol>"},{"location":"solutions/ha-test.html#testing-failover","title":"Testing failover","text":"<p>In a proper setup, client applications won\u2019t have issues connecting to the cluster, even if one or even two of the nodes go down. We will test the cluster for failover in the following scenarios:</p>"},{"location":"solutions/ha-test.html#scenario-1-intentionally-stop-the-postgresql-on-the-primary-node-and-verify-access-to-postgresql","title":"Scenario 1. Intentionally stop the PostgreSQL on the primary node and verify access to PostgreSQL.","text":"<ol> <li> <p>Run the following command on any node to check the current cluster status:</p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml list\n</code></pre> <p>Output:</p> <pre><code>+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Leader  | running |  1 |           |\n| node2  | node2 | Replica | running |  1 |         0 |\n| node3  | node3 | Replica | running |  1 |         0 |\n+--------+-------+---------+---------+----+-----------+\n</code></pre> </li> <li> <p><code>node1</code> is the current leader. Stop Patroni in <code>node1</code> to see how it changes the cluster:</p> <pre><code>$ sudo systemctl stop patroni\n</code></pre> </li> <li> <p>Once the service stops in <code>node1</code>, check the logs in <code>node2</code> and <code>node3</code> using the following command: </p> <pre><code>$ sudo journalctl -u patroni.service -n 100 -f\n</code></pre> Output <pre><code>Sep 23 14:18:13 node03 patroni[10042]: 2021-09-23 14:18:13,905 INFO: no action. I am a secondary (node3) and following a leader (node1)\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,011 INFO: Got response from node2 http://node2:8008/patroni: {\"state\": \"running\", \"postprimary_start_time\": \"2021-09-23 12:50:29.460027+00:00\", \"role\": \"replica\", \"server_version\": 130003, \"cluster_unlocked\": true, \"xlog\": {\"received_location\": 67219152, \"replayed_location\": 67219152, \"replayed_timestamp\": \"2021-09-23 13:19:50.329387+00:00\", \"paused\": false}, \"timeline\": 1, \"database_system_identifier\": \"7011110722654005156\", \"patroni\": {\"version\": \"2.1.0\", \"scope\": \"stampede1\"}}\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,031 WARNING: Request failed to node1: GET http://node1:8008/patroni (HTTPConnectionPool(host='node1', port=8008): Max retries exceeded with url: /patroni (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))))\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,038 INFO: Software Watchdog activated with 25 second timeout, timing slack 15 seconds\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,043 INFO: promoted self to leader by acquiring session lock\nSep 23 14:18:20 node03 patroni[13641]: server promoting\nSep 23 14:18:20 node03 patroni[10042]: 2021-09-23 14:18:20,049 INFO: cleared rewind state after becoming the leader\nSep 23 14:18:21 node03 patroni[10042]: 2021-09-23 14:18:21,101 INFO: no action. I am (node3) the leader with the lock\nSep 23 14:18:21 node03 patroni[10042]: 2021-09-23 14:18:21,117 INFO: no action. I am (node3) the leader with the lock\nSep 23 14:18:31 node03 patroni[10042]: 2021-09-23 14:18:31,114 INFO: no action. I am (node3) the leader with the lock\n...\n</code></pre> <p>The logs in <code>node3</code> show that the requests to <code>node1</code> are failing, the watchdog is coming into action, and <code>node3</code> is promoting itself as the leader:</p> </li> <li> <p>Verify that you can still access the cluster through the HAProxy instance and read data:</p> <pre><code>$ psql -U postgres -h 10.104.0.3 -p 5000 -c \"SELECT * FROM CUSTOMER;\"\n\n  name  | age\n--------+-----\n john   |  30\n dawson |  35\n(2 rows)\n</code></pre> </li> <li> <p>Restart the Patroni service in <code>node1</code></p> <pre><code>$ sudo systemctl start patroni\n</code></pre> </li> <li> <p>Check the current cluster status:  </p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml list\n</code></pre> <p>Output:</p> <pre><code>+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Replica | running |  2 |         0 |\n| node2  | node2 | Replica | running |  2 |         0 |\n| node3  | node3 | Leader  | running |  2 |           |\n+--------+-------+---------+---------+----+-----------+\n</code></pre> </li> </ol> <p>As we see, <code>node3</code> remains the leader and the rest are replicas.</p>"},{"location":"solutions/ha-test.html#scenario-2-abrupt-machine-shutdown-or-power-outage","title":"Scenario 2. Abrupt machine shutdown or power outage","text":"<p>To emulate the power outage, let\u2019s kill the service in <code>node3</code> and see what happens in <code>node1</code> and <code>node2</code>. </p> <ol> <li> <p>Identify the process ID of Patroni and then kill it with a <code>-9</code> switch. </p> <pre><code>$ ps aux | grep -i patroni\n\npostgres   10042  0.1  2.1 647132 43948 ?        Ssl  12:50   0:09 /usr/bin/python3 /usr/bin/patroni /etc/patroni/patroni.yml\n\n$ sudo kill -9 10042\n</code></pre> </li> <li> <p>Check the logs on <code>node2</code>: </p> <pre><code>$ sudo journalctl -u patroni.service -n 100 -f\n</code></pre> Output <pre><code>Sep 23 14:40:41 node02 patroni[10577]: 2021-09-23 14:40:41,656 INFO: no action. I am a secondary (node2) and following a leader (node3)\n\u2026\nSep 23 14:41:01 node02 patroni[10577]: 2021-09-23 14:41:01,373 INFO: Got response from node1 http://node1:8008/patroni: {\"state\": \"running\", \"postprimary_start_time\": \"2021-09-23 14:25:30.076762+00:00\", \"role\": \"replica\", \"server_version\": 130003, \"cluster_unlocked\": true, \"xlog\": {\"received_location\": 67221352, \"replayed_location\": 67221352, \"replayed_timestamp\": null, \"paused\": false}, \"timeline\": 2, \"database_system_identifier\": \"7011110722654005156\", \"patroni\": {\"version\": \"2.1.0\", \"scope\": \"stampede1\"}}\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,364 WARNING: Request failed to node3: GET http://node3:8008/patroni (HTTPConnectionPool(host='node3', port=8008): Max retries exceeded with url: /patroni (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPConnection object at 0x7f57e06dffa0&gt;, 'Connection to node3 timed out. (connect timeout=2)')))\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,373 INFO: Software Watchdog activated with 25 second timeout, timing slack 15 seconds\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,385 INFO: promoted self to leader by acquiring session lock\nSep 23 14:41:03 node02 patroni[15478]: server promoting\nSep 23 14:41:03 node02 patroni[10577]: 2021-09-23 14:41:03,397 INFO: cleared rewind state after becoming the leader\nSep 23 14:41:04 node02 patroni[10577]: 2021-09-23 14:41:04,450 INFO: no action. I am (node2) the leader with the lock\nSep 23 14:41:04 node02 patroni[10577]: 2021-09-23 14:41:04,475 INFO: no action. I am (node2) the leader with the lock\n\u2026\n\u2026 \n</code></pre> <p><code>node2</code> realizes that the leader is dead, and promotes itself as the leader.</p> </li> <li> <p>Try accessing the cluster using the HAProxy endpoint at any point in time between these operations. The cluster is still accepting connections.</p> </li> </ol>"},{"location":"solutions/ha-test.html#manual-switchover","title":"Manual switchover","text":"<p>Typically, a manual switchover is needed for planned downtime to perform maintenance activity on the leader node. Patroni provides the <code>switchover</code> command to manually switch over from the leader node. </p> <p>Run the following command on <code>node2</code> (the current leader node):</p> <pre><code>$ sudo patronictl -c /etc/patroni/patroni.yml switchover\n</code></pre> <p>Patroni asks the name of the current primary node and then the node that should take over as the switched-over primary. You can also specify the time at which the switchover should happen. To trigger the process immediately, specify the value now:</p> <pre><code>primary [node2]: node2\nCandidate ['node1', 'node3'] []: node1\nWhen should the switchover take place (e.g. 2021-09-23T15:56 )  [now]: now\nCurrent cluster topology\n+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Replica | running |  3 |         0 |\n| node2  | node2 | Leader  | running |  3 |           |\n| node3  | node3 | Replica | stopped |    |   unknown |\n+--------+-------+---------+---------+----+-----------+\nAre you sure you want to switchover cluster stampede1, demoting current primary node2? [y/N]: y\n2021-09-23 14:56:40.54009 Successfully switched over to \"node1\"\n+ Cluster: stampede1 (7011110722654005156) -----------+\n| Member | Host  | Role    | State   | TL | Lag in MB |\n+--------+-------+---------+---------+----+-----------+\n| node1  | node1 | Leader  | running |  3 |           |\n| node2  | node2 | Replica | stopped |    |   unknown |\n| node3  | node3 | Replica | stopped |    |   unknown |\n+--------+-------+---------+---------+----+-----------+\n</code></pre> <p>Restart the Patroni service in <code>node2</code> (after the \u201cplanned maintenance\u201d). The node rejoins the cluster as a secondary.</p> <p></p>"},{"location":"solutions/ha-test.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/high-availability.html","title":"High Availability in PostgreSQL with Patroni","text":"<p>PostgreSQL has been widely adopted as a modern, high-performance transactional database. A highly available PostgreSQL cluster can withstand failures caused by network outages, resource saturation, hardware failures, operating system crashes or unexpected reboots. Such cluster is often a critical component of the enterprise application landscape, where four nines of availability  is a minimum requirement. </p> <p>There are several methods to achieve high availability in PostgreSQL. This solution document provides Patroni - the open-source extension to facilitate and manage the deployment of high availability in PostgreSQL.</p> High availability methods <p>There are several native methods for achieving high availability with PostgreSQL:</p> <ul> <li>shared disk failover, </li> <li>file system replication, </li> <li>trigger-based replication, </li> <li>statement-based replication, </li> <li>logical replication, </li> <li>Write-Ahead Log (WAL) shipping, and</li> <li>streaming replication</li> </ul>"},{"location":"solutions/high-availability.html#streaming-replication","title":"Streaming replication","text":"<p>Streaming replication is part of Write-Ahead Log shipping, where changes to the WALs are immediately made available to standby replicas. With this approach, a standby instance is always up-to-date with changes from the primary node and can assume the role of primary in case of a failover.</p>"},{"location":"solutions/high-availability.html#why-native-streaming-replication-is-not-enough","title":"Why native streaming replication is not enough","text":"<p>Although the native streaming replication in PostgreSQL supports failing over  to the primary node, it lacks some key features expected from a truly highly-available solution. These include:</p> <ul> <li>No consensus-based promotion of a \u201cleader\u201d node during a failover</li> <li>No decent capability for monitoring cluster status </li> <li>No automated way to bring back the failed primary node to the cluster</li> <li>A manual or scheduled switchover is not easy to manage </li> </ul> <p>To address these shortcomings, there are a multitude of third-party, open-source extensions for PostgreSQL. The challenge for a database administrator here is to select the right utility for the current scenario. </p> <p>Percona Distribution for PostgreSQL solves this challenge by providing the Patroni  extension for achieving PostgreSQL high availability.</p>"},{"location":"solutions/high-availability.html#patroni","title":"Patroni","text":"<p>Patroni  is a template for you to create your own customized, high-availability solution using Python and - for maximum accessibility - a distributed configuration store like ZooKeeper, etcd, Consul or Kubernetes. </p>"},{"location":"solutions/high-availability.html#key-benefits-of-patroni","title":"Key benefits of Patroni:","text":"<ul> <li>Continuous monitoring and automatic failover</li> <li>Manual/scheduled switchover with a single command</li> <li>Built-in automation for bringing back a failed node to cluster again.</li> <li>REST APIs for entire cluster configuration and further tooling.</li> <li>Provides infrastructure for transparent application failover</li> <li>Distributed consensus for every action and configuration.</li> <li>Integration with Linux watchdog for avoiding split-brain syndrome.</li> </ul> <p>See also</p> <ul> <li> <p>Patroni documentation </p> </li> <li> <p>Percona Blog: </p> <ul> <li>PostgreSQL HA with Patroni: Your Turn to Test Failure Scenarios  </li> </ul> </li> </ul>"},{"location":"solutions/high-availability.html#architecture-layout","title":"Architecture layout","text":"<p>The following diagram shows the architecture of a three-node PostgreSQL cluster with a single-leader node. </p> <p></p>"},{"location":"solutions/high-availability.html#components","title":"Components","text":"<p>The components in this architecture are:</p> <ul> <li>PostgreSQL nodes </li> <li> <p>Patroni - a template for configuring a highly available PostgreSQL cluster.</p> </li> <li> <p>etcd - a Distributed Configuration store that stores the state of the PostgreSQL cluster. </p> </li> <li> <p>HAProxy - the load balancer for the cluster and is the single point of entry to client applications. </p> </li> <li> <p>pgBackRest - the backup and restore solution for PostgreSQL</p> </li> <li> <p>Percona Monitoring and Management (PMM) - the solution to monitor the health of your cluster </p> </li> </ul>"},{"location":"solutions/high-availability.html#how-components-work-together","title":"How components work together","text":"<p>Each PostgreSQL instance in the cluster maintains consistency with other members through streaming replication. Each instance hosts Patroni - a cluster manager that monitors the cluster health. Patroni relies on the operational etcd cluster to store the cluster configuration and sensitive data about the cluster health there. </p> <p>Patroni periodically sends heartbeat requests with the cluster status to etcd. etcd writes this information to disk and sends the response back to Patroni. If the current primary fails to renew its status as leader within the specified timeout, Patroni updates the state change in etcd, which uses this information to elect the new primary and keep the cluster up and running.</p> <p>The connections to the cluster do not happen directly to the database nodes but are routed via a connection proxy like HAProxy. This proxy determines the active node by querying the Patroni REST API.</p>"},{"location":"solutions/high-availability.html#next-steps","title":"Next steps","text":"<p>Deploy on Debian or Ubuntu Deploy on RHEL or derivatives</p> <p></p>"},{"location":"solutions/high-availability.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/pgbackrest.html","title":"pgBackRest setup","text":"<p>pgBackRest  is a backup tool used to perform PostgreSQL database backup, archiving, restoration, and point-in-time recovery. While it can be used for local backups, this procedure shows how to deploy a pgBackRest server running on a dedicated host  and how to configure PostgreSQL servers to use it for backups and archiving.</p> <p>You also need a backup storage to store the backups. It can either be a remote storage such as AWS S3, S3-compatible storages or Azure blob storage, or a filesystem-based one. </p>"},{"location":"solutions/pgbackrest.html#configure-backup-server","title":"Configure backup server","text":"<p>To make things easier when working with some templates, run the commands below  as the root user. Run the following command to switch to the root user:</p> <pre><code>$ sudo su -\n</code></pre>"},{"location":"solutions/pgbackrest.html#install-pgbackrest","title":"Install pgBackRest","text":"<ol> <li> <p>Enable the repository with percona-release </p> <pre><code>$ percona-release setup ppg-17       \n</code></pre> </li> <li> <p>Install pgBackRest package</p>  On Debian/Ubuntu On RHEL/derivatives <pre><code>$ apt install percona-pgbackrest\n</code></pre> <pre><code>$ yum install percona-pgbackrest\n</code></pre> </li> </ol>"},{"location":"solutions/pgbackrest.html#create-the-configuration-file","title":"Create the configuration file","text":"<ol> <li> <p>Create environment variables to simplify the config file creation:</p> <pre><code>export SRV_NAME=\"bkp-srv\"\nexport NODE1_NAME=\"node-1\"\nexport NODE2_NAME=\"node-2\"\nexport NODE3_NAME=\"node-3\"\nexport CA_PATH=\"/etc/ssl/certs/pg_ha\"\n</code></pre> </li> <li> <p>Create the <code>pgBackRest</code> repository, if necessary</p> <p>A repository is where <code>pgBackRest</code> stores backups. In this example, the backups will be saved to <code>/var/lib/pgbackrest</code>.</p> <p>This directory is usually created during pgBackRest\u2019s installation process. If it\u2019s not there already, create it as follows:</p> <pre><code>$ mkdir -p /var/lib/pgbackrest\n$ chmod 750 /var/lib/pgbackrest\n$ chown postgres:postgres /var/lib/pgbackrest\n</code></pre> </li> <li> <p>The default <code>pgBackRest</code> configuration file location is <code>/etc/pgbackrest/pgbackrest.conf</code>, but some systems continue to use the old path, <code>/etc/pgbackrest.conf</code>, which remains a valid alternative. If the former is not present in your system, create the latter.</p> <p>Access the file\u2019s parent directory (either <code>cd /etc/</code> or <code>cd /etc/pgbackrest/</code>), and make a backup copy of it:</p> <pre><code>$ cp pgbackrest.conf pgbackrest.conf.bak\n</code></pre> <p>Then use the following command to create a basic configuration file using the environment variables we created in a previous step:</p>  On Debian/Ubuntu On RHEL/derivatives <pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global] \n\n# Server repo details\nrepo1-path=/var/lib/pgbackrest \n\n### Retention ###\n#  - repo1-retention-archive-type\n#  - If set to full pgBackRest will keep archive logs for the number of full backups defined by repo-retention-archive\nrepo1-retention-archive-type=full \n\n# repo1-retention-archive\n#  - Number of backups worth of continuous WAL to retain\n#  - NOTE: WAL segments required to make a backup consistent are always retained until the backup is expired regardless of how this option is configured\n#  - If this value is not set and repo-retention-full-type is count (default), then the archive to expire will default to the repo-retention-full\n# repo1-retention-archive=2 \n\n# repo1-retention-full\n#  - Full backup retention count/time.\n#  - When a full backup expires, all differential and incremental backups associated with the full backup will also expire. \n#  - When the option is not defined a warning will be issued. \n#  - If indefinite retention is desired then set the option to the max value. \nrepo1-retention-full=4 \n\n# Server general options\nprocess-max=12\nlog-level-console=info\n#log-level-file=debug\nlog-level-file=info\nstart-fast=y\ndelta=y\nbackup-standby=y \n\n########## Server TLS options ##########\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${SRV_NAME}.crt\ntls-server-key-file=${CA_PATH}/${SRV_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt \n\n### Auth entry ###\ntls-server-auth=${NODE1_NAME}=cluster_1\ntls-server-auth=${NODE2_NAME}=cluster_1\ntls-server-auth=${NODE3_NAME}=cluster_1 \n\n### Clusters and nodes ###\n[cluster_1]\npg1-host=${NODE1_NAME}\npg1-host-port=8432\npg1-port=5432\npg1-path=/var/lib/postgresql/17/main\npg1-host-type=tls\npg1-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg1-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg1-host-ca-file=${CA_PATH}/ca.crt\npg1-socket-path=/var/run/postgresql \n\npg2-host=${NODE2_NAME}\npg2-host-port=8432\npg2-port=5432\npg2-path=/var/lib/postgresql/17/main\npg2-host-type=tls\npg2-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg2-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg2-host-ca-file=${CA_PATH}/ca.crt\npg2-socket-path=/var/run/postgresql \n\npg3-host=${NODE3_NAME}\npg3-host-port=8432\npg3-port=5432\npg3-path=/var/lib/postgresql/17/main\npg3-host-type=tls\npg3-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg3-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg3-host-ca-file=${CA_PATH}/ca.crt\npg3-socket-path=/var/run/postgresql\nEOF\n</code></pre> <pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global] \n\n# Server repo details\nrepo1-path=/var/lib/pgbackrest \n\n### Retention ###\n#  - repo1-retention-archive-type\n#  - If set to full pgBackRest will keep archive logs for the number of full backups defined by repo-retention-archive\nrepo1-retention-archive-type=full \n\n# repo1-retention-archive\n#  - Number of backups worth of continuous WAL to retain\n#  - NOTE: WAL segments required to make a backup consistent are always retained until the backup is expired regardless of how this option is configured\n#  - If this value is not set and repo-retention-full-type is count (default), then the archive to expire will default to the repo-retention-full\n# repo1-retention-archive=2 \n\n# repo1-retention-full\n#  - Full backup retention count/time.\n#  - When a full backup expires, all differential and incremental backups associated with the full backup will also expire. \n#  - When the option is not defined a warning will be issued. \n#  - If indefinite retention is desired then set the option to the max value. \nrepo1-retention-full=4 \n\n# Server general options\nprocess-max=12\nlog-level-console=info\n#log-level-file=debug\nlog-level-file=info\nstart-fast=y\ndelta=y\nbackup-standby=y \n\n########## Server TLS options ##########\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${SRV_NAME}.crt\ntls-server-key-file=${CA_PATH}/${SRV_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt \n\n### Auth entry ###\ntls-server-auth=${NODE1_NAME}=cluster_1\ntls-server-auth=${NODE2_NAME}=cluster_1\ntls-server-auth=${NODE3_NAME}=cluster_1 \n\n### Clusters and nodes ###\n[cluster_1]\npg1-host=${NODE1_NAME}\npg1-host-port=8432\npg1-port=5432\npg1-path=/var/lib/pgsql/17/data\npg1-host-type=tls\npg1-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg1-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg1-host-ca-file=${CA_PATH}/ca.crt\npg1-socket-path=/var/run/postgresql \n\npg2-host=${NODE2_NAME}\npg2-host-port=8432\npg2-port=5432\npg2-path=/var/lib/pgsql/17/data\npg2-host-type=tls\npg2-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg2-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg2-host-ca-file=${CA_PATH}/ca.crt\npg2-socket-path=/var/run/postgresql \n\npg3-host=${NODE3_NAME}\npg3-host-port=8432\npg3-port=5432\npg3-path=/var/lib/pgsql/17/data\npg3-host-type=tls\npg3-host-cert-file=${CA_PATH}/${SRV_NAME}.crt\npg3-host-key-file=${CA_PATH}/${SRV_NAME}.key\npg3-host-ca-file=${CA_PATH}/ca.crt\npg3-socket-path=/var/run/postgresql\nEOF\n</code></pre> <p>NOTE: The option <code>backup-standby=y</code> above indicates the backups should be taken from a standby server. If you are operating with a primary only, or if your secondaries are not configured with <code>pgBackRest</code>, set this option to <code>n</code>.</p> </li> </ol>"},{"location":"solutions/pgbackrest.html#create-the-certificate-files","title":"Create the certificate files","text":"<ol> <li> <p>Create the folder to store the certificates:</p> <pre><code>$ mkdir -p ${CA_PATH}\n</code></pre> </li> <li> <p>Create the certificates and keys</p> <pre><code>$ openssl req -new -x509 -days 365 -nodes -out ${CA_PATH}/ca.crt -keyout ${CA_PATH}/ca.key -subj \"/CN=root-ca\"\n</code></pre> </li> <li> <p>Create the certificate for the backup and the PostgreSQL servers</p> <pre><code>$ for node in ${SRV_NAME} ${NODE1_NAME} ${NODE2_NAME} ${NODE3_NAME}\ndo\nopenssl req -new -nodes -out ${CA_PATH}/$node.csr -keyout ${CA_PATH}/$node.key -subj \"/CN=$node\";\ndone\n</code></pre> </li> <li> <p>Sign the certificates with the <code>root-ca</code> key</p> <pre><code>$ for node in ${SRV_NAME} ${NODE1_NAME} ${NODE2_NAME} ${NODE3_NAME}\ndo\nopenssl x509 -req -in ${CA_PATH}/$node.csr -days 365 -CA ${CA_PATH}/ca.crt -CAkey ${CA_PATH}/ca.key -CAcreateserial -out ${CA_PATH}/$node.crt;\ndone\n</code></pre> </li> <li> <p>Remove temporary files, set ownership of the remaining files to the <code>postgres</code> user, and restrict their access:</p> <pre><code>$ rm -f ${CA_PATH}/*.csr\n$ chown postgres:postgres -R ${CA_PATH}\n$ chmod 0600 ${CA_PATH}/*\n</code></pre> </li> </ol>"},{"location":"solutions/pgbackrest.html#create-the-pgbackrest-daemon-service","title":"Create the <code>pgbackrest</code> daemon service","text":"<ol> <li> <p>Create the <code>systemd</code> unit file at the path <code>/etc/systemd/system/pgbackrest.service</code></p> /etc/systemd/system/pgbackrest.service<pre><code>[Unit]\nDescription=pgBackRest Server\nAfter=network.target\n\n[Service]\nType=simple\nUser=postgres\nRestart=always\nRestartSec=1\nExecStart=/usr/bin/pgbackrest server\n#ExecStartPost=/bin/sleep 3\n#ExecStartPost=/bin/bash -c \"[ ! -z $MAINPID ]\"\nExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Reload, start, and enable the service</p> <pre><code>$ systemctl daemon-reload\n$ systemctl start pgbackrest.service\n$ systemctl enable pgbackrest.service\n</code></pre> </li> </ol>"},{"location":"solutions/pgbackrest.html#configure-database-servers","title":"Configure database servers","text":"<p>Run the following commands on <code>node1</code>, <code>node2</code>, and <code>node3</code>.</p> <ol> <li> <p>Install pgBackRest package</p>  On Debian/Ubuntu On RHEL/derivatives <pre><code>$ apt install percona-pgbackrest\n</code></pre> <p>```{.bash data-prompt=\u201d$\u201d} $ yum install percona-pgbackrest</p> </li> <li> <p>Export environment variables to simplify the config file creation:</p> <pre><code>$ export NODE_NAME=`hostname -f`\n$ export SRV_NAME=\"bkp-srv\"\n$ export CA_PATH=\"/etc/ssl/certs/pg_ha\"\n</code></pre> </li> <li> <p>Create the certificates folder:</p> <pre><code>$ mkdir -p ${CA_PATH}\n</code></pre> </li> <li> <p>Copy the <code>.crt</code>, <code>.key</code> certificate files and the <code>ca.crt</code> file from the backup server where they were created to every respective node. Then change the ownership to the <code>postgres</code> user and restrict their access. Use the following commands to achieve this:</p> <pre><code>$ scp ${SRV_NAME}:${CA_PATH}/{$NODE_NAME.crt,$NODE_NAME.key,ca.crt} ${CA_PATH}/\n$ chown postgres:postgres -R ${CA_PATH}\n$ chmod 0600 ${CA_PATH}/* \n</code></pre> </li> <li> <p>Edit or create the configuration file which, as explained above, can be either at the <code>/etc/pgbackrest/pgbackrest.conf</code> or <code>/etc/pgbackrest.conf</code> path:</p>  On Debian/Ubuntu On RHEL/derivatives pgbackrest.conf<pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global]\nrepo1-host=${SRV_NAME}\nrepo1-host-user=postgres\nrepo1-host-type=tls\nrepo1-host-cert-file=${CA_PATH}/${NODE_NAME}.crt\nrepo1-host-key-file=${CA_PATH}/${NODE_NAME}.key\nrepo1-host-ca-file=${CA_PATH}/ca.crt\n\n# general options\nprocess-max=16\nlog-level-console=info\nlog-level-file=debug\n\n# tls server options\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${NODE_NAME}.crt\ntls-server-key-file=${CA_PATH}/${NODE_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt\ntls-server-auth=${SRV_NAME}=cluster_1\n\n[cluster_1]\npg1-path=/var/lib/postgresql/17/main\nEOF\n</code></pre> pgbackrest.conf<pre><code>cat &lt;&lt;EOF &gt; pgbackrest.conf\n[global]\nrepo1-host=${SRV_NAME}\nrepo1-host-user=postgres\nrepo1-host-type=tls\nrepo1-host-cert-file=${CA_PATH}/${NODE_NAME}.crt\nrepo1-host-key-file=${CA_PATH}/${NODE_NAME}.key\nrepo1-host-ca-file=${CA_PATH}/ca.crt\n\n# general options\nprocess-max=16\nlog-level-console=info\nlog-level-file=debug\n\n# tls server options\ntls-server-address=*\ntls-server-cert-file=${CA_PATH}/${NODE_NAME}.crt\ntls-server-key-file=${CA_PATH}/${NODE_NAME}.key\ntls-server-ca-file=${CA_PATH}/ca.crt\ntls-server-auth=${SRV_NAME}=cluster_1\n\n[cluster_1]\npg1-path=/var/lib/pgsql/17/data\nEOF\n</code></pre> </li> <li> <p>Create the pgbackrest <code>systemd</code> unit file at the path <code>/etc/systemd/system/pgbackrest.service</code></p> /etc/systemd/system/pgbackrest.service<pre><code>[Unit]\nDescription=pgBackRest Server\nAfter=network.target\n\n[Service]\nType=simple\nUser=postgres\nRestart=always\nRestartSec=1\nExecStart=/usr/bin/pgbackrest server\n#ExecStartPost=/bin/sleep 3\n#ExecStartPost=/bin/bash -c \"[ ! -z $MAINPID ]\"\nExecReload=/bin/kill -HUP $MAINPID\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> </li> <li> <p>Reload, start, and enable the service</p> <pre><code>$ systemctl daemon-reload\n$ systemctl start pgbackrest\n$ systemctl enable pgbackrest\n</code></pre> <p>The pgBackRest daemon listens on port <code>8432</code> by default:</p> <pre><code>$ netstat -taunp\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      1/systemd           \ntcp        0      0 0.0.0.0:8432            0.0.0.0:*               LISTEN      40224/pgbackrest\n</code></pre> </li> <li> <p>If you are using Patroni, change its configuration to use <code>pgBackRest</code> for archiving and restoring WAL files. Run this command only on one node, for example, on <code>node1</code>: </p> <pre><code>$ patronictl -c /etc/patroni/patroni.yml edit-config\n</code></pre>  On Debian/Ubuntu On RHEL/derivatives /etc/patroni/patroni.yml<pre><code>postgresql:\n  (...)\n  parameters:\n    (...)\n    archive_command: pgbackrest --stanza=cluster_1 archive-push /var/lib/postgresql/17/main/pg_wal/%f\n    (...)\n  recovery_conf:\n    (...)\n    restore_command: pgbackrest --config=/etc/pgbackrest.conf --stanza=cluster_1 archive-get %f %p\n    (...)\n</code></pre> /etc/patroni/patroni.yml<pre><code>postgresql:\n  (...)\n  parameters:\n    archive_command: pgbackrest --stanza=cluster_1 archive-push /var/lib/pgsql/17/data/pg_wal/%f\n    (...)\n  recovery_conf:\n    restore_command: pgbackrest --config=/etc/pgbackrest.conf --stanza=cluster_1 archive-get %f %p\n    (...)\n</code></pre> <p>Reload the changed configurations:</p> <pre><code>$ patronictl -c /etc/patroni/postgresql.yml reload\n</code></pre> <p> Note: When configuring a PostgreSQL server that is not managed by Patroni to archive/restore WALs from the <code>pgBackRest</code> server, edit the server\u2019s main configuration file directly and adjust the <code>archive_command</code> and <code>restore_command</code> variables as shown above."},{"location":"solutions/pgbackrest.html#create-backups","title":"Create backups","text":"<p>Run the following commands on the backup server:</p> <ol> <li> <p>Create the stanza. A stanza is the configuration for a PostgreSQL database cluster that defines where it is located, how it will be backed up, archiving options, etc. </p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 stanza-create\n</code></pre> </li> <li> <p>Create a full backup</p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 --type=full backup\n</code></pre> </li> <li> <p>Check backup info</p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 info\n</code></pre> </li> <li> <p>Expire (remove) a backup:</p> <pre><code>$ sudo -iu postgres pgbackrest --stanza=cluster_1 expire --set=&lt;BACKUP_ID&gt;\n</code></pre> </li> </ol> <p>Test PostgreSQL cluster</p> <p></p>"},{"location":"solutions/pgbackrest.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/postgis-deploy.html","title":"Deploy spatial data with PostgreSQL","text":"<p>The following document provides guidelines how to install PostGIS and how to run the basic queries. </p>"},{"location":"solutions/postgis-deploy.html#considerations","title":"Considerations","text":"<ol> <li>We assume that you have the basic knowledge of spatial data, GIS (Geographical Information System) and of shapefiles.</li> <li>For uploading the spatial data and querying the database, we use the same data set  as is used in PostGIS tutorial . </li> </ol>"},{"location":"solutions/postgis-deploy.html#install-postgis","title":"Install PostGIS","text":"On Debian and Ubuntu On RHEL and derivatives <ol> <li> <p>Enable Percona repository</p> <p>As other components of Percona Distribution for PostgreSQL, PostGIS is available from Percona repositories. Use the <code>percona-release</code>  repository management tool to enable the repository. </p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install PostGIS packages</p> <pre><code>$ sudo apt install percona-postgis\n</code></pre> </li> <li> <p>The command in the previous step installs the set of PostGIS extensions. To check what extensions are available, run the following query from the <code>psql</code> terminal:</p> <pre><code>SELECT name, default_version,installed_version\nFROM pg_available_extensions WHERE name LIKE 'postgis%' or name LIKE address%';\n</code></pre> <p>Note</p> <p>To enable the <code>postgis_sfcgal-3</code> extension on Ubuntu 18.04, you need to manually install the required dependency:</p> <pre><code>$ sudo apt-get install libsfcgal1\n</code></pre> </li> </ol> <ol> <li> <p>Check the Platform specific notes and enable required repositories and modules for the dependencies relevant to your operating system.</p> </li> <li> <p>Enable Percona repository    </p> <p>As other components of Percona Distribution for PostgreSQL, PostGIS is available from Percona repositories. Use the <code>percona-release</code>  repository management tool to enable the repository.     </p> <pre><code>$ sudo percona-release setup ppg17\n</code></pre> </li> <li> <p>Install the extension    </p> <pre><code>$ sudo yum install percona-postgis33_17 percona-postgis33_17-client\n</code></pre> </li> </ol> <p>This installs the set of PostGIS extensions. To check what extensions are available, run the following query from the <code>psql</code> terminal:        </p> <pre><code>SELECT name, default_version,installed_version\nFROM pg_available_extensions WHERE name LIKE 'postgis%' or name LIKE 'address%';\n</code></pre>"},{"location":"solutions/postgis-deploy.html#enable-postgis-extension","title":"Enable PostGIS extension","text":"<ol> <li> <p>Create a database and a schema for this database to store your data. A schema is a container that logically segments objects (tables, functions, views, and so on) for better management. Run the following commands from the <code>psql</code> terminal:</p> <pre><code>CREATE database nyc;\n\\c nyc;\nCREATE SCHEMA gis;\n</code></pre> </li> <li> <p>To make PostGIS functions and operations work, you need to enable the <code>postgis</code> extension. Make sure you are connected to the database you created earlier and run the following command:</p> <pre><code>CREATE EXTENSION postgis;\n</code></pre> </li> <li> <p>Check that the extension is enabled:</p> <pre><code>SELECT postgis_full_version();\n</code></pre> <p>The output should be similar to the following:</p> <pre><code>postgis_full_version\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n POSTGIS=\"3.3.3\" [EXTENSION] PGSQL=\"140\" GEOS=\"3.10.2-CAPI-1.16.0\" PROJ=\"8.2.1\" LIBXML=\"2.9.13\" LIBJSON=\"0.15\" LIBPROTOBUF=\"1.3.3\" WAGYU=\"0.5.0 (Internal)\"\n</code></pre> </li> </ol>"},{"location":"solutions/postgis-deploy.html#upload-spatial-data-to-postgresql","title":"Upload spatial data to PostgreSQL","text":"<p>PostGIS provides the <code>shp2pgsql</code> command line utility that converts the binary data from shapefiles into the series of SQL commands and loads them into the database.</p> <ol> <li> <p>For testing purposes, download the sample data set:</p> <pre><code>$ curl -LO https://s3.amazonaws.com/s3.cleverelephant.ca/postgis-workshop-2020.zip\n</code></pre> </li> <li> <p>Unzip the archive and from the folder where the <code>.shp</code> files are located, execute the following command and replace the <code>dbname</code> value with the name of your database:</p> <pre><code>shp2pgsql \\\n  -D \\\n  -I \\\n  -s 26918 \\\n  nyc_streets.shp \\\n  nyc_streets \\\n  | psql -U postgres dbname=nyc\n</code></pre> <p>The command does the following:</p> <ul> <li><code>-D</code> flag instructs the command to generate the dump format</li> <li><code>-I</code> flag instructs to create the spatial index on the table upon the data load</li> <li><code>-s</code> indicates the spatial reference identifier  of the data. The data we load is in the Projected coordinate system for North America and has the value 26918.</li> <li><code>nyc_streets.shp</code> is the source shapefile</li> <li><code>nyc_streets</code> is the table name to create in the database</li> <li><code>dbname=nyc</code> is the database name</li> </ul> </li> <li> <p>Check the uploaded data</p> </li> </ol> <pre><code>\\d nyc_streets;\n                                         Table \"public.nyc_streets\"\n Column |              Type               | Collation | Nullable |                 Default\n--------+---------------------------------+-----------+----------+------------------------------------------\n gid    | integer                         |           | not null | nextval('nyc_streets_gid_seq'::regclass)\n id     | double precision                |           |          |\n name   | character varying(200)          |           |          |\n oneway | character varying(10)           |           |          |\n type   | character varying(50)           |           |          |\n geom   | geometry(MultiLineString,26918) |           |          |\nIndexes:\n    \"nyc_streets_pkey\" PRIMARY KEY, btree (gid)\n    \"nyc_streets_geom_idx\" gist (geom)\n</code></pre> <ol> <li>Repeat the command to upload other shapefiles in the data set: <code>nyc_census_blocks</code>, <code>nyc_neighborhoods</code>, <code>nyc_subway_stations</code></li> </ol> <p></p>"},{"location":"solutions/postgis-deploy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/postgis-testing.html","title":"Query spatial data","text":"<p>After you installed and set up PostGIS, let\u2019s find answers to the following questions by querying the database:</p>"},{"location":"solutions/postgis-testing.html#what-is-the-population-of-the-new-york-city","title":"What is the population of the New York City?","text":"<pre><code>SELECT Sum(popn_total) AS population\n  FROM nyc_census_blocks;\n</code></pre> <p>Output:</p> <pre><code>population\n------------\n    8175032\n(1 row)\n</code></pre>"},{"location":"solutions/postgis-testing.html#what-is-the-area-of-central-park","title":"What is the area of Central Park?","text":"<p>To get the answer we will use the <code>ST_Area</code> function that returns the areas of polygons.</p> <pre><code>SELECT ST_Area(geom) / 1000000\n  FROM nyc_neighborhoods\n  WHERE name = 'Central Park';\n</code></pre> <p>Output:</p> <pre><code>      st_area\n--------------------\n 3.5198365965413293\n(1 row)\n</code></pre> <p>By default, the output is given in square meters. To get the value in square kilometers, divide it by 1 000 000.</p>"},{"location":"solutions/postgis-testing.html#how-long-is-columbus-circle","title":"How long is Columbus Circle?","text":"<pre><code>SELECT ST_Length(geom)\n  FROM nyc_streets\n  WHERE name = 'Columbus Cir';\n</code></pre> <p>Output:</p> <pre><code>     st_length\n-------------------\n 308.3419936909855\n(1 row)\n</code></pre> <p></p>"},{"location":"solutions/postgis-testing.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/postgis-upgrade.html","title":"Spatial database upgrade","text":"<p>When using PostgreSQL and PostGIS for some time, you may eventually come to the decision to upgrade your spatial database. There can be different reasons for that: to receive improvements and/or bug fixes that come with a minor version of the database/extension, reaching the end of life of the currently used software and others.</p> <p>The spatial database upgrade consists of two steps:</p> <ul> <li>upgrade of PostgreSQL, and </li> <li>upgrade of the PostGIS extension. </li> </ul> <p>Important</p> <p>Before the upgrade, backup your data.</p>"},{"location":"solutions/postgis-upgrade.html#upgrade-postgis","title":"Upgrade PostGIS","text":"<p>Each version of PostGIS is compatible with several versions of PostgreSQL and vise versa. The best practice is to first upgrade the PostGIS extension on the source cluster to match the compatible version on the target cluster and then upgrade PostgreSQL. Please see the PostGIS Support matrix  for version compatibility. </p> <p>PostGIS is enabled on the database level. This means that the upgrade is also done on the database level. </p> PostGIS 3 and abovePostGIS 2.5 <p>Connect to the database where it is enabled and run the <code>PostGIS_Extensions_Upgrade()</code>  function:</p> <pre><code>SELECT postgis_extensions_upgrade();\n</code></pre> <p>Repeat these steps to upgrade PostGIS on every database where it is enabled.</p> <p>Connect to the database with the enabled extension and run the following commands:</p> <pre><code>ALTER EXTENSION postgis UPDATE;\nSELECT postgis_extensions_upgrade();\n</code></pre> <p>Starting with version 3, vector and raster functionalities have been separated in two individual extensions. Thus, to upgrade those, you need to run the <code>postgis_extensions_upgrade();</code> twice.</p> <pre><code>SELECT postgis_extensions_upgrade();\n</code></pre> <p>TIP: If you don\u2019t need the raster functionality, you can drop the <code>postgis_raster</code> extension after the upgrade.</p> <p>Repeat these steps to upgrade PostGIS on every database where it is enabled.</p>"},{"location":"solutions/postgis-upgrade.html#upgrade-postgresql","title":"Upgrade PostgreSQL","text":"<p>Upgrade PostgreSQL either to the latest minor or to the major version.</p> <p>If you are using long deprecated views and functions and / or need the expertise in upgrading your spatial database, contact Percona Managed Services  for an individual upgrade scenario development.</p> <p></p>"},{"location":"solutions/postgis-upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"},{"location":"solutions/postgis.html","title":"Spatial data manipulation","text":"<p>Version added: 15.3</p> <p>Organizations dealing with spatial data need to store it somewhere and manipulate it. PostGIS is the open source extension for PostgreSQL that allows doing just that. It adds support for storing the spatial data types such as:</p> <ul> <li>Geographical data like points, lines, polygons, GPS coordinates that can be mapped on a sphere.</li> <li>Geometrical data. This is also points, lines and polygons but they apply to a 2D surface.</li> </ul> <p>To operate with spatial data inside SQL queries, PostGIS supports spatial functions  like distance, area, union, intersection. It uses the spatial indexes like R-Tree  and Quadtree  for efficient processing of database operations. Read more about supported spatial functions and indexes in PostGIS documentation . </p> <p>By deploying PostGIS with Percona Distribution for PostgreSQL, you receive the open-source spatial database that you can use in various areas without vendor lock-in. </p>"},{"location":"solutions/postgis.html#when-to-use-postgis","title":"When to use PostGIS","text":"<p>You can use PostGIS in the following cases:</p> <ul> <li>To store and manage spatial data, create and store spatial shapes, calculate areas and distances</li> <li>To build the software that visualizes spatial data on a map, </li> <li>To work with raster data, such as satellite imagery or digital elevation models.</li> <li>To integrate spatial and non-spatial data such as demographic or economic data in a database</li> </ul>"},{"location":"solutions/postgis.html#when-not-to-use-postgis","title":"When not to use PostGIS","text":"<p>Despite its power and flexibility, PostGIS may not suit your needs if:</p> <ul> <li>You need to store only a couple of map locations. Consider using the built-in geometric functions and operations of PostgreSQL </li> <li>You need real-time data analysis. While PostGIS can handle real-time spatial data, it may not be the best option for real-time data analysis on large volumes of data.</li> <li>You need complex 3D analysis or visualization.</li> <li>You need to acquire spatial data. Use other tools for this purpose and import spatial data into PostGIS to manipulate it.</li> </ul>"},{"location":"solutions/postgis.html#next-steps","title":"Next steps:","text":"<p>Deployment</p> <p></p>"},{"location":"solutions/postgis.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert  Join Percona Squad</p>"}]}